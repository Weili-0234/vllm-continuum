INFO 10-23 01:08:17 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:08:17 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:08:17 [core.py:76] Initializing a V1 LLM engine (v0.1.dev48+gd3e4e8fe3) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=meta-llama/Llama-3.1-8B-Instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":1,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[W1023 01:08:25.579569700 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:08:25 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:08:25 [factory.py:51] Creating v1 connector with name: LMCacheConnectorV1 and engine_id: f931f15b-6ddd-4517-8b42-08d050992b7d
[1;36m(EngineCore_DP0 pid=3659995)[0;0m WARNING 10-23 01:08:25 [base.py:84] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [33;20m[2025-10-23 01:08:25,122] LMCache WARNING:[0m No LMCache configuration file is set. Trying to read configurations from the environment variables. [3m(utils.py:61:lmcache.integration.vllm.utils)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [33;20m[2025-10-23 01:08:25,122] LMCache WARNING:[0m You can set the configuration file through the environment variable: LMCACHE_CONFIG_FILE [3m(utils.py:65:lmcache.integration.vllm.utils)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:08:25,122] LMCache INFO:[0m use mla: False, kv shape: (32, 2, 256, 8, 128), num_draft_layers:0 [3m(vllm_v1_adapter.py:473:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:08:25,126] LMCache INFO:[0m Creating LMCacheEngine instance vllm-instance [3m(cache_engine.py:1372:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:08:25,126] LMCache INFO:[0m NUMA mapping for instance vllm-instance: None [3m(cache_engine.py:1375:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:08:25,126] LMCache INFO:[0m sending cache usage stats to http://stats.lmcache.ai:8080/cache-usage [3m(usage_context.py:285:lmcache.usage_context)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:08:25,127] LMCache INFO:[0m Creating LMCacheEngine with config: {'chunk_size': 256, 'local_cpu': True, 'max_local_cpu_size': 200.0, 'local_disk': None, 'max_local_disk_size': 0.0, 'remote_url': None, 'remote_serde': 'naive', 'use_layerwise': False, 'save_decode_cache': False, 'pre_caching_hash_algorithm': 'builtin', 'enable_blending': False, 'blend_recompute_ratios': None, 'blend_thresholds': None, 'blend_check_layers': None, 'blend_min_tokens': 256, 'blend_special_str': ' # # ', 'enable_p2p': False, 'p2p_host': None, 'p2p_init_ports': None, 'p2p_lookup_ports': None, 'enable_controller': False, 'lmcache_instance_id': 'lmcache_default_instance', 'controller_pull_url': None, 'controller_reply_url': None, 'lmcache_worker_ports': None, 'lmcache_worker_heartbeat_delay_time': 10, 'lmcache_worker_heartbeat_time': None, 'enable_pd': False, 'pd_role': None, 'pd_buffer_size': None, 'pd_buffer_device': None, 'pd_peer_host': None, 'pd_peer_init_port': None, 'pd_peer_alloc_port': None, 'pd_proxy_host': None, 'pd_proxy_port': None, 'transfer_channel': None, 'nixl_backends': None, 'nixl_buffer_size': None, 'nixl_buffer_device': None, 'weka_path': None, 'gds_path': None, 'cufile_buffer_size': None, 'audit_actual_remote_url': None, 'internal_api_server_host': '0.0.0.0', 'extra_config': None, 'save_unfull_chunk': True, 'blocking_timeout_secs': 10, 'external_lookup_client': None, 'py_enable_gc': True, 'cache_policy': 'LRU', 'numa_mode': None, 'enable_async_loading': False, 'internal_api_server_enabled': False, 'internal_api_server_port_start': 6999, 'priority_limit': None, 'internal_api_server_include_index_list': None, 'internal_api_server_socket_path_prefix': None, 'plugin_locations': None, 'external_backends': None, 'lookup_timeout_ms': 3000, 'hit_miss_ratio': None} [3m(cache_engine.py:87:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:08:25,129] LMCache INFO:[0m Initializing LRUCachePolicy [3m(lru.py:20:lmcache.v1.storage_backend.cache_policy.lru)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:08:25,129] LMCache INFO:[0m NUMA mapping None [3m(local_cpu_backend.py:278:lmcache.v1.storage_backend.local_cpu_backend)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:09:26,754] LMCache INFO:[0m Initializing usage context. [3m(usage_context.py:357:lmcache.usage_context)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:09:27,526] LMCache INFO:[0m lmcache lookup server start on ipc:///tmp/engine_f931f15b-6ddd-4517-8b42-08d050992b7d_service_lookup_lmcache_rpc_port_0 [3m(lmcache_lookup_client.py:242:lmcache.v1.lookup_client.lmcache_lookup_client)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:09:27,527] LMCache INFO:[0m Internal API server disabled. internal_api_server_enabled=False, port_offset=1, port=7000, socket_path=None, include_index_list=None [3m(api_server.py:50:lmcache.v1.internal_api_server.api_server)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:09:27,527] LMCache INFO:[0m LMCache initialized for role KVConnectorRole.WORKER with version 0.3.7-ga2c5ba541, vllm version 0.1.dev48+gd3e4e8fe3, lmcache cache_engine metadata: LMCacheEngineMetadata(model_name='meta-llama/Llama-3.1-8B-Instruct', world_size=1, worker_id=0, fmt='vllm', kv_dtype=torch.bfloat16, kv_shape=(32, 2, 256, 8, 128), use_mla=False) [3m(vllm_v1_adapter.py:696:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m WARNING 10-23 01:09:27 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:27 [gpu_model_runner.py:2338] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:27 [gpu_model_runner.py:2370] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=3659995)[0;0m WARNING 10-23 01:09:27 [cuda.py:349] FlashInfer failed to import for V1 engine on Blackwell (SM 10.0) GPUs; it is recommended to install FlashInfer for better performance.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:27 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:28 [weight_utils.py:348] Using model weights format ['*.safetensors']
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.25it/s]
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:00,  2.11it/s]
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.67it/s]
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.49it/s]
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.55it/s]
[1;36m(EngineCore_DP0 pid=3659995)[0;0m 
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:30 [default_loader.py:268] Loading weights took 2.62 seconds
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:31 [gpu_model_runner.py:2392] Model loading took 14.9889 GiB and 3.231627 seconds
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:34 [backends.py:539] Using cache directory: /home/eecs/lihanc/.cache/vllm/torch_compile_cache/05f958c046/rank_0_0/backbone for vLLM's torch.compile
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:34 [backends.py:550] Dynamo bytecode transform time: 2.90 s
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:35 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 1.317 s
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:36 [monitor.py:34] torch.compile takes 2.90 s in total
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:36 [gpu_worker.py:298] Available KV cache memory: 140.27 GiB
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:36 [kv_cache_utils.py:864] GPU KV cache size: 1,149,104 tokens
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:36 [kv_cache_utils.py:868] Maximum concurrency for 131,072 tokens per request: 8.77x
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:36 [utils.py:114] Connectors do not specify a kv cache layout, defaulting to NHD.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:02, 22.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆ         | 7/67 [00:00<00:01, 30.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–‹        | 11/67 [00:00<00:01, 33.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:00<00:01, 34.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:00<00:01, 35.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:00<00:01, 36.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:00<00:01, 36.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:00<00:00, 36.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:01<00:00, 36.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:01<00:00, 31.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:01<00:00, 31.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:01<00:00, 32.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:01<00:00, 32.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:01<00:00, 32.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:01<00:00, 32.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:01<00:00, 32.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00, 33.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:02<00:00, 33.40it/s]
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:39 [gpu_model_runner.py:3118] Graph capturing finished in 2 secs, took 0.56 GiB
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:39 [gpu_worker.py:391] Free memory on device (177.66/178.36 GiB) on startup. Desired GPU memory utilization is (0.9, 160.53 GiB). Actual usage is 14.99 GiB for weight, 4.74 GiB for peak activation, 0.53 GiB for non-torch memory, and 0.56 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=149856856473` to fit into requested memory, or `--kv-cache-memory=168251461632` to fully utilize gpu memory. Current kv cache memory in use is 150616025497 bytes.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:39 [core.py:218] init engine (profile, create kv cache, warmup model) took 8.10 seconds
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:09:39 [factory.py:51] Creating v1 connector with name: LMCacheConnectorV1 and engine_id: f931f15b-6ddd-4517-8b42-08d050992b7d
[1;36m(EngineCore_DP0 pid=3659995)[0;0m WARNING 10-23 01:09:39 [base.py:84] Initializing KVConnectorBase_V1. This API is experimental and subject to change in the future as we iterate the design.
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:09:39,915] LMCache INFO:[0m lmcache lookup client connect to tp_rank 0 with socket path ipc:///tmp/engine_f931f15b-6ddd-4517-8b42-08d050992b7d_service_lookup_lmcache_rpc_port_0 [3m(lmcache_lookup_client.py:67:lmcache.v1.lookup_client.lmcache_lookup_client)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:09:39,916] LMCache INFO:[0m Internal API server disabled. internal_api_server_enabled=False, port_offset=0, port=6999, socket_path=None, include_index_list=None [3m(api_server.py:50:lmcache.v1.internal_api_server.api_server)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:09:39,916] LMCache INFO:[0m LMCache initialized for role KVConnectorRole.SCHEDULER with version 0.3.7-ga2c5ba541, vllm version 0.1.dev48+gd3e4e8fe3, lmcache cache_engine metadata: None [3m(vllm_v1_adapter.py:696:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [loggers.py:142] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 71819
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [async_llm.py:180] Torch profiler disabled. AsyncLLM CPU traces will not be collected.
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [api_server.py:1692] Supported_tasks: ['generate']
[1;36m(APIServer pid=3659290)[0;0m WARNING 10-23 01:09:40 [__init__.py:1695] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [serving_responses.py:130] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [serving_chat.py:137] Using default chat sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [serving_completion.py:76] Using default completion sampling params from model: {'temperature': 0.6, 'top_p': 0.9}
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [api_server.py:1971] Starting vLLM API server 0 on http://0.0.0.0:8000
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:36] Available routes are:
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /openapi.json, Methods: GET, HEAD
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /docs, Methods: GET, HEAD
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /docs/oauth2-redirect, Methods: GET, HEAD
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /redoc, Methods: GET, HEAD
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /health, Methods: GET
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /load, Methods: GET
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /ping, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /ping, Methods: GET
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /version, Methods: GET
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /pooling, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /classify, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /score, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /rerank, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /invocations, Methods: POST
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:09:40 [launcher.py:44] Route: /metrics, Methods: GET
[1;36m(APIServer pid=3659290)[0;0m INFO:     Started server process [3659290]
[1;36m(APIServer pid=3659290)[0;0m INFO:     Waiting for application startup.
[1;36m(APIServer pid=3659290)[0;0m INFO:     Application startup complete.
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:10:00 [chat_utils.py:538] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '1', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '89', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 1, time is 1761207000.261962
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 1
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 89, time is 1761207000.262211
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 89
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,263] LMCache INFO:[0m Reqid: chatcmpl-bbf236aea9bc433d99200685d44047aa, Total tokens 397, LMCache hit tokens: 0, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,264] LMCache INFO:[0m Reqid: chatcmpl-d4a827d40c954507bcd11144e432e26b, Total tokens 402, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '127', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '35', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '120', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '130', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '36', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '162', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '17', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '99', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '60', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '157', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '160', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '143', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '52', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '149', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '90', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '30', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '105', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '119', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '98', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '76', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '50', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '168', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '142', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '87', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '111', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '112', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '15', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,268] LMCache INFO:[0m Post-initializing LMCacheEngine [3m(cache_engine.py:170:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58720 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '128', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '124', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '117', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '24', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '39', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '23', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '126', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '32', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '109', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '121', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '93', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '107', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '131', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '129', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58840 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '159', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '77', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '146', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '123', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '95', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '25', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '100', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '169', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '91', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '104', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '134', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '141', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '166', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '101', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '92', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '3', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '81', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58878 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58984 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '94', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '106', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '8', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '140', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '11', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '152', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '83', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '78', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '66', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59100 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59118 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '103', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '6', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '144', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '118', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '2', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59244 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '165', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '110', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '29', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '114', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '151', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59280 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '19', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '148', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '108', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '171', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59324 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59356 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,333] LMCache INFO:[0m Storing KV cache for 397 out of 397 tokens (skip_leading_tokens=0) for request chatcmpl-bbf236aea9bc433d99200685d44047aa [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,334] LMCache INFO:[0m Stored 397 out of total 397 tokens. size: 0.0485 gb, cost 1.6140 ms, throughput: 30.0257 GB/s; offload_time: 1.5928 ms, put_time: 0.0213 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,335] LMCache INFO:[0m Storing KV cache for 402 out of 402 tokens (skip_leading_tokens=0) for request chatcmpl-d4a827d40c954507bcd11144e432e26b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,336] LMCache INFO:[0m Stored 402 out of total 402 tokens. size: 0.0491 gb, cost 1.1369 ms, throughput: 43.1629 GB/s; offload_time: 1.1272 ms, put_time: 0.0097 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 127, time is 1761207000.3531952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 127
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 35, time is 1761207000.3532937
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 35
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 120, time is 1761207000.3533325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 120
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207000.3533602
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 97
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 130, time is 1761207000.3533854
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 130
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 36, time is 1761207000.3534093
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 36
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 162, time is 1761207000.3534353
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 162
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207000.3534606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 16
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 17, time is 1761207000.353485
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 17
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 99, time is 1761207000.3535128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 99
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 60, time is 1761207000.3535423
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 60
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 157, time is 1761207000.3535702
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 157
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207000.3535964
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 160, time is 1761207000.3536205
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 143, time is 1761207000.3536458
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 52, time is 1761207000.3536701
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 52
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 149, time is 1761207000.353999
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 90, time is 1761207000.3541012
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 90
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207000.354136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 5
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 30, time is 1761207000.3541641
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 30
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 105, time is 1761207000.3541942
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 105
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 119, time is 1761207000.354221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 98, time is 1761207000.3542564
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 98
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 76, time is 1761207000.3542814
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 76
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 50, time is 1761207000.3543093
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 50
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207000.3543365
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 168, time is 1761207000.3543615
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 142, time is 1761207000.3543828
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 87, time is 1761207000.3544047
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 87
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 111, time is 1761207000.3544273
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 112, time is 1761207000.3544507
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 15, time is 1761207000.3544724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 15
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 128, time is 1761207000.3545072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 124, time is 1761207000.3545327
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 117, time is 1761207000.3545594
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 24, time is 1761207000.354585
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 24
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 39, time is 1761207000.3546135
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 39
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 23, time is 1761207000.3546412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 23
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 126, time is 1761207000.354665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 126
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 32, time is 1761207000.3546872
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 32
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 109, time is 1761207000.3547094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 121, time is 1761207000.354735
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 93, time is 1761207000.3547592
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 93
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 107, time is 1761207000.354783
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 107
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 131, time is 1761207000.3548057
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207000.3548315
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 129, time is 1761207000.3548713
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 159, time is 1761207000.3549058
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 159
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 77, time is 1761207000.3549373
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 77
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 146, time is 1761207000.354965
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 123, time is 1761207000.3549886
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 95, time is 1761207000.3550103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 95
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 25, time is 1761207000.3550336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 25
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 100, time is 1761207000.3550563
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 100
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207000.3550823
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 169, time is 1761207000.3551068
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 91, time is 1761207000.355132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 91
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 104, time is 1761207000.355156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 134, time is 1761207000.3551805
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 134
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 141, time is 1761207000.3552058
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 141
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 166, time is 1761207000.3552315
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 101, time is 1761207000.3552537
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 92, time is 1761207000.3552763
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 92
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 3, time is 1761207000.3553004
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 3
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 81, time is 1761207000.355329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 81
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207000.355355
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 94, time is 1761207000.3553793
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 94
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207000.3554034
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 106, time is 1761207000.3554285
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 106
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 8, time is 1761207000.3554537
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 8
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207000.35548
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 150
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207000.3555055
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 140, time is 1761207000.3555312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 140
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 11, time is 1761207000.3555603
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 11
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 152, time is 1761207000.3555877
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 83, time is 1761207000.3556166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 83
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207000.3556442
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 78, time is 1761207000.3556695
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 78
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207000.3556945
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 66, time is 1761207000.3557215
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 66
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 103, time is 1761207000.3557518
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 6, time is 1761207000.3557813
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 6
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 144, time is 1761207000.3558073
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207000.355833
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 118, time is 1761207000.35587
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 118
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207000.3558996
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 133
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 2, time is 1761207000.3559253
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 2
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 165, time is 1761207000.355952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 110, time is 1761207000.3559785
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 110
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207000.3560019
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 29, time is 1761207000.3560266
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 29
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 114, time is 1761207000.356052
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 151, time is 1761207000.3560827
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 151
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 19, time is 1761207000.3561056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 19
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 148, time is 1761207000.35613
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 148
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207000.356154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 108, time is 1761207000.3561823
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 108
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 171, time is 1761207000.3562098
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 171
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207000.3562407
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:00 [estimate_with_func.py:310] Request job id: 44
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,357] LMCache INFO:[0m Reqid: chatcmpl-ea87734753124d598ea1a3b973254edb, Total tokens 380, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,358] LMCache INFO:[0m Reqid: chatcmpl-57dd67e0712d4ce9814a40e3ae6acf2a, Total tokens 404, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,359] LMCache INFO:[0m Reqid: chatcmpl-875d1a726f394197b702b89bfb449af2, Total tokens 394, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,360] LMCache INFO:[0m Reqid: chatcmpl-0af2f0c559954d97956c0c62fe596cbe, Total tokens 381, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,361] LMCache INFO:[0m Reqid: chatcmpl-50d2d166c6e147e2807c29dbb92a21cd, Total tokens 403, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,362] LMCache INFO:[0m Reqid: chatcmpl-cb4145f602b64acfadde1a12ad52e800, Total tokens 393, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,363] LMCache INFO:[0m Reqid: chatcmpl-5ac6d222c8b3499fa2f12790deae5e50, Total tokens 390, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,364] LMCache INFO:[0m Reqid: chatcmpl-2b672064103a4891af6e08822b0b261a, Total tokens 397, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,365] LMCache INFO:[0m Reqid: chatcmpl-fc78a50b0b6a4c048371a4618146770a, Total tokens 385, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,366] LMCache INFO:[0m Reqid: chatcmpl-939861719c584acca5148ee800eb0d5b, Total tokens 424, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,367] LMCache INFO:[0m Reqid: chatcmpl-51585e09e6d44be5af4aeadc738fbc05, Total tokens 384, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,369] LMCache INFO:[0m Reqid: chatcmpl-863b1bfccc3c415b9accff7bfa08141c, Total tokens 378, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,370] LMCache INFO:[0m Reqid: chatcmpl-619beb13f7e74cba944e371ae45e9ae7, Total tokens 399, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,371] LMCache INFO:[0m Reqid: chatcmpl-6356814c68444a29b25dd61538465176, Total tokens 395, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,372] LMCache INFO:[0m Reqid: chatcmpl-fbfc88b46e6945e397796214e081e4e0, Total tokens 394, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,373] LMCache INFO:[0m Reqid: chatcmpl-1acb670e15df4525a608b15ff637d151, Total tokens 399, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,374] LMCache INFO:[0m Reqid: chatcmpl-7da43be90fb8491ea6e3f9072dd5d0bb, Total tokens 398, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,375] LMCache INFO:[0m Reqid: chatcmpl-a25b4a4bac174f1ba62593afd3903644, Total tokens 385, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,376] LMCache INFO:[0m Reqid: chatcmpl-c7fe9770f3924d3ea94e89fe39674405, Total tokens 406, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,377] LMCache INFO:[0m Reqid: chatcmpl-1fbb1d9d7e384e339ced22f67deabd8d, Total tokens 402, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,378] LMCache INFO:[0m Reqid: chatcmpl-65fa055d7a654f5dbf74c5ad03eb296d, Total tokens 407, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,379] LMCache INFO:[0m Reqid: chatcmpl-80546bdbf99c4a469023cd6a64d1084d, Total tokens 415, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,484] LMCache INFO:[0m Storing KV cache for 380 out of 380 tokens (skip_leading_tokens=0) for request chatcmpl-ea87734753124d598ea1a3b973254edb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,486] LMCache INFO:[0m Stored 380 out of total 380 tokens. size: 0.0464 gb, cost 1.2145 ms, throughput: 38.1926 GB/s; offload_time: 1.2032 ms, put_time: 0.0113 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,486] LMCache INFO:[0m Storing KV cache for 404 out of 404 tokens (skip_leading_tokens=0) for request chatcmpl-57dd67e0712d4ce9814a40e3ae6acf2a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,487] LMCache INFO:[0m Stored 404 out of total 404 tokens. size: 0.0493 gb, cost 1.1624 ms, throughput: 42.4266 GB/s; offload_time: 1.1542 ms, put_time: 0.0082 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,487] LMCache INFO:[0m Storing KV cache for 394 out of 394 tokens (skip_leading_tokens=0) for request chatcmpl-875d1a726f394197b702b89bfb449af2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,488] LMCache INFO:[0m Stored 394 out of total 394 tokens. size: 0.0481 gb, cost 1.1058 ms, throughput: 43.4947 GB/s; offload_time: 1.0981 ms, put_time: 0.0077 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,488] LMCache INFO:[0m Storing KV cache for 381 out of 381 tokens (skip_leading_tokens=0) for request chatcmpl-0af2f0c559954d97956c0c62fe596cbe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,489] LMCache INFO:[0m Stored 381 out of total 381 tokens. size: 0.0465 gb, cost 1.0952 ms, throughput: 42.4650 GB/s; offload_time: 1.0870 ms, put_time: 0.0082 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,489] LMCache INFO:[0m Storing KV cache for 403 out of 403 tokens (skip_leading_tokens=0) for request chatcmpl-50d2d166c6e147e2807c29dbb92a21cd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,491] LMCache INFO:[0m Stored 403 out of total 403 tokens. size: 0.0492 gb, cost 1.1536 ms, throughput: 42.6431 GB/s; offload_time: 1.1469 ms, put_time: 0.0068 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,491] LMCache INFO:[0m Storing KV cache for 393 out of 393 tokens (skip_leading_tokens=0) for request chatcmpl-cb4145f602b64acfadde1a12ad52e800 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,492] LMCache INFO:[0m Stored 393 out of total 393 tokens. size: 0.0480 gb, cost 1.1081 ms, throughput: 43.2932 GB/s; offload_time: 1.1015 ms, put_time: 0.0066 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,492] LMCache INFO:[0m Storing KV cache for 390 out of 390 tokens (skip_leading_tokens=0) for request chatcmpl-5ac6d222c8b3499fa2f12790deae5e50 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,493] LMCache INFO:[0m Stored 390 out of total 390 tokens. size: 0.0476 gb, cost 1.0951 ms, throughput: 43.4725 GB/s; offload_time: 1.0887 ms, put_time: 0.0064 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,493] LMCache INFO:[0m Storing KV cache for 397 out of 397 tokens (skip_leading_tokens=0) for request chatcmpl-2b672064103a4891af6e08822b0b261a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,494] LMCache INFO:[0m Stored 397 out of total 397 tokens. size: 0.0485 gb, cost 1.1046 ms, throughput: 43.8739 GB/s; offload_time: 1.0987 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,494] LMCache INFO:[0m Storing KV cache for 385 out of 385 tokens (skip_leading_tokens=0) for request chatcmpl-fc78a50b0b6a4c048371a4618146770a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,495] LMCache INFO:[0m Stored 385 out of total 385 tokens. size: 0.0470 gb, cost 1.0644 ms, throughput: 44.1528 GB/s; offload_time: 1.0565 ms, put_time: 0.0079 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,496] LMCache INFO:[0m Storing KV cache for 424 out of 424 tokens (skip_leading_tokens=0) for request chatcmpl-939861719c584acca5148ee800eb0d5b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,497] LMCache INFO:[0m Stored 424 out of total 424 tokens. size: 0.0518 gb, cost 1.1851 ms, throughput: 43.6755 GB/s; offload_time: 1.1785 ms, put_time: 0.0066 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,497] LMCache INFO:[0m Storing KV cache for 384 out of 384 tokens (skip_leading_tokens=0) for request chatcmpl-51585e09e6d44be5af4aeadc738fbc05 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,498] LMCache INFO:[0m Stored 384 out of total 384 tokens. size: 0.0469 gb, cost 1.0754 ms, throughput: 43.5876 GB/s; offload_time: 1.0696 ms, put_time: 0.0058 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,498] LMCache INFO:[0m Storing KV cache for 378 out of 378 tokens (skip_leading_tokens=0) for request chatcmpl-863b1bfccc3c415b9accff7bfa08141c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,499] LMCache INFO:[0m Stored 378 out of total 378 tokens. size: 0.0461 gb, cost 1.0546 ms, throughput: 43.7552 GB/s; offload_time: 1.0486 ms, put_time: 0.0060 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,499] LMCache INFO:[0m Storing KV cache for 399 out of 399 tokens (skip_leading_tokens=0) for request chatcmpl-619beb13f7e74cba944e371ae45e9ae7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,500] LMCache INFO:[0m Stored 399 out of total 399 tokens. size: 0.0487 gb, cost 1.1119 ms, throughput: 43.8054 GB/s; offload_time: 1.1061 ms, put_time: 0.0057 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,500] LMCache INFO:[0m Storing KV cache for 395 out of 395 tokens (skip_leading_tokens=0) for request chatcmpl-6356814c68444a29b25dd61538465176 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,502] LMCache INFO:[0m Stored 395 out of total 395 tokens. size: 0.0482 gb, cost 1.1229 ms, throughput: 42.9419 GB/s; offload_time: 1.1157 ms, put_time: 0.0071 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,502] LMCache INFO:[0m Storing KV cache for 394 out of 394 tokens (skip_leading_tokens=0) for request chatcmpl-fbfc88b46e6945e397796214e081e4e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,503] LMCache INFO:[0m Stored 394 out of total 394 tokens. size: 0.0481 gb, cost 1.1312 ms, throughput: 42.5167 GB/s; offload_time: 1.1253 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,503] LMCache INFO:[0m Storing KV cache for 399 out of 399 tokens (skip_leading_tokens=0) for request chatcmpl-1acb670e15df4525a608b15ff637d151 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,504] LMCache INFO:[0m Stored 399 out of total 399 tokens. size: 0.0487 gb, cost 1.1240 ms, throughput: 43.3319 GB/s; offload_time: 1.1179 ms, put_time: 0.0061 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,504] LMCache INFO:[0m Storing KV cache for 398 out of 398 tokens (skip_leading_tokens=0) for request chatcmpl-7da43be90fb8491ea6e3f9072dd5d0bb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,505] LMCache INFO:[0m Stored 398 out of total 398 tokens. size: 0.0486 gb, cost 1.1347 ms, throughput: 42.8180 GB/s; offload_time: 1.1284 ms, put_time: 0.0062 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,505] LMCache INFO:[0m Storing KV cache for 385 out of 385 tokens (skip_leading_tokens=0) for request chatcmpl-a25b4a4bac174f1ba62593afd3903644 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,506] LMCache INFO:[0m Stored 385 out of total 385 tokens. size: 0.0470 gb, cost 1.0954 ms, throughput: 42.9048 GB/s; offload_time: 1.0893 ms, put_time: 0.0060 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,507] LMCache INFO:[0m Storing KV cache for 406 out of 406 tokens (skip_leading_tokens=0) for request chatcmpl-c7fe9770f3924d3ea94e89fe39674405 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,508] LMCache INFO:[0m Stored 406 out of total 406 tokens. size: 0.0496 gb, cost 1.1639 ms, throughput: 42.5819 GB/s; offload_time: 1.1581 ms, put_time: 0.0058 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,508] LMCache INFO:[0m Storing KV cache for 402 out of 402 tokens (skip_leading_tokens=0) for request chatcmpl-1fbb1d9d7e384e339ced22f67deabd8d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,509] LMCache INFO:[0m Stored 402 out of total 402 tokens. size: 0.0491 gb, cost 1.1357 ms, throughput: 43.2086 GB/s; offload_time: 1.1285 ms, put_time: 0.0072 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,509] LMCache INFO:[0m Storing KV cache for 407 out of 407 tokens (skip_leading_tokens=0) for request chatcmpl-65fa055d7a654f5dbf74c5ad03eb296d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,510] LMCache INFO:[0m Stored 407 out of total 407 tokens. size: 0.0497 gb, cost 1.1217 ms, throughput: 44.2920 GB/s; offload_time: 1.1161 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,515] LMCache INFO:[0m Reqid: chatcmpl-a8e7c27241c743b085ff207f8a405072, Total tokens 398, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,516] LMCache INFO:[0m Reqid: chatcmpl-d4fceecdbb1746fabdbbeeee6b878fa8, Total tokens 405, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,517] LMCache INFO:[0m Reqid: chatcmpl-93745f61e9e748618cd2f38d7fd3791c, Total tokens 404, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,518] LMCache INFO:[0m Reqid: chatcmpl-b2a2d26204d64412a29fd52761f51dd2, Total tokens 395, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,519] LMCache INFO:[0m Reqid: chatcmpl-73d0d3ff19cf4b6bb7550a93d07d2220, Total tokens 394, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,520] LMCache INFO:[0m Reqid: chatcmpl-3fa7929f0f994cbeb216b8aa41dcc636, Total tokens 410, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,521] LMCache INFO:[0m Reqid: chatcmpl-c3381cd6caca45ba9ade931237aefc6a, Total tokens 378, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,522] LMCache INFO:[0m Reqid: chatcmpl-dcf58bc11bfe4efc97606fbf5b7f5e7e, Total tokens 392, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,523] LMCache INFO:[0m Reqid: chatcmpl-cb049d630e064875b90c1d9dd5a30b5c, Total tokens 400, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,524] LMCache INFO:[0m Reqid: chatcmpl-0a40309917ec40b0ada7859311a10ffc, Total tokens 403, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,525] LMCache INFO:[0m Reqid: chatcmpl-7f75b279d8ab4133bcc7d7388b290dca, Total tokens 385, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,527] LMCache INFO:[0m Reqid: chatcmpl-e8bdab635f7e4e9aa3af4dc53925edc6, Total tokens 373, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,528] LMCache INFO:[0m Reqid: chatcmpl-37a7e9097a6649dd8140b17d1819cd02, Total tokens 389, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,529] LMCache INFO:[0m Reqid: chatcmpl-98155469432e45c58df414a5f6b870bf, Total tokens 410, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,530] LMCache INFO:[0m Reqid: chatcmpl-454e8d43e1864532b8a8d642cf75daf7, Total tokens 379, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,531] LMCache INFO:[0m Reqid: chatcmpl-4b33e2f6a38d4ed9adb32f494581d1d8, Total tokens 386, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,532] LMCache INFO:[0m Reqid: chatcmpl-bbb688cf02224636826947e5c8599531, Total tokens 405, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,533] LMCache INFO:[0m Reqid: chatcmpl-dd753491fee94f77921873c5f8b03954, Total tokens 401, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,535] LMCache INFO:[0m Reqid: chatcmpl-70c4eb6b773e4fc28fca8277e8ab7ba8, Total tokens 386, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,535] LMCache INFO:[0m Reqid: chatcmpl-65a5d4d19b0a44f6a1869473e1ec96e8, Total tokens 398, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,536] LMCache INFO:[0m Reqid: chatcmpl-73bf447bb2a946ed923b70f1382224ae, Total tokens 383, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,537] LMCache INFO:[0m Reqid: chatcmpl-5e8f9e9610b943f483b29bccb077b2d0, Total tokens 392, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:10:00 [loggers.py:123] Engine 000: Avg prompt throughput: 909.7 tokens/s, Avg generation throughput: 2.5 tokens/s, Running: 24 reqs, Waiting: 77 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 3.9%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,648] LMCache INFO:[0m Storing KV cache for 398 out of 398 tokens (skip_leading_tokens=0) for request chatcmpl-a8e7c27241c743b085ff207f8a405072 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,649] LMCache INFO:[0m Stored 398 out of total 398 tokens. size: 0.0486 gb, cost 1.2028 ms, throughput: 40.3909 GB/s; offload_time: 1.1927 ms, put_time: 0.0102 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,650] LMCache INFO:[0m Storing KV cache for 405 out of 405 tokens (skip_leading_tokens=0) for request chatcmpl-d4fceecdbb1746fabdbbeeee6b878fa8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,651] LMCache INFO:[0m Stored 405 out of total 405 tokens. size: 0.0494 gb, cost 1.1624 ms, throughput: 42.5307 GB/s; offload_time: 1.1552 ms, put_time: 0.0072 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,651] LMCache INFO:[0m Storing KV cache for 404 out of 404 tokens (skip_leading_tokens=0) for request chatcmpl-93745f61e9e748618cd2f38d7fd3791c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,652] LMCache INFO:[0m Stored 404 out of total 404 tokens. size: 0.0493 gb, cost 1.1515 ms, throughput: 42.8280 GB/s; offload_time: 1.1446 ms, put_time: 0.0069 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,652] LMCache INFO:[0m Storing KV cache for 395 out of 395 tokens (skip_leading_tokens=0) for request chatcmpl-b2a2d26204d64412a29fd52761f51dd2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,653] LMCache INFO:[0m Stored 395 out of total 395 tokens. size: 0.0482 gb, cost 1.1374 ms, throughput: 42.3917 GB/s; offload_time: 1.1309 ms, put_time: 0.0066 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,653] LMCache INFO:[0m Storing KV cache for 394 out of 394 tokens (skip_leading_tokens=0) for request chatcmpl-73d0d3ff19cf4b6bb7550a93d07d2220 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,655] LMCache INFO:[0m Stored 394 out of total 394 tokens. size: 0.0481 gb, cost 1.1268 ms, throughput: 42.6836 GB/s; offload_time: 1.1203 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,655] LMCache INFO:[0m Storing KV cache for 410 out of 410 tokens (skip_leading_tokens=0) for request chatcmpl-3fa7929f0f994cbeb216b8aa41dcc636 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,656] LMCache INFO:[0m Stored 410 out of total 410 tokens. size: 0.0500 gb, cost 1.1646 ms, throughput: 42.9748 GB/s; offload_time: 1.1579 ms, put_time: 0.0067 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,656] LMCache INFO:[0m Storing KV cache for 378 out of 378 tokens (skip_leading_tokens=0) for request chatcmpl-c3381cd6caca45ba9ade931237aefc6a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,657] LMCache INFO:[0m Stored 378 out of total 378 tokens. size: 0.0461 gb, cost 1.0963 ms, throughput: 42.0896 GB/s; offload_time: 1.0904 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,657] LMCache INFO:[0m Storing KV cache for 392 out of 392 tokens (skip_leading_tokens=0) for request chatcmpl-dcf58bc11bfe4efc97606fbf5b7f5e7e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,658] LMCache INFO:[0m Stored 392 out of total 392 tokens. size: 0.0479 gb, cost 1.1054 ms, throughput: 43.2900 GB/s; offload_time: 1.0996 ms, put_time: 0.0057 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,658] LMCache INFO:[0m Storing KV cache for 400 out of 400 tokens (skip_leading_tokens=0) for request chatcmpl-cb049d630e064875b90c1d9dd5a30b5c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,659] LMCache INFO:[0m Stored 400 out of total 400 tokens. size: 0.0488 gb, cost 1.1332 ms, throughput: 43.0871 GB/s; offload_time: 1.1273 ms, put_time: 0.0060 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,660] LMCache INFO:[0m Storing KV cache for 403 out of 403 tokens (skip_leading_tokens=0) for request chatcmpl-0a40309917ec40b0ada7859311a10ffc [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,661] LMCache INFO:[0m Stored 403 out of total 403 tokens. size: 0.0492 gb, cost 1.1198 ms, throughput: 43.9297 GB/s; offload_time: 1.1143 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,661] LMCache INFO:[0m Storing KV cache for 385 out of 385 tokens (skip_leading_tokens=0) for request chatcmpl-7f75b279d8ab4133bcc7d7388b290dca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,662] LMCache INFO:[0m Stored 385 out of total 385 tokens. size: 0.0470 gb, cost 1.0930 ms, throughput: 43.0000 GB/s; offload_time: 1.0872 ms, put_time: 0.0057 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,662] LMCache INFO:[0m Storing KV cache for 373 out of 373 tokens (skip_leading_tokens=0) for request chatcmpl-e8bdab635f7e4e9aa3af4dc53925edc6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,663] LMCache INFO:[0m Stored 373 out of total 373 tokens. size: 0.0455 gb, cost 1.0610 ms, throughput: 42.9153 GB/s; offload_time: 1.0556 ms, put_time: 0.0054 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,663] LMCache INFO:[0m Storing KV cache for 389 out of 389 tokens (skip_leading_tokens=0) for request chatcmpl-37a7e9097a6649dd8140b17d1819cd02 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,664] LMCache INFO:[0m Stored 389 out of total 389 tokens. size: 0.0475 gb, cost 1.1297 ms, throughput: 42.0344 GB/s; offload_time: 1.1233 ms, put_time: 0.0064 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,664] LMCache INFO:[0m Storing KV cache for 410 out of 410 tokens (skip_leading_tokens=0) for request chatcmpl-98155469432e45c58df414a5f6b870bf [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,666] LMCache INFO:[0m Stored 410 out of total 410 tokens. size: 0.0500 gb, cost 1.1550 ms, throughput: 43.3317 GB/s; offload_time: 1.1489 ms, put_time: 0.0062 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,666] LMCache INFO:[0m Storing KV cache for 379 out of 379 tokens (skip_leading_tokens=0) for request chatcmpl-454e8d43e1864532b8a8d642cf75daf7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,667] LMCache INFO:[0m Stored 379 out of total 379 tokens. size: 0.0463 gb, cost 1.0886 ms, throughput: 42.5006 GB/s; offload_time: 1.0831 ms, put_time: 0.0055 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,667] LMCache INFO:[0m Storing KV cache for 386 out of 386 tokens (skip_leading_tokens=0) for request chatcmpl-4b33e2f6a38d4ed9adb32f494581d1d8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,668] LMCache INFO:[0m Stored 386 out of total 386 tokens. size: 0.0471 gb, cost 1.0990 ms, throughput: 42.8756 GB/s; offload_time: 1.0933 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,668] LMCache INFO:[0m Storing KV cache for 405 out of 405 tokens (skip_leading_tokens=0) for request chatcmpl-bbb688cf02224636826947e5c8599531 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,669] LMCache INFO:[0m Stored 405 out of total 405 tokens. size: 0.0494 gb, cost 1.1587 ms, throughput: 42.6676 GB/s; offload_time: 1.1528 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,669] LMCache INFO:[0m Storing KV cache for 401 out of 401 tokens (skip_leading_tokens=0) for request chatcmpl-dd753491fee94f77921873c5f8b03954 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,670] LMCache INFO:[0m Stored 401 out of total 401 tokens. size: 0.0490 gb, cost 1.1437 ms, throughput: 42.8008 GB/s; offload_time: 1.1380 ms, put_time: 0.0057 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,670] LMCache INFO:[0m Storing KV cache for 386 out of 386 tokens (skip_leading_tokens=0) for request chatcmpl-70c4eb6b773e4fc28fca8277e8ab7ba8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,672] LMCache INFO:[0m Stored 386 out of total 386 tokens. size: 0.0471 gb, cost 1.0919 ms, throughput: 43.1541 GB/s; offload_time: 1.0867 ms, put_time: 0.0052 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,672] LMCache INFO:[0m Storing KV cache for 398 out of 398 tokens (skip_leading_tokens=0) for request chatcmpl-65a5d4d19b0a44f6a1869473e1ec96e8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,673] LMCache INFO:[0m Stored 398 out of total 398 tokens. size: 0.0486 gb, cost 1.1305 ms, throughput: 42.9739 GB/s; offload_time: 1.1218 ms, put_time: 0.0088 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,673] LMCache INFO:[0m Storing KV cache for 383 out of 383 tokens (skip_leading_tokens=0) for request chatcmpl-73bf447bb2a946ed923b70f1382224ae [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,674] LMCache INFO:[0m Stored 383 out of total 383 tokens. size: 0.0468 gb, cost 1.0885 ms, throughput: 42.9525 GB/s; offload_time: 1.0824 ms, put_time: 0.0061 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,674] LMCache INFO:[0m Storing KV cache for 415 out of 415 tokens (skip_leading_tokens=0) for request chatcmpl-80546bdbf99c4a469023cd6a64d1084d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,675] LMCache INFO:[0m Stored 415 out of total 415 tokens. size: 0.0507 gb, cost 1.1767 ms, throughput: 43.0529 GB/s; offload_time: 1.1711 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,681] LMCache INFO:[0m Reqid: chatcmpl-7401842d9d3944a6842c17f6b6003828, Total tokens 390, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,682] LMCache INFO:[0m Reqid: chatcmpl-40c0183f9a3841a0b80eefd0338debbb, Total tokens 412, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,684] LMCache INFO:[0m Reqid: chatcmpl-de84068a62634b8ab8482372f2a55d31, Total tokens 381, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,685] LMCache INFO:[0m Reqid: chatcmpl-f1a5c4983efc46b2a09e0f33ac8be831, Total tokens 396, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,686] LMCache INFO:[0m Reqid: chatcmpl-0078817e6770409a9fe79edf33e61cf7, Total tokens 406, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,686] LMCache INFO:[0m Reqid: chatcmpl-3e6d7da1ce4f4794a3a93b513ddd265b, Total tokens 398, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,687] LMCache INFO:[0m Reqid: chatcmpl-7329d90db8c2417db2361e23bf8da545, Total tokens 393, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,688] LMCache INFO:[0m Reqid: chatcmpl-80a2d76efcc44dfc96f003c0b48fae05, Total tokens 389, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,689] LMCache INFO:[0m Reqid: chatcmpl-8c4f13e89709430396b52840d4af7be0, Total tokens 377, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,690] LMCache INFO:[0m Reqid: chatcmpl-708c7afdd87d40f4a60f3135dbd2a185, Total tokens 381, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,691] LMCache INFO:[0m Reqid: chatcmpl-000ca6bf668c4c4a8f494f43af1445df, Total tokens 377, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,692] LMCache INFO:[0m Reqid: chatcmpl-eede6c82caed4b27baffba7efa78694e, Total tokens 387, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,694] LMCache INFO:[0m Reqid: chatcmpl-8fdb0dd34e5941988fa4c3e5c67a5636, Total tokens 408, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,695] LMCache INFO:[0m Reqid: chatcmpl-fa5520ef41224778a45bea585fd0642e, Total tokens 406, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,696] LMCache INFO:[0m Reqid: chatcmpl-0caea17429424beb9038b3b4719311ec, Total tokens 406, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,697] LMCache INFO:[0m Reqid: chatcmpl-e725bc5693d648ac82e6b6b12b04bafb, Total tokens 394, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,698] LMCache INFO:[0m Reqid: chatcmpl-928c028b7e044f249589ee205fab297d, Total tokens 412, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,699] LMCache INFO:[0m Reqid: chatcmpl-1553300ac651437185c50b6a47696530, Total tokens 387, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,700] LMCache INFO:[0m Reqid: chatcmpl-00882f5ad8d142499d61d9335f84f20d, Total tokens 403, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,701] LMCache INFO:[0m Reqid: chatcmpl-b94bf30ae3b14be582e0012aeb9fd189, Total tokens 392, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,702] LMCache INFO:[0m Reqid: chatcmpl-0f85f83d7f564cae849785d4c88d7832, Total tokens 399, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,829] LMCache INFO:[0m Storing KV cache for 390 out of 390 tokens (skip_leading_tokens=0) for request chatcmpl-7401842d9d3944a6842c17f6b6003828 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,830] LMCache INFO:[0m Stored 390 out of total 390 tokens. size: 0.0476 gb, cost 1.1963 ms, throughput: 39.7969 GB/s; offload_time: 1.1858 ms, put_time: 0.0105 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,830] LMCache INFO:[0m Storing KV cache for 412 out of 412 tokens (skip_leading_tokens=0) for request chatcmpl-40c0183f9a3841a0b80eefd0338debbb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,832] LMCache INFO:[0m Stored 412 out of total 412 tokens. size: 0.0503 gb, cost 1.1978 ms, throughput: 41.9872 GB/s; offload_time: 1.1900 ms, put_time: 0.0078 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,832] LMCache INFO:[0m Storing KV cache for 381 out of 381 tokens (skip_leading_tokens=0) for request chatcmpl-de84068a62634b8ab8482372f2a55d31 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,833] LMCache INFO:[0m Stored 381 out of total 381 tokens. size: 0.0465 gb, cost 1.1029 ms, throughput: 42.1708 GB/s; offload_time: 1.0965 ms, put_time: 0.0064 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,833] LMCache INFO:[0m Storing KV cache for 396 out of 396 tokens (skip_leading_tokens=0) for request chatcmpl-f1a5c4983efc46b2a09e0f33ac8be831 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,834] LMCache INFO:[0m Stored 396 out of total 396 tokens. size: 0.0483 gb, cost 1.1330 ms, throughput: 42.6666 GB/s; offload_time: 1.1267 ms, put_time: 0.0063 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,834] LMCache INFO:[0m Storing KV cache for 406 out of 406 tokens (skip_leading_tokens=0) for request chatcmpl-0078817e6770409a9fe79edf33e61cf7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,835] LMCache INFO:[0m Stored 406 out of total 406 tokens. size: 0.0496 gb, cost 1.1532 ms, throughput: 42.9748 GB/s; offload_time: 1.1473 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,835] LMCache INFO:[0m Storing KV cache for 398 out of 398 tokens (skip_leading_tokens=0) for request chatcmpl-3e6d7da1ce4f4794a3a93b513ddd265b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,836] LMCache INFO:[0m Stored 398 out of total 398 tokens. size: 0.0486 gb, cost 1.1460 ms, throughput: 42.3958 GB/s; offload_time: 1.1396 ms, put_time: 0.0064 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,837] LMCache INFO:[0m Storing KV cache for 393 out of 393 tokens (skip_leading_tokens=0) for request chatcmpl-7329d90db8c2417db2361e23bf8da545 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,838] LMCache INFO:[0m Stored 393 out of total 393 tokens. size: 0.0480 gb, cost 1.1286 ms, throughput: 42.5090 GB/s; offload_time: 1.1223 ms, put_time: 0.0063 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,838] LMCache INFO:[0m Storing KV cache for 389 out of 389 tokens (skip_leading_tokens=0) for request chatcmpl-80a2d76efcc44dfc96f003c0b48fae05 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,839] LMCache INFO:[0m Stored 389 out of total 389 tokens. size: 0.0475 gb, cost 1.1132 ms, throughput: 42.6554 GB/s; offload_time: 1.1063 ms, put_time: 0.0070 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,839] LMCache INFO:[0m Storing KV cache for 377 out of 377 tokens (skip_leading_tokens=0) for request chatcmpl-8c4f13e89709430396b52840d4af7be0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,840] LMCache INFO:[0m Stored 377 out of total 377 tokens. size: 0.0460 gb, cost 1.0976 ms, throughput: 41.9298 GB/s; offload_time: 1.0911 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,840] LMCache INFO:[0m Storing KV cache for 381 out of 381 tokens (skip_leading_tokens=0) for request chatcmpl-708c7afdd87d40f4a60f3135dbd2a185 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,841] LMCache INFO:[0m Stored 381 out of total 381 tokens. size: 0.0465 gb, cost 1.1199 ms, throughput: 41.5284 GB/s; offload_time: 1.1133 ms, put_time: 0.0066 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,841] LMCache INFO:[0m Storing KV cache for 377 out of 377 tokens (skip_leading_tokens=0) for request chatcmpl-000ca6bf668c4c4a8f494f43af1445df [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,843] LMCache INFO:[0m Stored 377 out of total 377 tokens. size: 0.0460 gb, cost 1.0701 ms, throughput: 43.0073 GB/s; offload_time: 1.0644 ms, put_time: 0.0057 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,843] LMCache INFO:[0m Storing KV cache for 387 out of 387 tokens (skip_leading_tokens=0) for request chatcmpl-eede6c82caed4b27baffba7efa78694e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,844] LMCache INFO:[0m Stored 387 out of total 387 tokens. size: 0.0472 gb, cost 1.0979 ms, throughput: 43.0279 GB/s; offload_time: 1.0923 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,844] LMCache INFO:[0m Storing KV cache for 408 out of 408 tokens (skip_leading_tokens=0) for request chatcmpl-8fdb0dd34e5941988fa4c3e5c67a5636 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,845] LMCache INFO:[0m Stored 408 out of total 408 tokens. size: 0.0498 gb, cost 1.1510 ms, throughput: 43.2694 GB/s; offload_time: 1.1451 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,845] LMCache INFO:[0m Storing KV cache for 406 out of 406 tokens (skip_leading_tokens=0) for request chatcmpl-fa5520ef41224778a45bea585fd0642e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,846] LMCache INFO:[0m Stored 406 out of total 406 tokens. size: 0.0496 gb, cost 1.1815 ms, throughput: 41.9484 GB/s; offload_time: 1.1756 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,846] LMCache INFO:[0m Storing KV cache for 406 out of 406 tokens (skip_leading_tokens=0) for request chatcmpl-0caea17429424beb9038b3b4719311ec [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,848] LMCache INFO:[0m Stored 406 out of total 406 tokens. size: 0.0496 gb, cost 1.1566 ms, throughput: 42.8485 GB/s; offload_time: 1.1503 ms, put_time: 0.0063 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,848] LMCache INFO:[0m Storing KV cache for 394 out of 394 tokens (skip_leading_tokens=0) for request chatcmpl-e725bc5693d648ac82e6b6b12b04bafb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,849] LMCache INFO:[0m Stored 394 out of total 394 tokens. size: 0.0481 gb, cost 1.1406 ms, throughput: 42.1653 GB/s; offload_time: 1.1341 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,849] LMCache INFO:[0m Storing KV cache for 412 out of 412 tokens (skip_leading_tokens=0) for request chatcmpl-928c028b7e044f249589ee205fab297d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,850] LMCache INFO:[0m Stored 412 out of total 412 tokens. size: 0.0503 gb, cost 1.1676 ms, throughput: 43.0755 GB/s; offload_time: 1.1614 ms, put_time: 0.0061 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,850] LMCache INFO:[0m Storing KV cache for 387 out of 387 tokens (skip_leading_tokens=0) for request chatcmpl-1553300ac651437185c50b6a47696530 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,851] LMCache INFO:[0m Stored 387 out of total 387 tokens. size: 0.0472 gb, cost 1.0967 ms, throughput: 43.0751 GB/s; offload_time: 1.0910 ms, put_time: 0.0057 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,851] LMCache INFO:[0m Storing KV cache for 403 out of 403 tokens (skip_leading_tokens=0) for request chatcmpl-00882f5ad8d142499d61d9335f84f20d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,853] LMCache INFO:[0m Stored 403 out of total 403 tokens. size: 0.0492 gb, cost 1.1239 ms, throughput: 43.7714 GB/s; offload_time: 1.1183 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,853] LMCache INFO:[0m Storing KV cache for 392 out of 392 tokens (skip_leading_tokens=0) for request chatcmpl-b94bf30ae3b14be582e0012aeb9fd189 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,854] LMCache INFO:[0m Stored 392 out of total 392 tokens. size: 0.0479 gb, cost 1.1184 ms, throughput: 42.7862 GB/s; offload_time: 1.1128 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,854] LMCache INFO:[0m Storing KV cache for 256 out of 256 tokens (skip_leading_tokens=0) for request chatcmpl-0f85f83d7f564cae849785d4c88d7832 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,855] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.7314 ms, throughput: 42.7239 GB/s; offload_time: 0.7264 ms, put_time: 0.0050 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,855] LMCache INFO:[0m Storing KV cache for 392 out of 392 tokens (skip_leading_tokens=0) for request chatcmpl-5e8f9e9610b943f483b29bccb077b2d0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,856] LMCache INFO:[0m Stored 392 out of total 392 tokens. size: 0.0479 gb, cost 1.1280 ms, throughput: 42.4222 GB/s; offload_time: 1.1224 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,863] LMCache INFO:[0m Reqid: chatcmpl-4f8d4427a38f49acaac6103629dfe2ef, Total tokens 395, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,864] LMCache INFO:[0m Reqid: chatcmpl-150dbec1585f4aaebcdccdad825873da, Total tokens 408, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,865] LMCache INFO:[0m Reqid: chatcmpl-05fb02ab0d164fdaa9d68141fd9a4956, Total tokens 402, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,867] LMCache INFO:[0m Reqid: chatcmpl-81a406c726404100b2213fdb1a1314e3, Total tokens 400, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,868] LMCache INFO:[0m Reqid: chatcmpl-bbb5efb6c9f74f548e0d6be23a348791, Total tokens 396, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,869] LMCache INFO:[0m Reqid: chatcmpl-09fd12bb229c452aa193b8bd8298d0c3, Total tokens 413, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,870] LMCache INFO:[0m Reqid: chatcmpl-61bba815061340ada4fa4dbd33745104, Total tokens 402, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,871] LMCache INFO:[0m Reqid: chatcmpl-948ab540f73b4ea980aa7511d66f2a5c, Total tokens 410, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,872] LMCache INFO:[0m Reqid: chatcmpl-8979ac6a088d4d1494e66770cdb8c9fc, Total tokens 393, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,873] LMCache INFO:[0m Reqid: chatcmpl-e8a09b139d504fe18d3e3f0c0e99c9b2, Total tokens 400, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,874] LMCache INFO:[0m Reqid: chatcmpl-437b223eb86345a7ab1ec4b408676e06, Total tokens 415, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,875] LMCache INFO:[0m Reqid: chatcmpl-35bd3b81a910430aa4dce575805c68db, Total tokens 405, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,876] LMCache INFO:[0m Reqid: chatcmpl-8c9d79f6dc9345568b51726e9babe1cb, Total tokens 394, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,877] LMCache INFO:[0m Reqid: chatcmpl-f7cb720ca25c4ddab212bedf98f84281, Total tokens 396, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,878] LMCache INFO:[0m Reqid: chatcmpl-ffb82578e4d14892b3a1e7e8eee8c5b1, Total tokens 393, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,879] LMCache INFO:[0m Reqid: chatcmpl-3de07436a3ce455fa4ecd8acfdd6839a, Total tokens 366, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,880] LMCache INFO:[0m Reqid: chatcmpl-89c4ea6d4c5c41f39ce881fb00374414, Total tokens 401, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,881] LMCache INFO:[0m Reqid: chatcmpl-612c5851d73d4b01afcd403866acf20b, Total tokens 413, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,882] LMCache INFO:[0m Reqid: chatcmpl-b105d2f640084d4182ad53a761477631, Total tokens 399, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,884] LMCache INFO:[0m Reqid: chatcmpl-961a86f8b1634721b3358ae0a23e6817, Total tokens 383, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:00,885] LMCache INFO:[0m Reqid: chatcmpl-4c4e5e757fd1408096cd50d15b3ce3a0, Total tokens 381, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,012] LMCache INFO:[0m Storing KV cache for 395 out of 395 tokens (skip_leading_tokens=0) for request chatcmpl-4f8d4427a38f49acaac6103629dfe2ef [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,013] LMCache INFO:[0m Stored 395 out of total 395 tokens. size: 0.0482 gb, cost 1.1915 ms, throughput: 40.4674 GB/s; offload_time: 1.1814 ms, put_time: 0.0101 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,013] LMCache INFO:[0m Storing KV cache for 408 out of 408 tokens (skip_leading_tokens=0) for request chatcmpl-150dbec1585f4aaebcdccdad825873da [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,015] LMCache INFO:[0m Stored 408 out of total 408 tokens. size: 0.0498 gb, cost 1.1841 ms, throughput: 42.0622 GB/s; offload_time: 1.1764 ms, put_time: 0.0076 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,015] LMCache INFO:[0m Storing KV cache for 402 out of 402 tokens (skip_leading_tokens=0) for request chatcmpl-05fb02ab0d164fdaa9d68141fd9a4956 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,016] LMCache INFO:[0m Stored 402 out of total 402 tokens. size: 0.0491 gb, cost 1.1364 ms, throughput: 43.1832 GB/s; offload_time: 1.1298 ms, put_time: 0.0066 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,016] LMCache INFO:[0m Storing KV cache for 400 out of 400 tokens (skip_leading_tokens=0) for request chatcmpl-81a406c726404100b2213fdb1a1314e3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,017] LMCache INFO:[0m Stored 400 out of total 400 tokens. size: 0.0488 gb, cost 1.1384 ms, throughput: 42.8919 GB/s; offload_time: 1.1316 ms, put_time: 0.0068 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,017] LMCache INFO:[0m Storing KV cache for 396 out of 396 tokens (skip_leading_tokens=0) for request chatcmpl-bbb5efb6c9f74f548e0d6be23a348791 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,018] LMCache INFO:[0m Stored 396 out of total 396 tokens. size: 0.0483 gb, cost 1.1171 ms, throughput: 43.2741 GB/s; offload_time: 1.1100 ms, put_time: 0.0070 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,018] LMCache INFO:[0m Storing KV cache for 413 out of 413 tokens (skip_leading_tokens=0) for request chatcmpl-09fd12bb229c452aa193b8bd8298d0c3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,020] LMCache INFO:[0m Stored 413 out of total 413 tokens. size: 0.0504 gb, cost 1.1952 ms, throughput: 42.1830 GB/s; offload_time: 1.1882 ms, put_time: 0.0069 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,020] LMCache INFO:[0m Storing KV cache for 402 out of 402 tokens (skip_leading_tokens=0) for request chatcmpl-61bba815061340ada4fa4dbd33745104 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,021] LMCache INFO:[0m Stored 402 out of total 402 tokens. size: 0.0491 gb, cost 1.1434 ms, throughput: 42.9173 GB/s; offload_time: 1.1363 ms, put_time: 0.0071 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,021] LMCache INFO:[0m Storing KV cache for 410 out of 410 tokens (skip_leading_tokens=0) for request chatcmpl-948ab540f73b4ea980aa7511d66f2a5c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,022] LMCache INFO:[0m Stored 410 out of total 410 tokens. size: 0.0500 gb, cost 1.1766 ms, throughput: 42.5366 GB/s; offload_time: 1.1702 ms, put_time: 0.0064 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,022] LMCache INFO:[0m Storing KV cache for 393 out of 393 tokens (skip_leading_tokens=0) for request chatcmpl-8979ac6a088d4d1494e66770cdb8c9fc [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,023] LMCache INFO:[0m Stored 393 out of total 393 tokens. size: 0.0480 gb, cost 1.1248 ms, throughput: 42.6525 GB/s; offload_time: 1.1181 ms, put_time: 0.0067 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,024] LMCache INFO:[0m Storing KV cache for 400 out of 400 tokens (skip_leading_tokens=0) for request chatcmpl-e8a09b139d504fe18d3e3f0c0e99c9b2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,025] LMCache INFO:[0m Stored 400 out of total 400 tokens. size: 0.0488 gb, cost 1.1477 ms, throughput: 42.5437 GB/s; offload_time: 1.1418 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,025] LMCache INFO:[0m Storing KV cache for 415 out of 415 tokens (skip_leading_tokens=0) for request chatcmpl-437b223eb86345a7ab1ec4b408676e06 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,026] LMCache INFO:[0m Stored 415 out of total 415 tokens. size: 0.0507 gb, cost 1.1649 ms, throughput: 43.4884 GB/s; offload_time: 1.1586 ms, put_time: 0.0062 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,026] LMCache INFO:[0m Storing KV cache for 405 out of 405 tokens (skip_leading_tokens=0) for request chatcmpl-35bd3b81a910430aa4dce575805c68db [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,027] LMCache INFO:[0m Stored 405 out of total 405 tokens. size: 0.0494 gb, cost 1.1525 ms, throughput: 42.8968 GB/s; offload_time: 1.1460 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,027] LMCache INFO:[0m Storing KV cache for 394 out of 394 tokens (skip_leading_tokens=0) for request chatcmpl-8c9d79f6dc9345568b51726e9babe1cb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,029] LMCache INFO:[0m Stored 394 out of total 394 tokens. size: 0.0481 gb, cost 1.1403 ms, throughput: 42.1799 GB/s; offload_time: 1.1341 ms, put_time: 0.0061 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,029] LMCache INFO:[0m Storing KV cache for 396 out of 396 tokens (skip_leading_tokens=0) for request chatcmpl-f7cb720ca25c4ddab212bedf98f84281 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,030] LMCache INFO:[0m Stored 396 out of total 396 tokens. size: 0.0483 gb, cost 1.0948 ms, throughput: 44.1533 GB/s; offload_time: 1.0890 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,030] LMCache INFO:[0m Storing KV cache for 393 out of 393 tokens (skip_leading_tokens=0) for request chatcmpl-ffb82578e4d14892b3a1e7e8eee8c5b1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,031] LMCache INFO:[0m Stored 393 out of total 393 tokens. size: 0.0480 gb, cost 1.0951 ms, throughput: 43.8056 GB/s; offload_time: 1.0897 ms, put_time: 0.0054 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,031] LMCache INFO:[0m Storing KV cache for 366 out of 366 tokens (skip_leading_tokens=0) for request chatcmpl-3de07436a3ce455fa4ecd8acfdd6839a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,032] LMCache INFO:[0m Stored 366 out of total 366 tokens. size: 0.0447 gb, cost 1.0423 ms, throughput: 42.8626 GB/s; offload_time: 1.0357 ms, put_time: 0.0066 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,032] LMCache INFO:[0m Storing KV cache for 401 out of 401 tokens (skip_leading_tokens=0) for request chatcmpl-89c4ea6d4c5c41f39ce881fb00374414 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,033] LMCache INFO:[0m Stored 401 out of total 401 tokens. size: 0.0490 gb, cost 1.1291 ms, throughput: 43.3545 GB/s; offload_time: 1.1230 ms, put_time: 0.0060 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,033] LMCache INFO:[0m Storing KV cache for 413 out of 413 tokens (skip_leading_tokens=0) for request chatcmpl-612c5851d73d4b01afcd403866acf20b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,035] LMCache INFO:[0m Stored 413 out of total 413 tokens. size: 0.0504 gb, cost 1.1386 ms, throughput: 44.2771 GB/s; offload_time: 1.1328 ms, put_time: 0.0058 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,035] LMCache INFO:[0m Storing KV cache for 399 out of 399 tokens (skip_leading_tokens=0) for request chatcmpl-b105d2f640084d4182ad53a761477631 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,036] LMCache INFO:[0m Stored 399 out of total 399 tokens. size: 0.0487 gb, cost 1.1263 ms, throughput: 43.2438 GB/s; offload_time: 1.1151 ms, put_time: 0.0112 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,036] LMCache INFO:[0m Storing KV cache for 383 out of 383 tokens (skip_leading_tokens=0) for request chatcmpl-961a86f8b1634721b3358ae0a23e6817 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,037] LMCache INFO:[0m Stored 383 out of total 383 tokens. size: 0.0468 gb, cost 1.0792 ms, throughput: 43.3201 GB/s; offload_time: 1.0731 ms, put_time: 0.0062 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,037] LMCache INFO:[0m Storing KV cache for 256 out of 256 tokens (skip_leading_tokens=0) for request chatcmpl-4c4e5e757fd1408096cd50d15b3ce3a0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,038] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.6943 ms, throughput: 45.0102 GB/s; offload_time: 0.6895 ms, put_time: 0.0048 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,046] LMCache INFO:[0m Reqid: chatcmpl-571c806a26764d87a009b00653f49da4, Total tokens 383, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,047] LMCache INFO:[0m Reqid: chatcmpl-c3519e7112614423a8943a84abda738c, Total tokens 389, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,048] LMCache INFO:[0m Reqid: chatcmpl-32ac340dbe104c3eb434d1b56876a35e, Total tokens 403, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,049] LMCache INFO:[0m Reqid: chatcmpl-ce6ea685353546edb89dfac47be285fe, Total tokens 389, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,050] LMCache INFO:[0m Reqid: chatcmpl-cbd5a2b393d04b3ab36e14a5280e8b3e, Total tokens 414, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,051] LMCache INFO:[0m Reqid: chatcmpl-e780ba11bbcf4c3d9fb83feb7e6ec4e8, Total tokens 404, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,052] LMCache INFO:[0m Reqid: chatcmpl-8ba19537f4534a889809af3e2c7d8a14, Total tokens 393, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,053] LMCache INFO:[0m Reqid: chatcmpl-a18b87cadcbf4d6a9f6cc28063fd1e27, Total tokens 406, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,054] LMCache INFO:[0m Reqid: chatcmpl-f24c0c7177544ef4993887efbaefe0e1, Total tokens 383, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,055] LMCache INFO:[0m Reqid: chatcmpl-953ced9f7317479c809c0f21c5c3633a, Total tokens 388, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,056] LMCache INFO:[0m Reqid: chatcmpl-9f1d3b4bc43049dfb1afb3cf5d1e3280, Total tokens 409, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,057] LMCache INFO:[0m Reqid: chatcmpl-0d2b41f203d34cc283bb5a9fe513e239, Total tokens 400, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,058] LMCache INFO:[0m Reqid: chatcmpl-923059e18ecd448ca96ff29461459329, Total tokens 404, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,153] LMCache INFO:[0m Storing KV cache for 383 out of 383 tokens (skip_leading_tokens=0) for request chatcmpl-571c806a26764d87a009b00653f49da4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,154] LMCache INFO:[0m Stored 383 out of total 383 tokens. size: 0.0468 gb, cost 1.1373 ms, throughput: 41.1081 GB/s; offload_time: 1.1277 ms, put_time: 0.0096 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,155] LMCache INFO:[0m Storing KV cache for 389 out of 389 tokens (skip_leading_tokens=0) for request chatcmpl-c3519e7112614423a8943a84abda738c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,156] LMCache INFO:[0m Stored 389 out of total 389 tokens. size: 0.0475 gb, cost 1.1292 ms, throughput: 42.0506 GB/s; offload_time: 1.1222 ms, put_time: 0.0071 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,156] LMCache INFO:[0m Storing KV cache for 403 out of 403 tokens (skip_leading_tokens=0) for request chatcmpl-32ac340dbe104c3eb434d1b56876a35e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,157] LMCache INFO:[0m Stored 403 out of total 403 tokens. size: 0.0492 gb, cost 1.1489 ms, throughput: 42.8180 GB/s; offload_time: 1.1420 ms, put_time: 0.0069 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,157] LMCache INFO:[0m Storing KV cache for 389 out of 389 tokens (skip_leading_tokens=0) for request chatcmpl-ce6ea685353546edb89dfac47be285fe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,158] LMCache INFO:[0m Stored 389 out of total 389 tokens. size: 0.0475 gb, cost 1.1161 ms, throughput: 42.5467 GB/s; offload_time: 1.1096 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,158] LMCache INFO:[0m Storing KV cache for 414 out of 414 tokens (skip_leading_tokens=0) for request chatcmpl-cbd5a2b393d04b3ab36e14a5280e8b3e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,160] LMCache INFO:[0m Stored 414 out of total 414 tokens. size: 0.0505 gb, cost 1.1953 ms, throughput: 42.2800 GB/s; offload_time: 1.1892 ms, put_time: 0.0061 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,160] LMCache INFO:[0m Storing KV cache for 404 out of 404 tokens (skip_leading_tokens=0) for request chatcmpl-e780ba11bbcf4c3d9fb83feb7e6ec4e8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,161] LMCache INFO:[0m Stored 404 out of total 404 tokens. size: 0.0493 gb, cost 1.1507 ms, throughput: 42.8560 GB/s; offload_time: 1.1443 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,161] LMCache INFO:[0m Storing KV cache for 393 out of 393 tokens (skip_leading_tokens=0) for request chatcmpl-8ba19537f4534a889809af3e2c7d8a14 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,162] LMCache INFO:[0m Stored 393 out of total 393 tokens. size: 0.0480 gb, cost 1.1333 ms, throughput: 42.3311 GB/s; offload_time: 1.1268 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,162] LMCache INFO:[0m Storing KV cache for 406 out of 406 tokens (skip_leading_tokens=0) for request chatcmpl-a18b87cadcbf4d6a9f6cc28063fd1e27 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,163] LMCache INFO:[0m Stored 406 out of total 406 tokens. size: 0.0496 gb, cost 1.1527 ms, throughput: 42.9934 GB/s; offload_time: 1.1467 ms, put_time: 0.0060 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,163] LMCache INFO:[0m Storing KV cache for 383 out of 383 tokens (skip_leading_tokens=0) for request chatcmpl-f24c0c7177544ef4993887efbaefe0e1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,165] LMCache INFO:[0m Stored 383 out of total 383 tokens. size: 0.0468 gb, cost 1.0815 ms, throughput: 43.2315 GB/s; offload_time: 1.0756 ms, put_time: 0.0059 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,165] LMCache INFO:[0m Storing KV cache for 388 out of 388 tokens (skip_leading_tokens=0) for request chatcmpl-953ced9f7317479c809c0f21c5c3633a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,166] LMCache INFO:[0m Stored 388 out of total 388 tokens. size: 0.0474 gb, cost 1.1034 ms, throughput: 42.9266 GB/s; offload_time: 1.0971 ms, put_time: 0.0063 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,166] LMCache INFO:[0m Storing KV cache for 409 out of 409 tokens (skip_leading_tokens=0) for request chatcmpl-9f1d3b4bc43049dfb1afb3cf5d1e3280 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,167] LMCache INFO:[0m Stored 409 out of total 409 tokens. size: 0.0499 gb, cost 1.1476 ms, throughput: 43.5068 GB/s; offload_time: 1.1419 ms, put_time: 0.0056 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,167] LMCache INFO:[0m Storing KV cache for 400 out of 400 tokens (skip_leading_tokens=0) for request chatcmpl-0d2b41f203d34cc283bb5a9fe513e239 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,168] LMCache INFO:[0m Stored 400 out of total 400 tokens. size: 0.0488 gb, cost 1.1185 ms, throughput: 43.6531 GB/s; offload_time: 1.1125 ms, put_time: 0.0060 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,168] LMCache INFO:[0m Storing KV cache for 404 out of 404 tokens (skip_leading_tokens=0) for request chatcmpl-923059e18ecd448ca96ff29461459329 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:01,169] LMCache INFO:[0m Stored 404 out of total 404 tokens. size: 0.0493 gb, cost 1.1505 ms, throughput: 42.8640 GB/s; offload_time: 1.1441 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207001.4612336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 53739520
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 388
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 136: 0.0016682942708333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 136: 40002
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 136: 1.8830395609999389
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 136: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 111, time is 1761207001.6836948
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 57409536
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 111: 0.0017822265625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 111: 39614
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 111: 1.8524206209763612
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 111: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 140, time is 1761207001.6839843
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 59506688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 410
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 140: 0.0018473307291666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 140: 39614
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 140: 1.8524206209763612
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 140: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 166, time is 1761207001.6946766
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 60030976
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 166: 0.0018636067708333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 166: 38812
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 166: 1.789886810646437
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 166: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 144, time is 1761207001.6949
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 60030976
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 413
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 144: 0.0018636067708333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 144: 38812
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 144: 1.789886810646437
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 144: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 127, time is 1761207001.705419
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 56229888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 380
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 127: 0.00174560546875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 127: 37987
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 127: 1.7266226979418144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 127: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207001.9048262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 58851328
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 381
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 97: 0.0018269856770833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 97: 37607
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 97: 1.6978455140053303
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 97: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 90, time is 1761207001.9050517
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 59375616
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 90: 0.00184326171875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 90: 37607
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 90: 1.6978455140053303
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 90: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207001.947098
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 61079552
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 173: 0.0018961588541666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 173: 36841
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 173: 1.640532002225001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 173: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 128, time is 1761207001.947287
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 59768832
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 128: 0.00185546875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 128: 36841
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 128: 1.640532002225001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 128: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 124, time is 1761207001.9474032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 58195968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 373
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 124: 0.001806640625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 124: 36841
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 124: 1.640532002225001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 124: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207001.9475799
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 61341696
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 399
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 164: 0.001904296875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 164: 36841
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 164: 1.640532002225001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 164: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207001.9476805
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 58851328
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 381
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 133: 0.0018269856770833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 133: 36841
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 133: 1.640532002225001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 133: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 76, time is 1761207001.9680371
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 62652416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 405
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 76: 0.0019449869791666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 76: 34908
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 76: 1.500033346510501
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 76: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 168, time is 1761207001.9682226
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 61210624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 394
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 168: 0.0019002278645833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 168: 34908
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 168: 1.500033346510501
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 168: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207001.9785051
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 62128128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 402
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 102: 0.0019287109375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 102: 34109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 102: 1.443687428626621
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 102: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [estimate_with_func.py:328] Request job id finishing: 114, time is 1761207001.9888182
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1462] Request GPU size bytes: 62390272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1463] Token size of the request: 404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1469] Swap waste for job 114: 0.0019368489583333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1479] Accumulated tokens for job 114: 33707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1481] Discard waste for job 114: 1.4157205401117103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:01 [scheduler.py:1484] Preserve waste for job 114: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207002.0288422
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 61997056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 396
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 7: 0.0019246419270833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 7: 33303
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 7: 1.3878724020739224
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 7: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 91, time is 1761207002.1773903
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 65667072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 91: 0.00203857421875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 91: 32907
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 91: 1.3608266130670703
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 91: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 162, time is 1761207002.1973617
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 63832064
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 390
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 162: 0.0019816080729166668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 162: 32499
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 162: 1.3332210510214848
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 162: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 30, time is 1761207002.1975899
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 65404928
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 402
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 30: 0.0020304361979166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 30: 32499
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 30: 1.3332210510214848
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 30: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 157, time is 1761207002.207434
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 62390272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 378
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 157: 0.0019368489583333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 157: 31707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 157: 1.2803864857801104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 157: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 117, time is 1761207002.2076442
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 63700992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 389
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 117: 0.0019775390625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 117: 31707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 117: 1.2803864857801104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 117: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 106, time is 1761207002.2174253
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 65011712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 106: 0.002018229166666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 106: 30940
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 106: 1.2301666963609201
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 106: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 146, time is 1761207002.2271402
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 65011712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 398
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 146: 0.002018229166666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 146: 30540
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 146: 1.2043461526185202
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 146: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 29, time is 1761207002.2370417
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 66977792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 29: 0.002079264322916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 29: 30142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 29: 1.178906249103491
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 29: 0.0
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '90', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:307] Request job id arriving: 90, time is 1761207002.2468407
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:315] Request job id: 90
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,248] LMCache INFO:[0m Reqid: chatcmpl-2731a0e5e03e4a759e4df8d990d0cf51, Total tokens 1137, LMCache hit tokens: 256, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,276] LMCache INFO:[0m Storing KV cache for 881 out of 1137 tokens (skip_leading_tokens=256) for request chatcmpl-2731a0e5e03e4a759e4df8d990d0cf51 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,278] LMCache INFO:[0m Stored 881 out of total 881 tokens. size: 0.1075 gb, cost 2.4117 ms, throughput: 44.5920 GB/s; offload_time: 2.4005 ms, put_time: 0.0113 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 25, time is 1761207002.2808979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 62652416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 377
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 25: 0.0019449869791666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 25: 30865
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 25: 1.2253060397821576
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 25: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 36, time is 1761207002.4362674
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 67108864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 393
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 36: 0.0020833333333333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 36: 30488
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 36: 1.2010080967403969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 36: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 98, time is 1761207002.4560816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 67895296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 398
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 98: 0.0021077473958333332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 98: 30095
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 98: 1.1759186037519176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 98: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 50, time is 1761207002.4660742
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 68812800
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 50: 0.00213623046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 50: 29697
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 50: 1.1507592370573223
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 50: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 121, time is 1761207002.4662943
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 68026368
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 398
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 121: 0.00211181640625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 121: 29697
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 121: 1.1507592370573223
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 121: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 39, time is 1761207002.4764063
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 65667072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 379
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 39: 0.00203857421875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 39: 28895
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 39: 1.1008234228083178
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 39: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 126, time is 1761207002.4766054
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 69074944
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 405
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 126: 0.0021443684895833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 126: 28895
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 126: 1.1008234228083178
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 126: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 2, time is 1761207002.4767923
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 65798144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 383
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 2: 0.0020426432291666668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 2: 28895
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 2: 1.1008234228083178
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 2: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 129, time is 1761207002.4864793
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 65929216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 381
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 129: 0.0020467122395833332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 129: 27728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 129: 1.029981049965645
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 129: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 6, time is 1761207002.5058718
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 68681728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 401
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 6: 0.002132161458333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 6: 27347
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 6: 1.0073196662743424
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 6: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 131, time is 1761207002.53465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 67764224
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 390
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 131: 0.0021036783854166668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 131: 26946
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 131: 0.9837170607821851
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 131: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207002.5348895
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 69206016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 402
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 174: 0.0021484375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 174: 26946
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 174: 0.9837170607821851
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 174: 0.34186291694641113
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '91', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207002.5453448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 67502080
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 389
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 138: 0.0020955403645833335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 138: 26154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 138: 0.9378487549467452
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 138: 0.34186291694641113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:307] Request job id arriving: 91, time is 1761207002.5455768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:315] Request job id: 91
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,547] LMCache INFO:[0m Reqid: chatcmpl-956152292f9144edb8bba6fbb53cd823, Total tokens 1199, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,569] LMCache INFO:[0m Storing KV cache for 943 out of 1199 tokens (skip_leading_tokens=256) for request chatcmpl-956152292f9144edb8bba6fbb53cd823 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,571] LMCache INFO:[0m Stored 943 out of total 943 tokens. size: 0.1151 gb, cost 2.5671 ms, throughput: 44.8417 GB/s; offload_time: 2.5561 ms, put_time: 0.0109 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 90, time is 1761207002.6956487
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 154533888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 1137
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 90: 0.00479736328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 90: 26964
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 90: 0.9847710694153712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 90: 0.3550148010253906
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '98', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:307] Request job id arriving: 98, time is 1761207002.7145052
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:315] Request job id: 98
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,716] LMCache INFO:[0m Reqid: chatcmpl-b3e1e2547f524fe9ac72e06892e29131, Total tokens 1227, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,736] LMCache INFO:[0m Storing KV cache for 971 out of 1227 tokens (skip_leading_tokens=256) for request chatcmpl-b3e1e2547f524fe9ac72e06892e29131 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,738] LMCache INFO:[0m Stored 971 out of total 971 tokens. size: 0.1185 gb, cost 2.6487 ms, throughput: 44.7496 GB/s; offload_time: 2.6336 ms, put_time: 0.0151 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 99, time is 1761207002.7408583
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 74842112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 424
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 99: 0.002323404947916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 99: 27054
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 99: 0.9900488106725852
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 99: 0.32282741864522296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 123, time is 1761207002.7410898
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 70516736
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 393
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 123: 0.0021891276041666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 123: 27054
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 123: 0.9900488106725852
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 123: 0.32282741864522296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 3, time is 1761207002.760912
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 70647808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 3: 0.002193196614583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 3: 26237
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 3: 0.9426090548114142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 3: 0.32282741864522296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 94, time is 1761207002.7611036
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 72613888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 94: 0.002254231770833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 94: 26237
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 94: 0.9426090548114142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 94: 0.32282741864522296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 8, time is 1761207002.77095
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 91, time is 1761207002.771079
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 159776768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 1199
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 91: 0.004960123697916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 91: 25437
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 91: 0.8971809289011744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 91: 0.0
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '2', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 77, time is 1761207002.7897723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 72876032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 406
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 77: 0.002262369791666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 77: 23842
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 77: 0.8096340042212508
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 77: 0.32282741864522296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 19, time is 1761207002.7900298
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 72613888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 406
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 19: 0.002254231770833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 19: 23842
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 19: 0.8096340042212508
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 19: 0.32282741864522296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:307] Request job id arriving: 2, time is 1761207002.790179
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:315] Request job id: 2
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,791] LMCache INFO:[0m Reqid: chatcmpl-850ab8acf0a245f8a76b22ffe61f0b2f, Total tokens 1093, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,815] LMCache INFO:[0m Storing KV cache for 837 out of 1093 tokens (skip_leading_tokens=256) for request chatcmpl-850ab8acf0a245f8a76b22ffe61f0b2f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:02,817] LMCache INFO:[0m Stored 837 out of total 837 tokens. size: 0.1022 gb, cost 2.3076 ms, throughput: 44.2771 GB/s; offload_time: 2.2965 ms, put_time: 0.0111 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207002.8200338
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 71434240
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 68: 0.0022176106770833335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 68: 24123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 68: 0.8247652040253263
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 68: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 148, time is 1761207002.829312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 69861376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 383
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 148: 0.0021687825520833332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 148: 23728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 148: 0.8035310310728448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 148: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 110, time is 1761207002.8384962
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 72613888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 110: 0.002254231770833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 110: 23345
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 110: 0.7831779377679174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 110: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [estimate_with_func.py:328] Request job id finishing: 2, time is 1761207002.9890487
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1462] Request GPU size bytes: 145883136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1463] Token size of the request: 1093
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1469] Swap waste for job 2: 0.00452880859375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1479] Accumulated tokens for job 2: 22942
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1481] Discard waste for job 2: 0.7620128872369308
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:02 [scheduler.py:1484] Preserve waste for job 2: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 23, time is 1761207003.0068252
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 73269248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 23: 0.0022745768229166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 23: 21849
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 23: 0.7059049053563448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 23: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 15, time is 1761207003.015834
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 75628544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 15: 0.0023478190104166668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 15: 21463
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 15: 0.6865421489643543
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 15: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 24, time is 1761207003.0160222
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 76546048
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 410
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 24: 0.002376302083333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 24: 21463
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 24: 0.6865421489643543
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 24: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 93, time is 1761207003.0248997
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 73138176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 383
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 93: 0.0022705078125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 93: 20650
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 93: 0.64653198673575
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 93: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 101, time is 1761207003.0251057
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 73531392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 387
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 101: 0.00228271484375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 101: 20650
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 101: 0.64653198673575
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 101: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 83, time is 1761207003.0339408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 77201408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 415
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 83: 0.0023966471354166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 83: 19880
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 83: 0.60960334121968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 83: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207003.0427673
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 77070336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 156: 0.002392578125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 156: 19465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 156: 0.5900897183407575
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 156: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207003.0429657
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 72482816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 377
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 122: 0.0022501627604166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 122: 19465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 122: 0.5900897183407575
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 122: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207003.0430973
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 77070336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 413
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 150: 0.002392578125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 150: 19465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 150: 0.5900897183407575
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 150: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 104, time is 1761207003.0602021
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 76546048
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 406
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 104: 0.002376302083333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 104: 18263
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 104: 0.5351100715493143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 104: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 98, time is 1761207003.1112478
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 166068224
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 1227
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 98: 0.005155436197916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 98: 17857
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 98: 0.5170566208395303
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 98: 0.0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 120, time is 1761207003.2006354
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 160, time is 1761207003.2168217
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 77856768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 160: 0.0024169921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 160: 16236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 160: 0.44757849507425124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 160: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 105, time is 1761207003.2170272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 79429632
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 407
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 105: 0.0024658203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 105: 16236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 105: 0.44757849507425124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 105: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 112, time is 1761207003.217178
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 78381056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 112: 0.0024332682291666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 112: 16236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 112: 0.44757849507425124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 112: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 95, time is 1761207003.2253578
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 134, time is 1761207003.2254543
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 79167488
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 406
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 134: 0.0024576822916666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 134: 15034
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 134: 0.39874664218831324
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 134: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 142, time is 1761207003.2330053
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 79953920
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 410
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 142: 0.0024820963541666665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 142: 14239
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 142: 0.3677067352304487
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 142: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207003.2332194
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 79036416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 405
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 79: 0.00245361328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 79: 14239
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 79: 0.3677067352304487
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 79: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 103, time is 1761207003.2333462
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 73924608
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 366
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 103: 0.002294921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 103: 14239
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 103: 0.3677067352304487
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 103: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207003.2481935
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 79036416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 44: 0.00245361328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 44: 13058
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 44: 0.32344409958413084
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 44: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207003.2559187
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 79953920
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 406
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 5: 0.0024820963541666665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 5: 12654
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 5: 0.3088097447391452
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 5: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 165, time is 1761207003.27843
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 77594624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 389
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 165: 0.0024088541666666668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 165: 12248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 165: 0.2943633946813888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 165: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 35, time is 1761207003.4110606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 82444288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 35: 0.002559407552083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 35: 11859
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 35: 0.2807668662830207
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 35: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 108, time is 1761207003.5036235
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207003.57999
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 84410368
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 397
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 16: 0.002620442708333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 16: 11046
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 16: 0.2531244194960252
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 16: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 1, time is 1761207003.6030288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 84934656
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 397
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 1: 0.00263671875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 1: 10649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 1: 0.24000664701362473
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 1: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 17, time is 1761207003.6108253
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 83361792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 17: 0.002587890625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 17: 10252
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 17: 0.2271385223643888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 17: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 81, time is 1761207003.626059
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 85065728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 399
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 81: 0.0026407877604166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 81: 9867
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 81: 0.2148978014953583
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 81: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 78, time is 1761207003.6262598
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 84410368
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 394
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 78: 0.002620442708333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 78: 9867
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 78: 0.2148978014953583
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 78: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 92, time is 1761207003.6475384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 86114304
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 92: 0.00267333984375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 92: 9074
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 92: 0.19042493158861723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 92: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 171, time is 1761207003.647735
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 85458944
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 171: 0.0026529947916666668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 171: 9074
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 171: 0.19042493158861723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 171: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 89, time is 1761207003.7738702
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 88735744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 402
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 89: 0.0027547200520833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 89: 8271
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 89: 0.1666584485475527
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 89: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 143, time is 1761207003.7810838
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 87687168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 394
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 143: 0.00272216796875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 143: 7869
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 143: 0.1551440537782367
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 143: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207003.7882156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 88473600
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 399
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 10: 0.00274658203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 10: 7475
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 10: 0.1441071866029375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 10: 0.3204716444015503
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '91', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 149, time is 1761207003.7951818
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 88473600
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 398
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 149: 0.00274658203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 149: 7076
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 149: 0.1331808471644272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 149: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:307] Request job id arriving: 91, time is 1761207003.7954476
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:315] Request job id: 91
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:03,797] LMCache INFO:[0m Reqid: chatcmpl-39e3d1dd68aa4169bedd8b68eab688f1, Total tokens 10542, LMCache hit tokens: 1024, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '2', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:03,976] LMCache INFO:[0m Storing KV cache for 8192 out of 9216 tokens (skip_leading_tokens=1024) for request chatcmpl-39e3d1dd68aa4169bedd8b68eab688f1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:03,997] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.2528 ms, throughput: 47.0526 GB/s; offload_time: 21.2138 ms, put_time: 0.0390 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:328] Request job id finishing: 169, time is 1761207003.9991307
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1462] Request GPU size bytes: 86900736
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1463] Token size of the request: 387
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1469] Swap waste for job 169: 0.00269775390625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1479] Accumulated tokens for job 169: 17220
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1481] Discard waste for job 169: 0.48925756671548
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [scheduler.py:1484] Preserve waste for job 169: 0.3204716444015503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:307] Request job id arriving: 2, time is 1761207003.9993796
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:315] Request job id: 2
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207003.9994361
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:03 [estimate_with_func.py:315] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,000] LMCache INFO:[0m Reqid: chatcmpl-b60e25b261d44096901f58211569bd50, Total tokens 10246, LMCache hit tokens: 1024, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '144', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '128', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '76', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '166', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '168', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,185] LMCache INFO:[0m Storing KV cache for 6912 out of 7936 tokens (skip_leading_tokens=1024) for request chatcmpl-b60e25b261d44096901f58211569bd50 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,203] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 17.8361 ms, throughput: 47.3056 GB/s; offload_time: 17.8049 ms, put_time: 0.0312 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,204] LMCache INFO:[0m Storing KV cache for 1326 out of 10542 tokens (skip_leading_tokens=9216) for request chatcmpl-39e3d1dd68aa4169bedd8b68eab688f1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,207] LMCache INFO:[0m Stored 1326 out of total 1326 tokens. size: 0.1619 gb, cost 3.6528 ms, throughput: 44.3121 GB/s; offload_time: 3.6406 ms, put_time: 0.0122 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 144, time is 1761207004.209387
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207004.2094927
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 128, time is 1761207004.2095377
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 76, time is 1761207004.2095761
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 76
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 166, time is 1761207004.2096143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 168, time is 1761207004.2096546
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,211] LMCache INFO:[0m Reqid: chatcmpl-c240bb9ee43f4646946290921cbdeceb, Total tokens 1064, LMCache hit tokens: 256, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,212] LMCache INFO:[0m Reqid: chatcmpl-2bedef574c9c4b308bde7013fe4e198b, Total tokens 1132, LMCache hit tokens: 256, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,214] LMCache INFO:[0m Reqid: chatcmpl-11ebf3b8efe24e86b022fbc4ba1387b2, Total tokens 1014, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,215] LMCache INFO:[0m Reqid: chatcmpl-c5cc7af5498b4c5abd065ba9db82cbb1, Total tokens 1129, LMCache hit tokens: 256, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,217] LMCache INFO:[0m Reqid: chatcmpl-f0bc98156b094542819220a7b3d7111e, Total tokens 1034, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,218] LMCache INFO:[0m Reqid: chatcmpl-f793946bf3374dbc9410dddf725b226a, Total tokens 1109, LMCache hit tokens: 256, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,219] LMCache INFO:[0m Reqid: chatcmpl-c1f35dc562564736a1b5e1e27b75f9f0, Total tokens 1175, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '127', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '98', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '25', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,355] LMCache INFO:[0m Storing KV cache for 808 out of 1064 tokens (skip_leading_tokens=256) for request chatcmpl-c240bb9ee43f4646946290921cbdeceb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,357] LMCache INFO:[0m Stored 808 out of total 808 tokens. size: 0.0986 gb, cost 2.3021 ms, throughput: 42.8450 GB/s; offload_time: 2.2893 ms, put_time: 0.0128 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,357] LMCache INFO:[0m Storing KV cache for 876 out of 1132 tokens (skip_leading_tokens=256) for request chatcmpl-2bedef574c9c4b308bde7013fe4e198b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,360] LMCache INFO:[0m Stored 876 out of total 876 tokens. size: 0.1069 gb, cost 2.3719 ms, throughput: 45.0828 GB/s; offload_time: 2.3619 ms, put_time: 0.0100 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,360] LMCache INFO:[0m Storing KV cache for 758 out of 1014 tokens (skip_leading_tokens=256) for request chatcmpl-11ebf3b8efe24e86b022fbc4ba1387b2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,362] LMCache INFO:[0m Stored 758 out of total 758 tokens. size: 0.0925 gb, cost 2.0414 ms, throughput: 45.3271 GB/s; offload_time: 2.0332 ms, put_time: 0.0081 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,362] LMCache INFO:[0m Storing KV cache for 873 out of 1129 tokens (skip_leading_tokens=256) for request chatcmpl-c5cc7af5498b4c5abd065ba9db82cbb1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,365] LMCache INFO:[0m Stored 873 out of total 873 tokens. size: 0.1066 gb, cost 2.3579 ms, throughput: 45.1962 GB/s; offload_time: 2.3485 ms, put_time: 0.0094 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,365] LMCache INFO:[0m Storing KV cache for 778 out of 1034 tokens (skip_leading_tokens=256) for request chatcmpl-f0bc98156b094542819220a7b3d7111e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,367] LMCache INFO:[0m Stored 778 out of total 778 tokens. size: 0.0950 gb, cost 2.3485 ms, throughput: 40.4380 GB/s; offload_time: 2.3375 ms, put_time: 0.0111 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,367] LMCache INFO:[0m Storing KV cache for 853 out of 1109 tokens (skip_leading_tokens=256) for request chatcmpl-f793946bf3374dbc9410dddf725b226a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,369] LMCache INFO:[0m Stored 853 out of total 853 tokens. size: 0.1041 gb, cost 2.2873 ms, throughput: 45.5235 GB/s; offload_time: 2.2788 ms, put_time: 0.0085 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,370] LMCache INFO:[0m Storing KV cache for 919 out of 1175 tokens (skip_leading_tokens=256) for request chatcmpl-c1f35dc562564736a1b5e1e27b75f9f0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,372] LMCache INFO:[0m Stored 919 out of total 919 tokens. size: 0.1122 gb, cost 2.4483 ms, throughput: 45.8214 GB/s; offload_time: 2.4390 ms, put_time: 0.0093 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,372] LMCache INFO:[0m Storing KV cache for 2310 out of 10246 tokens (skip_leading_tokens=7936) for request chatcmpl-b60e25b261d44096901f58211569bd50 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,378] LMCache INFO:[0m Stored 2310 out of total 2310 tokens. size: 0.2820 gb, cost 6.1159 ms, throughput: 46.1064 GB/s; offload_time: 6.1016 ms, put_time: 0.0143 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 127, time is 1761207004.3806
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 127
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207004.3807213
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 133
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 98, time is 1761207004.3807693
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 98
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 25, time is 1761207004.380808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 25
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,382] LMCache INFO:[0m Reqid: chatcmpl-3f41b54b5c5d40ac8c7b066d9f7d762e, Total tokens 1103, LMCache hit tokens: 256, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,383] LMCache INFO:[0m Reqid: chatcmpl-b44fcdac02f14db9b83d7b0773f52387, Total tokens 1123, LMCache hit tokens: 256, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,384] LMCache INFO:[0m Reqid: chatcmpl-8c919dd31dab484d89fd7ae483e849a1, Total tokens 5149, LMCache hit tokens: 1024, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,386] LMCache INFO:[0m Reqid: chatcmpl-3a724f9020984505a438efd6036e726d, Total tokens 1055, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '114', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,505] LMCache INFO:[0m Storing KV cache for 847 out of 1103 tokens (skip_leading_tokens=256) for request chatcmpl-3f41b54b5c5d40ac8c7b066d9f7d762e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,507] LMCache INFO:[0m Stored 847 out of total 847 tokens. size: 0.1034 gb, cost 2.3550 ms, throughput: 43.9041 GB/s; offload_time: 2.3440 ms, put_time: 0.0110 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,507] LMCache INFO:[0m Storing KV cache for 867 out of 1123 tokens (skip_leading_tokens=256) for request chatcmpl-b44fcdac02f14db9b83d7b0773f52387 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,510] LMCache INFO:[0m Stored 867 out of total 867 tokens. size: 0.1058 gb, cost 2.3395 ms, throughput: 45.2377 GB/s; offload_time: 2.3307 ms, put_time: 0.0088 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,510] LMCache INFO:[0m Storing KV cache for 4125 out of 5149 tokens (skip_leading_tokens=1024) for request chatcmpl-8c919dd31dab484d89fd7ae483e849a1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,521] LMCache INFO:[0m Stored 4125 out of total 4125 tokens. size: 0.5035 gb, cost 10.8644 ms, throughput: 46.3478 GB/s; offload_time: 10.8280 ms, put_time: 0.0364 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,521] LMCache INFO:[0m Storing KV cache for 799 out of 1055 tokens (skip_leading_tokens=256) for request chatcmpl-3a724f9020984505a438efd6036e726d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,523] LMCache INFO:[0m Stored 799 out of total 799 tokens. size: 0.0975 gb, cost 2.1680 ms, throughput: 44.9878 GB/s; offload_time: 2.1590 ms, put_time: 0.0090 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:328] Request job id finishing: 152, time is 1761207004.5254638
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1462] Request GPU size bytes: 88866816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1463] Token size of the request: 400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1469] Swap waste for job 152: 0.0027587890625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1479] Accumulated tokens for job 152: 43166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1481] Discard waste for job 152: 2.1416267110475937
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1484] Preserve waste for job 152: 1.7845357656478882
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 114, time is 1761207004.5258226
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,527] LMCache INFO:[0m Reqid: chatcmpl-524770983d434c9bb30f57134fb2169b, Total tokens 1154, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,558] LMCache INFO:[0m Storing KV cache for 898 out of 1154 tokens (skip_leading_tokens=256) for request chatcmpl-524770983d434c9bb30f57134fb2169b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,561] LMCache INFO:[0m Stored 898 out of total 898 tokens. size: 0.1096 gb, cost 2.5475 ms, throughput: 43.0301 GB/s; offload_time: 2.5314 ms, put_time: 0.0161 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '157', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 157, time is 1761207004.610854
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 157
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,612] LMCache INFO:[0m Reqid: chatcmpl-ace928a765d644ef8d978f20b6afc0ac, Total tokens 1174, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '24', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '146', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '131', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,639] LMCache INFO:[0m Storing KV cache for 918 out of 1174 tokens (skip_leading_tokens=256) for request chatcmpl-ace928a765d644ef8d978f20b6afc0ac [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,642] LMCache INFO:[0m Stored 918 out of total 918 tokens. size: 0.1121 gb, cost 2.5044 ms, throughput: 44.7451 GB/s; offload_time: 2.4942 ms, put_time: 0.0103 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 24, time is 1761207004.6435719
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 24
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 146, time is 1761207004.6436753
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 131, time is 1761207004.6437244
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,645] LMCache INFO:[0m Reqid: chatcmpl-6f9adfe6338a4e9eb4883ce0c7765b1e, Total tokens 1218, LMCache hit tokens: 256, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,646] LMCache INFO:[0m Reqid: chatcmpl-bd3aca0aa5a44ad78b677756a542f0df, Total tokens 1242, LMCache hit tokens: 256, need to load: -304 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,648] LMCache INFO:[0m Reqid: chatcmpl-ff6ebeb3e8cf4237a2065299e591bacc, Total tokens 1302, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,691] LMCache INFO:[0m Storing KV cache for 962 out of 1218 tokens (skip_leading_tokens=256) for request chatcmpl-6f9adfe6338a4e9eb4883ce0c7765b1e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,694] LMCache INFO:[0m Stored 962 out of total 962 tokens. size: 0.1174 gb, cost 2.6174 ms, throughput: 44.8649 GB/s; offload_time: 2.6066 ms, put_time: 0.0108 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,694] LMCache INFO:[0m Storing KV cache for 986 out of 1242 tokens (skip_leading_tokens=256) for request chatcmpl-bd3aca0aa5a44ad78b677756a542f0df [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,697] LMCache INFO:[0m Stored 986 out of total 986 tokens. size: 0.1204 gb, cost 2.6181 ms, throughput: 45.9727 GB/s; offload_time: 2.6096 ms, put_time: 0.0085 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,697] LMCache INFO:[0m Storing KV cache for 1046 out of 1302 tokens (skip_leading_tokens=256) for request chatcmpl-ff6ebeb3e8cf4237a2065299e591bacc [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,700] LMCache INFO:[0m Stored 1046 out of total 1046 tokens. size: 0.1277 gb, cost 2.7680 ms, throughput: 46.1295 GB/s; offload_time: 2.7588 ms, put_time: 0.0092 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207004.7018082
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,703] LMCache INFO:[0m Reqid: chatcmpl-6d382166c34b4d08b1a9a9148a8c2ef9, Total tokens 1092, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '129', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,730] LMCache INFO:[0m Storing KV cache for 836 out of 1092 tokens (skip_leading_tokens=256) for request chatcmpl-6d382166c34b4d08b1a9a9148a8c2ef9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,732] LMCache INFO:[0m Stored 836 out of total 836 tokens. size: 0.1021 gb, cost 2.3058 ms, throughput: 44.2587 GB/s; offload_time: 2.2951 ms, put_time: 0.0107 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 129, time is 1761207004.7343702
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,735] LMCache INFO:[0m Reqid: chatcmpl-6e24d0bf7e6e4feb82902f38c42a9388, Total tokens 1259, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '90', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,765] LMCache INFO:[0m Storing KV cache for 1003 out of 1259 tokens (skip_leading_tokens=256) for request chatcmpl-6e24d0bf7e6e4feb82902f38c42a9388 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,768] LMCache INFO:[0m Stored 1003 out of total 1003 tokens. size: 0.1224 gb, cost 2.7291 ms, throughput: 44.8640 GB/s; offload_time: 2.7178 ms, put_time: 0.0113 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 90, time is 1761207004.7702048
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 90
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,771] LMCache INFO:[0m Reqid: chatcmpl-8d7ab893b0dc453d9c0ff35adfb60123, Total tokens 2356, LMCache hit tokens: 1024, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '121', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,810] LMCache INFO:[0m Storing KV cache for 1332 out of 2356 tokens (skip_leading_tokens=1024) for request chatcmpl-8d7ab893b0dc453d9c0ff35adfb60123 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,814] LMCache INFO:[0m Stored 1332 out of total 1332 tokens. size: 0.1626 gb, cost 3.5790 ms, throughput: 45.4310 GB/s; offload_time: 3.5669 ms, put_time: 0.0121 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 121, time is 1761207004.815804
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,817] LMCache INFO:[0m Reqid: chatcmpl-6e2de92256074fe587f9fbfed95d3272, Total tokens 1224, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,846] LMCache INFO:[0m Storing KV cache for 968 out of 1224 tokens (skip_leading_tokens=256) for request chatcmpl-6e2de92256074fe587f9fbfed95d3272 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,849] LMCache INFO:[0m Stored 968 out of total 968 tokens. size: 0.1182 gb, cost 2.6374 ms, throughput: 44.8030 GB/s; offload_time: 2.6269 ms, put_time: 0.0106 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '77', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:328] Request job id finishing: 76, time is 1761207004.8674645
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1462] Request GPU size bytes: 137494528
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1463] Token size of the request: 1034
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1469] Swap waste for job 76: 0.0042683919270833336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1479] Accumulated tokens for job 76: 54787
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1481] Discard waste for job 76: 3.227462937712855
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1484] Preserve waste for job 76: 1.1013976732889812
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 77, time is 1761207004.8677602
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 77
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,869] LMCache INFO:[0m Reqid: chatcmpl-cbe56d8336e14b78a624cc96db06a68e, Total tokens 1209, LMCache hit tokens: 256, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '36', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,897] LMCache INFO:[0m Storing KV cache for 953 out of 1209 tokens (skip_leading_tokens=256) for request chatcmpl-cbe56d8336e14b78a624cc96db06a68e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,900] LMCache INFO:[0m Stored 953 out of total 953 tokens. size: 0.1163 gb, cost 2.6113 ms, throughput: 44.5498 GB/s; offload_time: 2.6001 ms, put_time: 0.0112 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 36, time is 1761207004.9019997
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 36
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,903] LMCache INFO:[0m Reqid: chatcmpl-97acf5ea80ec44ce9d3ba81d22df0301, Total tokens 1085, LMCache hit tokens: 256, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,932] LMCache INFO:[0m Storing KV cache for 829 out of 1085 tokens (skip_leading_tokens=256) for request chatcmpl-97acf5ea80ec44ce9d3ba81d22df0301 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,934] LMCache INFO:[0m Stored 829 out of total 829 tokens. size: 0.1012 gb, cost 2.2798 ms, throughput: 44.3884 GB/s; offload_time: 2.2667 ms, put_time: 0.0131 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:328] Request job id finishing: 2, time is 1761207004.9506423
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1462] Request GPU size bytes: 1345323008
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1463] Token size of the request: 10246
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1469] Swap waste for job 2: 0.041764322916666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1479] Accumulated tokens for job 2: 56047
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1481] Discard waste for job 2: 3.3580480427350023
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1484] Preserve waste for job 2: 2.0018864631652833
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207004.9677103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1462] Request GPU size bytes: 135397376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1463] Token size of the request: 1014
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1469] Swap waste for job 7: 0.004203287760416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1479] Accumulated tokens for job 7: 45801
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1481] Discard waste for job 7: 2.3690816048385046
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [scheduler.py:1484] Preserve waste for job 7: 1.1013976732889812
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207004.9679995
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 97
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,969] LMCache INFO:[0m Reqid: chatcmpl-2efea97e8f0c427fbe42b106d5c1d6ef, Total tokens 1110, LMCache hit tokens: 256, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,994] LMCache INFO:[0m Storing KV cache for 854 out of 1110 tokens (skip_leading_tokens=256) for request chatcmpl-2efea97e8f0c427fbe42b106d5c1d6ef [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:04,997] LMCache INFO:[0m Stored 854 out of total 854 tokens. size: 0.1042 gb, cost 2.3558 ms, throughput: 44.2523 GB/s; offload_time: 2.3417 ms, put_time: 0.0141 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207004.9991872
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:04 [estimate_with_func.py:315] Request job id: 44
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,000] LMCache INFO:[0m Reqid: chatcmpl-af2d183dc86a41c9937f9306ba57d65c, Total tokens 1258, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,030] LMCache INFO:[0m Storing KV cache for 1002 out of 1258 tokens (skip_leading_tokens=256) for request chatcmpl-af2d183dc86a41c9937f9306ba57d65c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,033] LMCache INFO:[0m Stored 1002 out of total 1002 tokens. size: 0.1223 gb, cost 2.7100 ms, throughput: 45.1341 GB/s; offload_time: 2.6993 ms, put_time: 0.0107 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 109, time is 1761207005.0349703
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 89784320
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 109: 0.0027872721354166665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 109: 47155
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 109: 2.4902373485114175
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 109: 2.0319012535942926
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207005.0352917
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,036] LMCache INFO:[0m Reqid: chatcmpl-bf98509e03f14412accc60b003ee6a8f, Total tokens 1274, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '162', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,063] LMCache INFO:[0m Storing KV cache for 1018 out of 1274 tokens (skip_leading_tokens=256) for request chatcmpl-bf98509e03f14412accc60b003ee6a8f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '140', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59118 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,066] LMCache INFO:[0m Stored 1018 out of total 1018 tokens. size: 0.1243 gb, cost 2.9683 ms, throughput: 41.8650 GB/s; offload_time: 2.9563 ms, put_time: 0.0120 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207005.067907
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 5
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 162, time is 1761207005.0680084
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 162
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 140, time is 1761207005.0680583
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 140
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,069] LMCache INFO:[0m Reqid: chatcmpl-f91973c1cb2d453491fa5d7490c647a9, Total tokens 1185, LMCache hit tokens: 256, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,070] LMCache INFO:[0m Reqid: chatcmpl-db95038a4cd14c798852db18b522a909, Total tokens 1103, LMCache hit tokens: 256, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,072] LMCache INFO:[0m Reqid: chatcmpl-b7375b4eaf824b00a1d462e6a01c7f61, Total tokens 1311, LMCache hit tokens: 256, need to load: -352 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '76', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,118] LMCache INFO:[0m Storing KV cache for 929 out of 1185 tokens (skip_leading_tokens=256) for request chatcmpl-f91973c1cb2d453491fa5d7490c647a9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,121] LMCache INFO:[0m Stored 929 out of total 929 tokens. size: 0.1134 gb, cost 2.5320 ms, throughput: 44.7888 GB/s; offload_time: 2.5206 ms, put_time: 0.0113 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,121] LMCache INFO:[0m Storing KV cache for 847 out of 1103 tokens (skip_leading_tokens=256) for request chatcmpl-db95038a4cd14c798852db18b522a909 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,123] LMCache INFO:[0m Stored 847 out of total 847 tokens. size: 0.1034 gb, cost 2.2480 ms, throughput: 45.9941 GB/s; offload_time: 2.2394 ms, put_time: 0.0086 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,124] LMCache INFO:[0m Storing KV cache for 1055 out of 1311 tokens (skip_leading_tokens=256) for request chatcmpl-b7375b4eaf824b00a1d462e6a01c7f61 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,126] LMCache INFO:[0m Stored 1055 out of total 1055 tokens. size: 0.1288 gb, cost 2.7969 ms, throughput: 46.0451 GB/s; offload_time: 2.7875 ms, put_time: 0.0094 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 130, time is 1761207005.1284838
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 92405760
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 130: 0.00286865234375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 130: 51642
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 130: 2.9124903082566913
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 130: 2.11059586463436
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 52, time is 1761207005.128682
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 91881472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 399
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 52: 0.0028523763020833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 52: 51642
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 52: 2.9124903082566913
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 52: 2.11059586463436
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 107, time is 1761207005.128815
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 90701824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 107: 0.0028157552083333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 107: 51642
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 107: 2.9124903082566913
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 107: 2.11059586463436
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 114, time is 1761207005.1289685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 154009600
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 1154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 114: 0.004781087239583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 114: 51642
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 114: 2.9124903082566913
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 114: 1.1013976732889812
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 76, time is 1761207005.1292083
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 76
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,131] LMCache INFO:[0m Reqid: chatcmpl-561d9a2dfd124a819660d54c14468c5b, Total tokens 7317, LMCache hit tokens: 1024, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '110', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '126', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '117', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '134', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '50', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,280] LMCache INFO:[0m Storing KV cache for 6293 out of 7317 tokens (skip_leading_tokens=1024) for request chatcmpl-561d9a2dfd124a819660d54c14468c5b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '165', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59280 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,297] LMCache INFO:[0m Stored 6293 out of total 6293 tokens. size: 0.7682 gb, cost 17.0867 ms, throughput: 44.9583 GB/s; offload_time: 17.0523 ms, put_time: 0.0344 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207005.2997162
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 110, time is 1761207005.299843
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 110
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 126, time is 1761207005.299989
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 126
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 117, time is 1761207005.3000376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207005.3000813
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 134, time is 1761207005.3001213
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 134
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 50, time is 1761207005.3001611
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 50
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 165, time is 1761207005.3001971
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,301] LMCache INFO:[0m Reqid: chatcmpl-bf52fcdd976440338445fb8b6ea5fed7, Total tokens 1215, LMCache hit tokens: 256, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,303] LMCache INFO:[0m Reqid: chatcmpl-6b7b8d35ca4e4c519e2012b108b60571, Total tokens 1364, LMCache hit tokens: 256, need to load: -320 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,304] LMCache INFO:[0m Reqid: chatcmpl-41a5239c7db74b45ae89e557a13991a1, Total tokens 1329, LMCache hit tokens: 256, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,305] LMCache INFO:[0m Reqid: chatcmpl-5bd397fe8dd84a57b87df77a92428a23, Total tokens 1249, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,306] LMCache INFO:[0m Reqid: chatcmpl-4140bfdfabc24bc1a019a3f87cac5822, Total tokens 1639, LMCache hit tokens: 768, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,307] LMCache INFO:[0m Reqid: chatcmpl-9ccc33cc37514d96ba043130308d84f3, Total tokens 1454, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,309] LMCache INFO:[0m Reqid: chatcmpl-26e6ed44cb4f48259e6c8cb2297723c5, Total tokens 1127, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,310] LMCache INFO:[0m Reqid: chatcmpl-50443e6068a14483b2097f909e211a8b, Total tokens 1404, LMCache hit tokens: 256, need to load: -320 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '130', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '29', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '104', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '107', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '142', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,422] LMCache INFO:[0m Storing KV cache for 959 out of 1215 tokens (skip_leading_tokens=256) for request chatcmpl-bf52fcdd976440338445fb8b6ea5fed7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,425] LMCache INFO:[0m Stored 959 out of total 959 tokens. size: 0.1171 gb, cost 2.8095 ms, throughput: 41.6683 GB/s; offload_time: 2.7931 ms, put_time: 0.0164 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,425] LMCache INFO:[0m Storing KV cache for 1108 out of 1364 tokens (skip_leading_tokens=256) for request chatcmpl-6b7b8d35ca4e4c519e2012b108b60571 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,428] LMCache INFO:[0m Stored 1108 out of total 1108 tokens. size: 0.1353 gb, cost 3.0663 ms, throughput: 44.1096 GB/s; offload_time: 3.0565 ms, put_time: 0.0098 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,428] LMCache INFO:[0m Storing KV cache for 1073 out of 1329 tokens (skip_leading_tokens=256) for request chatcmpl-41a5239c7db74b45ae89e557a13991a1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,431] LMCache INFO:[0m Stored 1073 out of total 1073 tokens. size: 0.1310 gb, cost 2.9643 ms, throughput: 44.1868 GB/s; offload_time: 2.9556 ms, put_time: 0.0087 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,431] LMCache INFO:[0m Storing KV cache for 993 out of 1249 tokens (skip_leading_tokens=256) for request chatcmpl-5bd397fe8dd84a57b87df77a92428a23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,434] LMCache INFO:[0m Stored 993 out of total 993 tokens. size: 0.1212 gb, cost 2.7266 ms, throughput: 44.4569 GB/s; offload_time: 2.7181 ms, put_time: 0.0085 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,434] LMCache INFO:[0m Storing KV cache for 871 out of 1639 tokens (skip_leading_tokens=768) for request chatcmpl-4140bfdfabc24bc1a019a3f87cac5822 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,437] LMCache INFO:[0m Stored 871 out of total 871 tokens. size: 0.1063 gb, cost 2.5272 ms, throughput: 42.0708 GB/s; offload_time: 2.5190 ms, put_time: 0.0083 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,437] LMCache INFO:[0m Storing KV cache for 1198 out of 1454 tokens (skip_leading_tokens=256) for request chatcmpl-9ccc33cc37514d96ba043130308d84f3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,440] LMCache INFO:[0m Stored 1198 out of total 1198 tokens. size: 0.1462 gb, cost 3.2805 ms, throughput: 44.5781 GB/s; offload_time: 3.2721 ms, put_time: 0.0084 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,440] LMCache INFO:[0m Storing KV cache for 871 out of 1127 tokens (skip_leading_tokens=256) for request chatcmpl-26e6ed44cb4f48259e6c8cb2297723c5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,443] LMCache INFO:[0m Stored 871 out of total 871 tokens. size: 0.1063 gb, cost 2.3953 ms, throughput: 44.3883 GB/s; offload_time: 2.3877 ms, put_time: 0.0076 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,443] LMCache INFO:[0m Storing KV cache for 1148 out of 1404 tokens (skip_leading_tokens=256) for request chatcmpl-50443e6068a14483b2097f909e211a8b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,446] LMCache INFO:[0m Stored 1148 out of total 1148 tokens. size: 0.1401 gb, cost 3.1526 ms, throughput: 44.4512 GB/s; offload_time: 3.1437 ms, put_time: 0.0089 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 87, time is 1761207005.4489465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 89260032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 378
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 87: 0.00277099609375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 87: 67392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 87: 4.647088945038541
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 87: 2.184029535243386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 66, time is 1761207005.4491959
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 90963968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 393
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 66: 0.0028238932291666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 66: 67392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 66: 4.647088945038541
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 66: 2.184029535243386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 151, time is 1761207005.4493144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 90832896
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 393
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 151: 0.00281982421875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 151: 67392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 151: 4.647088945038541
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 151: 2.184029535243386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 131, time is 1761207005.4494436
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 172752896
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 1302
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 131: 0.005362955729166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 131: 67392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 131: 4.647088945038541
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 131: 0.7796501159667969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207005.4495683
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 145096704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 1092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 164: 0.00450439453125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 164: 67392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 164: 4.647088945038541
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 164: 0.7796501159667969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 130, time is 1761207005.44986
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 130
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 29, time is 1761207005.4499342
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 29
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 104, time is 1761207005.449984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 107, time is 1761207005.4503891
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 107
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 142, time is 1761207005.4504547
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207005.4505
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,452] LMCache INFO:[0m Reqid: chatcmpl-1a370814261a4d1a8f6255eeba61d460, Total tokens 1095, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,453] LMCache INFO:[0m Reqid: chatcmpl-98d0bca2a1be47e69cd541208397ccc0, Total tokens 1544, LMCache hit tokens: 256, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,454] LMCache INFO:[0m Reqid: chatcmpl-b8c0e682adb94919be9cfff8c58273c6, Total tokens 1347, LMCache hit tokens: 256, need to load: -320 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,455] LMCache INFO:[0m Reqid: chatcmpl-ee59fffa984948abb607e88f15c1796b, Total tokens 1560, LMCache hit tokens: 256, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,456] LMCache INFO:[0m Reqid: chatcmpl-641b35b93bf5473d8b643542eb0ecc0a, Total tokens 1473, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,457] LMCache INFO:[0m Reqid: chatcmpl-7f09435fb35c45ffa4a7b395e85be89e, Total tokens 1261, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '105', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '148', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,560] LMCache INFO:[0m Storing KV cache for 839 out of 1095 tokens (skip_leading_tokens=256) for request chatcmpl-1a370814261a4d1a8f6255eeba61d460 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,563] LMCache INFO:[0m Stored 839 out of total 839 tokens. size: 0.1024 gb, cost 2.3177 ms, throughput: 44.1897 GB/s; offload_time: 2.3056 ms, put_time: 0.0121 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,563] LMCache INFO:[0m Storing KV cache for 1288 out of 1544 tokens (skip_leading_tokens=256) for request chatcmpl-98d0bca2a1be47e69cd541208397ccc0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,567] LMCache INFO:[0m Stored 1288 out of total 1288 tokens. size: 0.1572 gb, cost 3.4460 ms, throughput: 45.6263 GB/s; offload_time: 3.4339 ms, put_time: 0.0121 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,567] LMCache INFO:[0m Storing KV cache for 1091 out of 1347 tokens (skip_leading_tokens=256) for request chatcmpl-b8c0e682adb94919be9cfff8c58273c6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,570] LMCache INFO:[0m Stored 1091 out of total 1091 tokens. size: 0.1332 gb, cost 2.9215 ms, throughput: 45.5861 GB/s; offload_time: 2.9113 ms, put_time: 0.0102 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,570] LMCache INFO:[0m Storing KV cache for 1304 out of 1560 tokens (skip_leading_tokens=256) for request chatcmpl-ee59fffa984948abb607e88f15c1796b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,574] LMCache INFO:[0m Stored 1304 out of total 1304 tokens. size: 0.1592 gb, cost 3.4323 ms, throughput: 46.3767 GB/s; offload_time: 3.4223 ms, put_time: 0.0100 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,574] LMCache INFO:[0m Storing KV cache for 1217 out of 1473 tokens (skip_leading_tokens=256) for request chatcmpl-641b35b93bf5473d8b643542eb0ecc0a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,577] LMCache INFO:[0m Stored 1217 out of total 1217 tokens. size: 0.1486 gb, cost 3.2306 ms, throughput: 45.9846 GB/s; offload_time: 3.2188 ms, put_time: 0.0119 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,577] LMCache INFO:[0m Storing KV cache for 1005 out of 1261 tokens (skip_leading_tokens=256) for request chatcmpl-7f09435fb35c45ffa4a7b395e85be89e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,580] LMCache INFO:[0m Stored 1005 out of total 1005 tokens. size: 0.1227 gb, cost 2.6690 ms, throughput: 45.9658 GB/s; offload_time: 2.6601 ms, put_time: 0.0088 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 141, time is 1761207005.5824776
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 91357184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 394
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 141: 0.0028361002604166668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 141: 72114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 141: 5.243698334228362
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 141: 2.144581686366688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 105, time is 1761207005.5828562
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 105
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 148, time is 1761207005.5829263
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 148
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,584] LMCache INFO:[0m Reqid: chatcmpl-9f752035606944eebf29b06fc03402fb, Total tokens 1344, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,586] LMCache INFO:[0m Reqid: chatcmpl-76575063338f4a8ab9cee5bc32b6b041, Total tokens 1321, LMCache hit tokens: 256, need to load: -272 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '93', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58840 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '112', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,634] LMCache INFO:[0m Storing KV cache for 1088 out of 1344 tokens (skip_leading_tokens=256) for request chatcmpl-9f752035606944eebf29b06fc03402fb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,637] LMCache INFO:[0m Stored 1088 out of total 1088 tokens. size: 0.1328 gb, cost 2.9656 ms, throughput: 44.7850 GB/s; offload_time: 2.9532 ms, put_time: 0.0123 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,637] LMCache INFO:[0m Storing KV cache for 1065 out of 1321 tokens (skip_leading_tokens=256) for request chatcmpl-76575063338f4a8ab9cee5bc32b6b041 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '123', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,640] LMCache INFO:[0m Stored 1065 out of total 1065 tokens. size: 0.1300 gb, cost 2.8325 ms, throughput: 45.8975 GB/s; offload_time: 2.8223 ms, put_time: 0.0102 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 93, time is 1761207005.6426058
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 93
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 112, time is 1761207005.642716
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207005.6427646
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207005.642811
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 123, time is 1761207005.6428618
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,644] LMCache INFO:[0m Reqid: chatcmpl-4ebb26e7f51f446e8408c9339b07cc10, Total tokens 1155, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,646] LMCache INFO:[0m Reqid: chatcmpl-0f64ff345c0847d9b452d64c0590acbc, Total tokens 1331, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,647] LMCache INFO:[0m Reqid: chatcmpl-af6f9b7e4aae40f688f6a38dc4236618, Total tokens 1361, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,649] LMCache INFO:[0m Reqid: chatcmpl-906b40b8f2f8431f9b4dd5039d4ba9f6, Total tokens 1316, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,650] LMCache INFO:[0m Reqid: chatcmpl-20121705a6a04267a70f215ac718dbff, Total tokens 1248, LMCache hit tokens: 256, need to load: -272 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '17', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,722] LMCache INFO:[0m Storing KV cache for 899 out of 1155 tokens (skip_leading_tokens=256) for request chatcmpl-4ebb26e7f51f446e8408c9339b07cc10 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,725] LMCache INFO:[0m Stored 899 out of total 899 tokens. size: 0.1097 gb, cost 2.4650 ms, throughput: 44.5204 GB/s; offload_time: 2.4539 ms, put_time: 0.0110 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,725] LMCache INFO:[0m Storing KV cache for 1075 out of 1331 tokens (skip_leading_tokens=256) for request chatcmpl-0f64ff345c0847d9b452d64c0590acbc [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,728] LMCache INFO:[0m Stored 1075 out of total 1075 tokens. size: 0.1312 gb, cost 2.8564 ms, throughput: 45.9410 GB/s; offload_time: 2.8468 ms, put_time: 0.0096 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,728] LMCache INFO:[0m Storing KV cache for 1105 out of 1361 tokens (skip_leading_tokens=256) for request chatcmpl-af6f9b7e4aae40f688f6a38dc4236618 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,731] LMCache INFO:[0m Stored 1105 out of total 1105 tokens. size: 0.1349 gb, cost 2.9471 ms, throughput: 45.7691 GB/s; offload_time: 2.9370 ms, put_time: 0.0101 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,731] LMCache INFO:[0m Storing KV cache for 1060 out of 1316 tokens (skip_leading_tokens=256) for request chatcmpl-906b40b8f2f8431f9b4dd5039d4ba9f6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,734] LMCache INFO:[0m Stored 1060 out of total 1060 tokens. size: 0.1294 gb, cost 2.8337 ms, throughput: 45.6635 GB/s; offload_time: 2.8243 ms, put_time: 0.0094 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,734] LMCache INFO:[0m Storing KV cache for 992 out of 1248 tokens (skip_leading_tokens=256) for request chatcmpl-20121705a6a04267a70f215ac718dbff [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '1', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,737] LMCache INFO:[0m Stored 992 out of total 992 tokens. size: 0.1211 gb, cost 2.6336 ms, throughput: 45.9798 GB/s; offload_time: 2.6254 ms, put_time: 0.0083 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 17, time is 1761207005.7396598
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 17
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 1, time is 1761207005.7397754
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 1
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,741] LMCache INFO:[0m Reqid: chatcmpl-30ee99b32f844f78902c485534c63a81, Total tokens 1354, LMCache hit tokens: 256, need to load: -368 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,742] LMCache INFO:[0m Reqid: chatcmpl-515a9b7322d949408265abef4ec3a0fd, Total tokens 1387, LMCache hit tokens: 256, need to load: -384 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '39', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '169', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '160', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,788] LMCache INFO:[0m Storing KV cache for 1098 out of 1354 tokens (skip_leading_tokens=256) for request chatcmpl-30ee99b32f844f78902c485534c63a81 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,791] LMCache INFO:[0m Stored 1098 out of total 1098 tokens. size: 0.1340 gb, cost 2.9696 ms, throughput: 45.1354 GB/s; offload_time: 2.9579 ms, put_time: 0.0116 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,791] LMCache INFO:[0m Storing KV cache for 1131 out of 1387 tokens (skip_leading_tokens=256) for request chatcmpl-515a9b7322d949408265abef4ec3a0fd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '101', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,794] LMCache INFO:[0m Stored 1131 out of total 1131 tokens. size: 0.1381 gb, cost 3.0074 ms, throughput: 45.9077 GB/s; offload_time: 2.9966 ms, put_time: 0.0107 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 24, time is 1761207005.7969484
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 165412864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 1242
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 24: 0.005135091145833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 24: 83537
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 24: 6.833018597443354
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 24: 0.7796501159667969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 36, time is 1761207005.797173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 143917056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 1085
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 36: 0.0044677734375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 36: 83537
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 36: 6.833018597443354
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 36: 0.7796501159667969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207005.7974262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 16
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 39, time is 1761207005.7974913
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 39
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 169, time is 1761207005.79754
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 160, time is 1761207005.7975857
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 101, time is 1761207005.7979565
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,799] LMCache INFO:[0m Reqid: chatcmpl-83d1623e1538440581a9b92133c0538a, Total tokens 1366, LMCache hit tokens: 256, need to load: -384 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,801] LMCache INFO:[0m Reqid: chatcmpl-1951d3ec8a1142c8af706e2e2ee600ae, Total tokens 1104, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,802] LMCache INFO:[0m Reqid: chatcmpl-d2c94f2202d94cb18632adfd551c2967, Total tokens 1595, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,804] LMCache INFO:[0m Reqid: chatcmpl-4d3eccad2ffd40fdb4dd76d55da09779, Total tokens 1420, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,805] LMCache INFO:[0m Reqid: chatcmpl-f5959d48a7354b0d9eec3561b44f6611, Total tokens 1358, LMCache hit tokens: 256, need to load: -304 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '15', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,883] LMCache INFO:[0m Storing KV cache for 1110 out of 1366 tokens (skip_leading_tokens=256) for request chatcmpl-83d1623e1538440581a9b92133c0538a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,886] LMCache INFO:[0m Stored 1110 out of total 1110 tokens. size: 0.1355 gb, cost 3.0455 ms, throughput: 44.4913 GB/s; offload_time: 3.0320 ms, put_time: 0.0135 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,886] LMCache INFO:[0m Storing KV cache for 848 out of 1104 tokens (skip_leading_tokens=256) for request chatcmpl-1951d3ec8a1142c8af706e2e2ee600ae [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,888] LMCache INFO:[0m Stored 848 out of total 848 tokens. size: 0.1035 gb, cost 2.2830 ms, throughput: 45.3418 GB/s; offload_time: 2.2716 ms, put_time: 0.0114 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,888] LMCache INFO:[0m Storing KV cache for 1339 out of 1595 tokens (skip_leading_tokens=256) for request chatcmpl-d2c94f2202d94cb18632adfd551c2967 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,892] LMCache INFO:[0m Stored 1339 out of total 1339 tokens. size: 0.1635 gb, cost 3.5246 ms, throughput: 46.3746 GB/s; offload_time: 3.5143 ms, put_time: 0.0104 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,892] LMCache INFO:[0m Storing KV cache for 1164 out of 1420 tokens (skip_leading_tokens=256) for request chatcmpl-4d3eccad2ffd40fdb4dd76d55da09779 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,895] LMCache INFO:[0m Stored 1164 out of total 1164 tokens. size: 0.1421 gb, cost 3.0736 ms, throughput: 46.2292 GB/s; offload_time: 3.0640 ms, put_time: 0.0096 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,895] LMCache INFO:[0m Storing KV cache for 1102 out of 1358 tokens (skip_leading_tokens=256) for request chatcmpl-f5959d48a7354b0d9eec3561b44f6611 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,898] LMCache INFO:[0m Stored 1102 out of total 1102 tokens. size: 0.1345 gb, cost 2.9274 ms, throughput: 45.9531 GB/s; offload_time: 2.9186 ms, put_time: 0.0088 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 157, time is 1761207005.900766
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 156762112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 1174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 157: 0.004866536458333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 157: 88053
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 157: 7.5183522821866235
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 157: 0.7796501159667969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:328] Request job id finishing: 146, time is 1761207005.9010398
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1462] Request GPU size bytes: 162398208
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1463] Token size of the request: 1218
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1469] Swap waste for job 146: 0.00504150390625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1479] Accumulated tokens for job 146: 88053
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1481] Discard waste for job 146: 7.5183522821866235
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [scheduler.py:1484] Preserve waste for job 146: 0.7796501159667969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207005.9013803
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 15, time is 1761207005.9014516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 15
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207005.9015045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 150
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,903] LMCache INFO:[0m Reqid: chatcmpl-5e1b2264d093474b92640976f6cfe40d, Total tokens 1325, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,904] LMCache INFO:[0m Reqid: chatcmpl-e58bb8dda35a4742b88d024f6f5a859d, Total tokens 1236, LMCache hit tokens: 256, need to load: -320 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,906] LMCache INFO:[0m Reqid: chatcmpl-3b9c7c0091e24104b3eca3c40f668794, Total tokens 1445, LMCache hit tokens: 256, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '124', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '106', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,965] LMCache INFO:[0m Storing KV cache for 1069 out of 1325 tokens (skip_leading_tokens=256) for request chatcmpl-5e1b2264d093474b92640976f6cfe40d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,968] LMCache INFO:[0m Stored 1069 out of total 1069 tokens. size: 0.1305 gb, cost 2.9148 ms, throughput: 44.7693 GB/s; offload_time: 2.9022 ms, put_time: 0.0126 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,968] LMCache INFO:[0m Storing KV cache for 980 out of 1236 tokens (skip_leading_tokens=256) for request chatcmpl-e58bb8dda35a4742b88d024f6f5a859d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,971] LMCache INFO:[0m Stored 980 out of total 980 tokens. size: 0.1196 gb, cost 2.6078 ms, throughput: 45.8733 GB/s; offload_time: 2.5981 ms, put_time: 0.0097 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,971] LMCache INFO:[0m Storing KV cache for 1189 out of 1445 tokens (skip_leading_tokens=256) for request chatcmpl-3b9c7c0091e24104b3eca3c40f668794 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,974] LMCache INFO:[0m Stored 1189 out of total 1189 tokens. size: 0.1451 gb, cost 3.1384 ms, throughput: 46.2477 GB/s; offload_time: 3.1288 ms, put_time: 0.0096 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207005.9772322
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 124, time is 1761207005.9773514
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207005.9774032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:307] Request job id arriving: 106, time is 1761207005.9774513
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:05 [estimate_with_func.py:315] Request job id: 106
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,979] LMCache INFO:[0m Reqid: chatcmpl-39cd10513a92429a83a47fb8d7fa1c56, Total tokens 1118, LMCache hit tokens: 256, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,980] LMCache INFO:[0m Reqid: chatcmpl-e92f3f3078ce4d41aa77e85b744addc0, Total tokens 1183, LMCache hit tokens: 256, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,982] LMCache INFO:[0m Reqid: chatcmpl-16c25283eb57492bad41f88b252c0147, Total tokens 7386, LMCache hit tokens: 1024, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:05,984] LMCache INFO:[0m Reqid: chatcmpl-ef04308f35b64524b7421a61a619cc39, Total tokens 1196, LMCache hit tokens: 256, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '131', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '24', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '36', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '23', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '30', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '35', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,157] LMCache INFO:[0m Storing KV cache for 862 out of 1118 tokens (skip_leading_tokens=256) for request chatcmpl-39cd10513a92429a83a47fb8d7fa1c56 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,160] LMCache INFO:[0m Stored 862 out of total 862 tokens. size: 0.1052 gb, cost 2.5935 ms, throughput: 40.5717 GB/s; offload_time: 2.5769 ms, put_time: 0.0167 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,160] LMCache INFO:[0m Storing KV cache for 927 out of 1183 tokens (skip_leading_tokens=256) for request chatcmpl-e92f3f3078ce4d41aa77e85b744addc0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,162] LMCache INFO:[0m Stored 927 out of total 927 tokens. size: 0.1132 gb, cost 2.4918 ms, throughput: 45.4127 GB/s; offload_time: 2.4815 ms, put_time: 0.0103 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,163] LMCache INFO:[0m Storing KV cache for 6362 out of 7386 tokens (skip_leading_tokens=1024) for request chatcmpl-16c25283eb57492bad41f88b252c0147 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '103', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,179] LMCache INFO:[0m Stored 6362 out of total 6362 tokens. size: 0.7766 gb, cost 16.3923 ms, throughput: 47.3767 GB/s; offload_time: 16.3654 ms, put_time: 0.0269 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,179] LMCache INFO:[0m Storing KV cache for 512 out of 768 tokens (skip_leading_tokens=256) for request chatcmpl-ef04308f35b64524b7421a61a619cc39 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,181] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.3768 ms, throughput: 45.3964 GB/s; offload_time: 1.3700 ms, put_time: 0.0068 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 131, time is 1761207006.183861
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 24, time is 1761207006.1840184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 24
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 36, time is 1761207006.184073
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 36
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 23, time is 1761207006.1841216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 23
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 30, time is 1761207006.1841726
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 30
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 35, time is 1761207006.184221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 35
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 103, time is 1761207006.1842651
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,186] LMCache INFO:[0m Reqid: chatcmpl-e032f996f8274727869fdaff739630eb, Total tokens 1088, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,187] LMCache INFO:[0m Reqid: chatcmpl-61c704253a114c6f92062521171f5c3e, Total tokens 7090, LMCache hit tokens: 1280, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,189] LMCache INFO:[0m Reqid: chatcmpl-652e3d40d7a64f69a84d73de5be1292a, Total tokens 1975, LMCache hit tokens: 1024, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,191] LMCache INFO:[0m Reqid: chatcmpl-16a74e18b31943c383407cfce47effbd, Total tokens 6756, LMCache hit tokens: 1024, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '81', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '3', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '6', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '152', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '92', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,367] LMCache INFO:[0m Storing KV cache for 832 out of 1088 tokens (skip_leading_tokens=256) for request chatcmpl-e032f996f8274727869fdaff739630eb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,370] LMCache INFO:[0m Stored 832 out of total 832 tokens. size: 0.1016 gb, cost 2.4632 ms, throughput: 41.2323 GB/s; offload_time: 2.4439 ms, put_time: 0.0192 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,370] LMCache INFO:[0m Storing KV cache for 5810 out of 7090 tokens (skip_leading_tokens=1280) for request chatcmpl-61c704253a114c6f92062521171f5c3e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,385] LMCache INFO:[0m Stored 5810 out of total 5810 tokens. size: 0.7092 gb, cost 14.9771 ms, throughput: 47.3541 GB/s; offload_time: 14.9524 ms, put_time: 0.0247 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,385] LMCache INFO:[0m Storing KV cache for 951 out of 1975 tokens (skip_leading_tokens=1024) for request chatcmpl-652e3d40d7a64f69a84d73de5be1292a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,388] LMCache INFO:[0m Stored 951 out of total 951 tokens. size: 0.1161 gb, cost 2.5610 ms, throughput: 45.3302 GB/s; offload_time: 2.5516 ms, put_time: 0.0094 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,388] LMCache INFO:[0m Storing KV cache for 768 out of 1792 tokens (skip_leading_tokens=1024) for request chatcmpl-16a74e18b31943c383407cfce47effbd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,390] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.0437 ms, throughput: 45.8731 GB/s; offload_time: 2.0354 ms, put_time: 0.0082 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,390] LMCache INFO:[0m Storing KV cache for 428 out of 1196 tokens (skip_leading_tokens=768) for request chatcmpl-ef04308f35b64524b7421a61a619cc39 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,391] LMCache INFO:[0m Stored 428 out of total 428 tokens. size: 0.0522 gb, cost 1.1998 ms, throughput: 43.5451 GB/s; offload_time: 1.1933 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 81, time is 1761207006.3946912
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 81
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 3, time is 1761207006.3948348
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 3
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207006.3949015
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 6, time is 1761207006.3949544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 6
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 152, time is 1761207006.3950043
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 92, time is 1761207006.3950515
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 92
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,397] LMCache INFO:[0m Reqid: chatcmpl-5abd873526214543ab8d7c1df61a9689, Total tokens 1210, LMCache hit tokens: 256, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,398] LMCache INFO:[0m Reqid: chatcmpl-e2befed0ba3f451c8329c091b2d9aa8c, Total tokens 1310, LMCache hit tokens: 256, need to load: -368 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,400] LMCache INFO:[0m Reqid: chatcmpl-1d1b77c7e0844931949ecfacfacdc3d4, Total tokens 1302, LMCache hit tokens: 256, need to load: -304 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,401] LMCache INFO:[0m Reqid: chatcmpl-1cc5f437c4b3474888798f493277622e, Total tokens 1435, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,402] LMCache INFO:[0m Reqid: chatcmpl-54c6e8adbdc64af1a0a2330bd6fcd9a0, Total tokens 1165, LMCache hit tokens: 256, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '94', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '114', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '146', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '89', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,570] LMCache INFO:[0m Storing KV cache for 954 out of 1210 tokens (skip_leading_tokens=256) for request chatcmpl-5abd873526214543ab8d7c1df61a9689 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,573] LMCache INFO:[0m Stored 954 out of total 954 tokens. size: 0.1165 gb, cost 2.6690 ms, throughput: 43.6327 GB/s; offload_time: 2.6565 ms, put_time: 0.0125 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,573] LMCache INFO:[0m Storing KV cache for 1054 out of 1310 tokens (skip_leading_tokens=256) for request chatcmpl-e2befed0ba3f451c8329c091b2d9aa8c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,576] LMCache INFO:[0m Stored 1054 out of total 1054 tokens. size: 0.1287 gb, cost 2.8134 ms, throughput: 45.7319 GB/s; offload_time: 2.8033 ms, put_time: 0.0101 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,576] LMCache INFO:[0m Storing KV cache for 1046 out of 1302 tokens (skip_leading_tokens=256) for request chatcmpl-1d1b77c7e0844931949ecfacfacdc3d4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,579] LMCache INFO:[0m Stored 1046 out of total 1046 tokens. size: 0.1277 gb, cost 2.8045 ms, throughput: 45.5281 GB/s; offload_time: 2.7936 ms, put_time: 0.0109 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,579] LMCache INFO:[0m Storing KV cache for 1179 out of 1435 tokens (skip_leading_tokens=256) for request chatcmpl-1cc5f437c4b3474888798f493277622e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,582] LMCache INFO:[0m Stored 1179 out of total 1179 tokens. size: 0.1439 gb, cost 3.1394 ms, throughput: 45.8432 GB/s; offload_time: 3.1294 ms, put_time: 0.0100 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,582] LMCache INFO:[0m Storing KV cache for 256 out of 512 tokens (skip_leading_tokens=256) for request chatcmpl-54c6e8adbdc64af1a0a2330bd6fcd9a0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,583] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.7486 ms, throughput: 41.7462 GB/s; offload_time: 0.6940 ms, put_time: 0.0546 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,583] LMCache INFO:[0m Storing KV cache for 4964 out of 6756 tokens (skip_leading_tokens=1792) for request chatcmpl-16a74e18b31943c383407cfce47effbd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,596] LMCache INFO:[0m Stored 4964 out of total 4964 tokens. size: 0.6060 gb, cost 12.8478 ms, throughput: 47.1642 GB/s; offload_time: 12.8274 ms, put_time: 0.0204 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 94, time is 1761207006.5995433
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 94
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 114, time is 1761207006.599672
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 146, time is 1761207006.5997238
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 89, time is 1761207006.5997667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 89
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,601] LMCache INFO:[0m Reqid: chatcmpl-40cfe9a9095d41b39cb31de332021d4d, Total tokens 1450, LMCache hit tokens: 256, need to load: -416 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,603] LMCache INFO:[0m Reqid: chatcmpl-ce03727d68144b6599e4eee346f139a1, Total tokens 1106, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,604] LMCache INFO:[0m Reqid: chatcmpl-6fc36323fae44faf9520367b00798c27, Total tokens 1567, LMCache hit tokens: 256, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,609] LMCache INFO:[0m Reqid: chatcmpl-fcdf1fd316044fe4b7316b3fc383c731, Total tokens 1524, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,610] LMCache INFO:[0m Reqid: chatcmpl-a68ad09618174c7e9942cd39f9e610b1, Total tokens 1329, LMCache hit tokens: 256, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,612] LMCache INFO:[0m Reqid: chatcmpl-87e395053975423d81bb333087b66970, Total tokens 5050, LMCache hit tokens: 1024, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,766] LMCache INFO:[0m Storing KV cache for 1194 out of 1450 tokens (skip_leading_tokens=256) for request chatcmpl-40cfe9a9095d41b39cb31de332021d4d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,770] LMCache INFO:[0m Stored 1194 out of total 1194 tokens. size: 0.1458 gb, cost 3.4285 ms, throughput: 42.5125 GB/s; offload_time: 3.4111 ms, put_time: 0.0173 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,770] LMCache INFO:[0m Storing KV cache for 850 out of 1106 tokens (skip_leading_tokens=256) for request chatcmpl-ce03727d68144b6599e4eee346f139a1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,772] LMCache INFO:[0m Stored 850 out of total 850 tokens. size: 0.1038 gb, cost 2.3149 ms, throughput: 44.8217 GB/s; offload_time: 2.3046 ms, put_time: 0.0103 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,772] LMCache INFO:[0m Storing KV cache for 1311 out of 1567 tokens (skip_leading_tokens=256) for request chatcmpl-6fc36323fae44faf9520367b00798c27 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,776] LMCache INFO:[0m Stored 1311 out of total 1311 tokens. size: 0.1600 gb, cost 3.4873 ms, throughput: 45.8904 GB/s; offload_time: 3.4772 ms, put_time: 0.0101 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,776] LMCache INFO:[0m Storing KV cache for 1268 out of 1524 tokens (skip_leading_tokens=256) for request chatcmpl-fcdf1fd316044fe4b7316b3fc383c731 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,779] LMCache INFO:[0m Stored 1268 out of total 1268 tokens. size: 0.1548 gb, cost 3.3482 ms, throughput: 46.2293 GB/s; offload_time: 3.3393 ms, put_time: 0.0089 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,779] LMCache INFO:[0m Storing KV cache for 1073 out of 1329 tokens (skip_leading_tokens=256) for request chatcmpl-a68ad09618174c7e9942cd39f9e610b1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,782] LMCache INFO:[0m Stored 1073 out of total 1073 tokens. size: 0.1310 gb, cost 2.8811 ms, throughput: 45.4629 GB/s; offload_time: 2.8723 ms, put_time: 0.0088 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,782] LMCache INFO:[0m Storing KV cache for 3328 out of 4352 tokens (skip_leading_tokens=1024) for request chatcmpl-87e395053975423d81bb333087b66970 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,791] LMCache INFO:[0m Stored 3328 out of total 3328 tokens. size: 0.4062 gb, cost 8.6165 ms, throughput: 47.1478 GB/s; offload_time: 8.6009 ms, put_time: 0.0156 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,791] LMCache INFO:[0m Storing KV cache for 653 out of 1165 tokens (skip_leading_tokens=512) for request chatcmpl-54c6e8adbdc64af1a0a2330bd6fcd9a0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,793] LMCache INFO:[0m Stored 653 out of total 653 tokens. size: 0.0797 gb, cost 1.8012 ms, throughput: 44.2541 GB/s; offload_time: 1.7932 ms, put_time: 0.0080 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,799] LMCache INFO:[0m Reqid: chatcmpl-65486d83f5474748aa2fb838ec92cd02, Total tokens 4447, LMCache hit tokens: 1024, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,800] LMCache INFO:[0m Reqid: chatcmpl-fc74f996c09149dfa85b845e311dd67a, Total tokens 1584, LMCache hit tokens: 256, need to load: -352 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '143', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '157', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,926] LMCache INFO:[0m Storing KV cache for 3423 out of 4447 tokens (skip_leading_tokens=1024) for request chatcmpl-65486d83f5474748aa2fb838ec92cd02 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,935] LMCache INFO:[0m Stored 3423 out of total 3423 tokens. size: 0.4178 gb, cost 8.9813 ms, throughput: 46.5243 GB/s; offload_time: 8.9588 ms, put_time: 0.0225 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,936] LMCache INFO:[0m Storing KV cache for 1328 out of 1584 tokens (skip_leading_tokens=256) for request chatcmpl-fc74f996c09149dfa85b845e311dd67a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,939] LMCache INFO:[0m Stored 1328 out of total 1328 tokens. size: 0.1621 gb, cost 3.5348 ms, throughput: 45.8615 GB/s; offload_time: 3.5232 ms, put_time: 0.0116 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,939] LMCache INFO:[0m Storing KV cache for 698 out of 5050 tokens (skip_leading_tokens=4352) for request chatcmpl-87e395053975423d81bb333087b66970 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,941] LMCache INFO:[0m Stored 698 out of total 698 tokens. size: 0.0852 gb, cost 1.9380 ms, throughput: 43.9659 GB/s; offload_time: 1.9293 ms, put_time: 0.0086 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 143, time is 1761207006.94475
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:307] Request job id arriving: 157, time is 1761207006.9448912
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:06 [estimate_with_func.py:315] Request job id: 157
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,947] LMCache INFO:[0m Reqid: chatcmpl-3e94af4406644fc886dd80d94ab2e0a8, Total tokens 1535, LMCache hit tokens: 256, need to load: -400 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:06,948] LMCache INFO:[0m Reqid: chatcmpl-b7502ad74ca744b785b4d7b7d3e49307, Total tokens 5486, LMCache hit tokens: 1024, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '2', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '109', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,072] LMCache INFO:[0m Storing KV cache for 1279 out of 1535 tokens (skip_leading_tokens=256) for request chatcmpl-3e94af4406644fc886dd80d94ab2e0a8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,076] LMCache INFO:[0m Stored 1279 out of total 1279 tokens. size: 0.1561 gb, cost 3.4587 ms, throughput: 45.1405 GB/s; offload_time: 3.4464 ms, put_time: 0.0123 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,076] LMCache INFO:[0m Storing KV cache for 4462 out of 5486 tokens (skip_leading_tokens=1024) for request chatcmpl-b7502ad74ca744b785b4d7b7d3e49307 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,088] LMCache INFO:[0m Stored 4462 out of total 4462 tokens. size: 0.5447 gb, cost 11.6915 ms, throughput: 46.5876 GB/s; offload_time: 11.6584 ms, put_time: 0.0331 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207007.0912385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 147849216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1110
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 97: 0.00458984375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 97: 148959
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 97: 19.916987781221682
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 97: 0.7623334328333536
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207007.0914772
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 167116800
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1258
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 44: 0.00518798828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 44: 148959
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 44: 19.916987781221682
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 44: 0.7623334328333536
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 2, time is 1761207007.091855
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 2
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 109, time is 1761207007.0919356
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,094] LMCache INFO:[0m Reqid: chatcmpl-5f63f47e3b6a46f18d6af070698d3929, Total tokens 19590, LMCache hit tokens: 10240, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '99', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '78', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '111', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,424] LMCache INFO:[0m Storing KV cache for 7936 out of 18176 tokens (skip_leading_tokens=10240) for request chatcmpl-5f63f47e3b6a46f18d6af070698d3929 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '83', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,445] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.5317 ms, throughput: 47.1831 GB/s; offload_time: 20.4977 ms, put_time: 0.0339 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 99, time is 1761207007.4482307
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 99
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 78, time is 1761207007.4483669
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 78
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207007.4484224
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 97
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 111, time is 1761207007.4484646
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 83, time is 1761207007.4485145
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 83
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,450] LMCache INFO:[0m Reqid: chatcmpl-e416845bd3c947dd86257ce00df73739, Total tokens 1108, LMCache hit tokens: 256, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,452] LMCache INFO:[0m Reqid: chatcmpl-f97f18a8beb447a895d667f70636823f, Total tokens 1585, LMCache hit tokens: 256, need to load: -384 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,453] LMCache INFO:[0m Reqid: chatcmpl-4004abe34ff24487b8659fa22e62de92, Total tokens 1103, LMCache hit tokens: 256, need to load: -304 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,454] LMCache INFO:[0m Reqid: chatcmpl-62bd5023f22d4d7fa9f0d0b543d36aaf, Total tokens 1412, LMCache hit tokens: 256, need to load: -384 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,455] LMCache INFO:[0m Reqid: chatcmpl-7dda52e1b108453294c9fa33cdc537f9, Total tokens 2454, LMCache hit tokens: 1024, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,456] LMCache INFO:[0m Reqid: chatcmpl-43eed49b8d97498b8674bf40f7076bc7, Total tokens 1271, LMCache hit tokens: 256, need to load: -320 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '149', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '52', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '151', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,616] LMCache INFO:[0m Storing KV cache for 852 out of 1108 tokens (skip_leading_tokens=256) for request chatcmpl-e416845bd3c947dd86257ce00df73739 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,619] LMCache INFO:[0m Stored 852 out of total 852 tokens. size: 0.1040 gb, cost 2.3965 ms, throughput: 43.3982 GB/s; offload_time: 2.3797 ms, put_time: 0.0168 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,619] LMCache INFO:[0m Storing KV cache for 1329 out of 1585 tokens (skip_leading_tokens=256) for request chatcmpl-f97f18a8beb447a895d667f70636823f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,622] LMCache INFO:[0m Stored 1329 out of total 1329 tokens. size: 0.1622 gb, cost 3.5253 ms, throughput: 46.0195 GB/s; offload_time: 3.5142 ms, put_time: 0.0111 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,622] LMCache INFO:[0m Storing KV cache for 847 out of 1103 tokens (skip_leading_tokens=256) for request chatcmpl-4004abe34ff24487b8659fa22e62de92 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,625] LMCache INFO:[0m Stored 847 out of total 847 tokens. size: 0.1034 gb, cost 2.2775 ms, throughput: 45.3977 GB/s; offload_time: 2.2694 ms, put_time: 0.0081 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,625] LMCache INFO:[0m Storing KV cache for 1156 out of 1412 tokens (skip_leading_tokens=256) for request chatcmpl-62bd5023f22d4d7fa9f0d0b543d36aaf [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,628] LMCache INFO:[0m Stored 1156 out of total 1156 tokens. size: 0.1411 gb, cost 3.0509 ms, throughput: 46.2537 GB/s; offload_time: 3.0412 ms, put_time: 0.0096 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,628] LMCache INFO:[0m Storing KV cache for 1430 out of 2454 tokens (skip_leading_tokens=1024) for request chatcmpl-7dda52e1b108453294c9fa33cdc537f9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,632] LMCache INFO:[0m Stored 1430 out of total 1430 tokens. size: 0.1746 gb, cost 3.7878 ms, throughput: 46.0850 GB/s; offload_time: 3.7780 ms, put_time: 0.0098 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,632] LMCache INFO:[0m Storing KV cache for 1015 out of 1271 tokens (skip_leading_tokens=256) for request chatcmpl-43eed49b8d97498b8674bf40f7076bc7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,635] LMCache INFO:[0m Stored 1015 out of total 1015 tokens. size: 0.1239 gb, cost 2.6943 ms, throughput: 45.9865 GB/s; offload_time: 2.6852 ms, put_time: 0.0091 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,635] LMCache INFO:[0m Storing KV cache for 1414 out of 19590 tokens (skip_leading_tokens=18176) for request chatcmpl-5f63f47e3b6a46f18d6af070698d3929 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,639] LMCache INFO:[0m Stored 1414 out of total 1414 tokens. size: 0.1726 gb, cost 4.3270 ms, throughput: 39.8906 GB/s; offload_time: 4.3145 ms, put_time: 0.0125 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 77, time is 1761207007.642886
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 161611776
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1209
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 77: 0.00501708984375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 77: 175114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 77: 27.044774475623164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 77: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 149, time is 1761207007.6437151
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 52, time is 1761207007.6438196
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 52
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 151, time is 1761207007.6438835
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 151
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,646] LMCache INFO:[0m Reqid: chatcmpl-6d89d9fb97d5499ab035596647b755fa, Total tokens 1538, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,647] LMCache INFO:[0m Reqid: chatcmpl-151804f855804c6b94df19f2fd17528f, Total tokens 1467, LMCache hit tokens: 256, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,648] LMCache INFO:[0m Reqid: chatcmpl-f62fc932ec2a4dd0b3f10a3c4c26c686, Total tokens 1584, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '87', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,730] LMCache INFO:[0m Storing KV cache for 1282 out of 1538 tokens (skip_leading_tokens=256) for request chatcmpl-6d89d9fb97d5499ab035596647b755fa [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,734] LMCache INFO:[0m Stored 1282 out of total 1282 tokens. size: 0.1565 gb, cost 3.5224 ms, throughput: 44.4285 GB/s; offload_time: 3.5080 ms, put_time: 0.0144 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,734] LMCache INFO:[0m Storing KV cache for 1211 out of 1467 tokens (skip_leading_tokens=256) for request chatcmpl-151804f855804c6b94df19f2fd17528f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,737] LMCache INFO:[0m Stored 1211 out of total 1211 tokens. size: 0.1478 gb, cost 3.2044 ms, throughput: 46.1331 GB/s; offload_time: 3.1939 ms, put_time: 0.0104 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,737] LMCache INFO:[0m Storing KV cache for 1328 out of 1584 tokens (skip_leading_tokens=256) for request chatcmpl-f62fc932ec2a4dd0b3f10a3c4c26c686 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,741] LMCache INFO:[0m Stored 1328 out of total 1328 tokens. size: 0.1621 gb, cost 3.5123 ms, throughput: 46.1543 GB/s; offload_time: 3.5021 ms, put_time: 0.0103 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:307] Request job id arriving: 87, time is 1761207007.7447596
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:315] Request job id: 87
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,747] LMCache INFO:[0m Reqid: chatcmpl-182989464edf4fbc9fac7733f07ad87e, Total tokens 1584, LMCache hit tokens: 256, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,800] LMCache INFO:[0m Storing KV cache for 1328 out of 1584 tokens (skip_leading_tokens=256) for request chatcmpl-182989464edf4fbc9fac7733f07ad87e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:07,804] LMCache INFO:[0m Stored 1328 out of total 1328 tokens. size: 0.1621 gb, cost 3.7036 ms, throughput: 43.7712 GB/s; offload_time: 3.6894 ms, put_time: 0.0141 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 91, time is 1761207007.8069134
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 1387266048
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 10542
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 91: 0.04306640625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 91: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 91: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 91: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 117, time is 1761207007.807317
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 161480704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1215
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 117: 0.005013020833333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 117: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 117: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 117: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 110, time is 1761207007.8074775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 176422912
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 110: 0.005476888020833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 110: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 110: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 110: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 130, time is 1761207007.8076167
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 204472320
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 130: 0.00634765625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 130: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 130: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 130: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 105, time is 1761207007.8077455
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 178126848
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 105: 0.00552978515625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 105: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 105: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 105: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 93, time is 1761207007.8078651
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 176291840
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1331
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 93: 0.005472819010416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 93: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 93: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 93: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 112, time is 1761207007.8079765
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 180224000
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1361
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 112: 0.005594889322916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 112: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 112: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 112: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 123, time is 1761207007.8080783
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 165412864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 123: 0.005135091145833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 123: 180078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 123: 28.51991031973092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 123: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 98, time is 1761207007.8335276
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 680263680
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 5149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 98: 0.0211181640625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 98: 160164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 98: 22.837916441236494
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 98: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207007.8338273
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 181141504
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1364
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 156: 0.005623372395833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 156: 160164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 156: 22.837916441236494
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 156: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 165, time is 1761207007.8339763
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 186384384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 165: 0.0057861328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 165: 160164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 165: 22.837916441236494
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 165: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 29, time is 1761207007.8341045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 145752064
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1095
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 29: 0.004524739583333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 29: 160164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 29: 22.837916441236494
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 29: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207007.859328
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 169869312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1274
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 174: 0.0052734375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 174: 151152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 174: 20.473008589663312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 174: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 17, time is 1761207007.8595703
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 179437568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1354
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 17: 0.005570475260416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 17: 151152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 17: 20.473008589663312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 17: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 128, time is 1761207007.883858
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 153747456
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 128: 0.00477294921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 128: 148524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 128: 19.80760175705979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 128: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207007.8841176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 174718976
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1311
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 5: 0.005423990885416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 5: 148524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 5: 19.80760175705979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 5: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 50, time is 1761207007.8842618
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 150339584
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1127
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 50: 0.004667154947916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 50: 148524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 50: 19.80760175705979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 50: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 107, time is 1761207007.8843765
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 206962688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1560
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 107: 0.006424967447916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 107: 148524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 107: 19.80760175705979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 107: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 142, time is 1761207007.8844962
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 195559424
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1473
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 142: 0.006070963541666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 142: 148524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 142: 19.80760175705979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 142: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207007.8846295
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 181010432
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1366
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 16: 0.0056193033854166664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 16: 148524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 16: 19.80760175705979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 16: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 39, time is 1761207007.8847406
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 146669568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 39: 0.00455322265625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 39: 148524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 39: 19.80760175705979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 39: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 169, time is 1761207007.908575
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 211156992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1595
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 169: 0.00655517578125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 169: 139454
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 169: 17.595117565934824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 169: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 15, time is 1761207007.9088688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 163971072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 15: 0.00509033203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 15: 139454
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 15: 17.595117565934824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 15: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 124, time is 1761207007.9089916
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 148373504
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1118
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 124: 0.004606119791666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 124: 139454
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 124: 17.595117565934824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 124: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207007.9091024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 969932800
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 7386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 164: 0.030110677083333332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 164: 139454
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 164: 17.595117565934824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 164: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 148, time is 1761207007.9318433
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 175767552
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1321
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 148: 0.00545654296875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 148: 128119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 148: 15.013300838656138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 148: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 30, time is 1761207007.9320822
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 144441344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 30: 0.004484049479166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 30: 128119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 30: 15.013300838656138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 30: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 35, time is 1761207007.9545457
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 173539328
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1310
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 35: 0.005387369791666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 35: 125710
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 35: 14.490815660637269
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 35: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207007.9770153
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 217972736
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1639
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 7: 0.006766764322916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 7: 124400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 7: 14.210549762992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 7: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 103, time is 1761207007.977279
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 172621824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1302
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 103: 0.00535888671875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 103: 124400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 103: 14.210549762992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 103: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207007.9774165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 191889408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1450
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 10: 0.00595703125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 10: 124400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 10: 14.210549762992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 10: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [estimate_with_func.py:328] Request job id finishing: 6, time is 1761207007.977531
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1462] Request GPU size bytes: 146800640
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1463] Token size of the request: 1106
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1469] Swap waste for job 6: 0.004557291666666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1479] Accumulated tokens for job 6: 124400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1481] Discard waste for job 6: 14.210549762992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:07 [scheduler.py:1484] Preserve waste for job 6: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 1, time is 1761207008.0002422
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 184549376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1387
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 1: 0.005729166666666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 1: 118903
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 1: 13.06413725611984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 1: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207008.0222259
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 176291840
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 79: 0.005472819010416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 79: 117516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 79: 12.782437041835083
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 79: 2.5750552730998773
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '130', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 160, time is 1761207008.0441139
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 189005824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1420
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 160: 0.005867513020833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 160: 116191
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 160: 12.51617496836024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 160: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 24, time is 1761207008.044337
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 261357568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1975
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 24: 0.008113606770833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 24: 116191
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 24: 12.51617496836024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 24: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 2, time is 1761207008.0444996
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 2569404416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 19590
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 2: 0.07976481119791666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 2: 116191
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 2: 12.51617496836024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 2: 0.7311650606302115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 130, time is 1761207008.044856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 130
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,046] LMCache INFO:[0m Reqid: chatcmpl-e38392a9a6494dd6838e2ddd87471cc1, Total tokens 2457, LMCache hit tokens: 1536, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '123', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,085] LMCache INFO:[0m Storing KV cache for 921 out of 2457 tokens (skip_leading_tokens=1536) for request chatcmpl-e38392a9a6494dd6838e2ddd87471cc1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,088] LMCache INFO:[0m Stored 921 out of total 921 tokens. size: 0.1124 gb, cost 2.6223 ms, throughput: 42.8728 GB/s; offload_time: 2.6044 ms, put_time: 0.0179 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 94, time is 1761207008.0903392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 176553984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 94: 0.00548095703125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 94: 95663
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 94: 8.746304934901595
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 94: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 123, time is 1761207008.0906446
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,092] LMCache INFO:[0m Reqid: chatcmpl-ae45778189c54fd88a5bf2988ef1d82e, Total tokens 7095, LMCache hit tokens: 1024, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '15', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '93', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58840 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '112', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '6', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '39', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,226] LMCache INFO:[0m Storing KV cache for 6071 out of 7095 tokens (skip_leading_tokens=1024) for request chatcmpl-ae45778189c54fd88a5bf2988ef1d82e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,243] LMCache INFO:[0m Stored 6071 out of total 6071 tokens. size: 0.7411 gb, cost 16.8328 ms, throughput: 44.0265 GB/s; offload_time: 16.7989 ms, put_time: 0.0340 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 121, time is 1761207008.2453969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 165675008
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1224
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 121: 0.005143229166666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 121: 101429
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 121: 9.737791632548772
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 121: 0.6683345635732015
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 15, time is 1761207008.2458663
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 15
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 93, time is 1761207008.2459538
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 93
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 112, time is 1761207008.2460022
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207008.2460475
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 16
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 6, time is 1761207008.2460895
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 6
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 39, time is 1761207008.2461336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 39
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207008.2461836
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 44
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,248] LMCache INFO:[0m Reqid: chatcmpl-28ebb61c55ab4c369caf411655b3ee61, Total tokens 3292, LMCache hit tokens: 1024, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,249] LMCache INFO:[0m Reqid: chatcmpl-1669593a4e7f44fd9e8abec96ef8b123, Total tokens 8262, LMCache hit tokens: 1280, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '2', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '1', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '35', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,426] LMCache INFO:[0m Storing KV cache for 2268 out of 3292 tokens (skip_leading_tokens=1024) for request chatcmpl-28ebb61c55ab4c369caf411655b3ee61 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '142', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,432] LMCache INFO:[0m Stored 2268 out of total 2268 tokens. size: 0.2769 gb, cost 6.5768 ms, throughput: 42.0956 GB/s; offload_time: 6.5505 ms, put_time: 0.0263 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,432] LMCache INFO:[0m Storing KV cache for 6144 out of 7424 tokens (skip_leading_tokens=1280) for request chatcmpl-1669593a4e7f44fd9e8abec96ef8b123 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '117', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,449] LMCache INFO:[0m Stored 6144 out of total 6144 tokens. size: 0.7500 gb, cost 16.2935 ms, throughput: 46.0305 GB/s; offload_time: 16.2558 ms, put_time: 0.0377 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 11, time is 1761207008.4515452
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 94765056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 393
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 11: 0.00294189453125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 11: 111759
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 11: 11.64576096027856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 11: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 152, time is 1761207008.4519718
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 208011264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1567
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 152: 0.00645751953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 152: 111759
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 152: 11.64576096027856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 152: 0.6083782586184415
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207008.4521606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 323747840
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 2454
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 97: 0.010050455729166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 97: 111759
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 97: 11.64576096027856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 97: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 2, time is 1761207008.4524271
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 2
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 1, time is 1761207008.452502
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 1
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207008.4529364
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 35, time is 1761207008.45301
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 35
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207008.4530563
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 142, time is 1761207008.453103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 117, time is 1761207008.453152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,455] LMCache INFO:[0m Reqid: chatcmpl-9a2017b991fc44c1940b79ca53a380e1, Total tokens 5095, LMCache hit tokens: 1280, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '29', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,458] LMCache INFO:[0m Reqid: chatcmpl-e568ef834ead481b943db5a95b2e71d1, Total tokens 5149, LMCache hit tokens: 1280, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '124', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '77', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '121', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,637] LMCache INFO:[0m Storing KV cache for 3815 out of 5095 tokens (skip_leading_tokens=1280) for request chatcmpl-9a2017b991fc44c1940b79ca53a380e1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '103', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,647] LMCache INFO:[0m Stored 3815 out of total 3815 tokens. size: 0.4657 gb, cost 9.9663 ms, throughput: 46.7275 GB/s; offload_time: 9.9414 ms, put_time: 0.0249 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,647] LMCache INFO:[0m Storing KV cache for 3584 out of 4864 tokens (skip_leading_tokens=1280) for request chatcmpl-e568ef834ead481b943db5a95b2e71d1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,657] LMCache INFO:[0m Stored 3584 out of total 3584 tokens. size: 0.4375 gb, cost 9.7460 ms, throughput: 44.8902 GB/s; offload_time: 9.7227 ms, put_time: 0.0233 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,657] LMCache INFO:[0m Storing KV cache for 838 out of 8262 tokens (skip_leading_tokens=7424) for request chatcmpl-1669593a4e7f44fd9e8abec96ef8b123 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,659] LMCache INFO:[0m Stored 838 out of total 838 tokens. size: 0.1023 gb, cost 2.3619 ms, throughput: 43.3106 GB/s; offload_time: 2.3512 ms, put_time: 0.0107 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 60, time is 1761207008.6621099
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 94109696
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 60: 0.0029215494791666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 60: 117589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 60: 12.797187400146308
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 60: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 146, time is 1761207008.6624358
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 585498624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 4447
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 146: 0.01817626953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 146: 117589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 146: 12.797187400146308
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 146: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 89, time is 1761207008.662632
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 210239488
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1584
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 89: 0.0065266927083333336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 89: 117589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 89: 12.797187400146308
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 89: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 29, time is 1761207008.6629705
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 29
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 124, time is 1761207008.6630523
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207008.663104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 77, time is 1761207008.6631508
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 77
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 121, time is 1761207008.6631942
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 103, time is 1761207008.663237
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,665] LMCache INFO:[0m Reqid: chatcmpl-52b88379b8d947f59eab9c5eb25589ea, Total tokens 7849, LMCache hit tokens: 1024, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,667] LMCache INFO:[0m Reqid: chatcmpl-36d1cf71e86b48beac51de8a44188a0b, Total tokens 29283, LMCache hit tokens: 1024, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '50', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '30', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '98', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '17', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,854] LMCache INFO:[0m Storing KV cache for 6825 out of 7849 tokens (skip_leading_tokens=1024) for request chatcmpl-52b88379b8d947f59eab9c5eb25589ea [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,872] LMCache INFO:[0m Stored 6825 out of total 6825 tokens. size: 0.8331 gb, cost 17.7138 ms, throughput: 47.0329 GB/s; offload_time: 17.6743 ms, put_time: 0.0394 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,873] LMCache INFO:[0m Storing KV cache for 1280 out of 2304 tokens (skip_leading_tokens=1024) for request chatcmpl-36d1cf71e86b48beac51de8a44188a0b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,876] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.8429 ms, throughput: 40.6593 GB/s; offload_time: 3.8300 ms, put_time: 0.0129 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,877] LMCache INFO:[0m Storing KV cache for 285 out of 5149 tokens (skip_leading_tokens=4864) for request chatcmpl-e568ef834ead481b943db5a95b2e71d1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:08,878] LMCache INFO:[0m Stored 285 out of total 285 tokens. size: 0.0348 gb, cost 0.8794 ms, throughput: 39.5590 GB/s; offload_time: 0.8715 ms, put_time: 0.0080 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 81, time is 1761207008.8802612
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 191102976
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1435
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 81: 0.0059326171875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 81: 148306
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 81: 19.75289575610657
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 81: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 3, time is 1761207008.8804948
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 155582464
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 3: 0.004829915364583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 3: 148306
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 3: 19.75289575610657
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 3: 0.6139408452170235
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:328] Request job id finishing: 109, time is 1761207008.8806257
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1462] Request GPU size bytes: 210108416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1463] Token size of the request: 1585
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1469] Swap waste for job 109: 0.006522623697916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1479] Accumulated tokens for job 109: 148306
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1481] Discard waste for job 109: 19.75289575610657
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [scheduler.py:1484] Preserve waste for job 109: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 50, time is 1761207008.8809547
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 50
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 30, time is 1761207008.881034
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 30
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 98, time is 1761207008.8810847
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 98
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:307] Request job id arriving: 17, time is 1761207008.881129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:08 [estimate_with_func.py:315] Request job id: 17
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '105', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,110] LMCache INFO:[0m Storing KV cache for 7936 out of 10240 tokens (skip_leading_tokens=2304) for request chatcmpl-36d1cf71e86b48beac51de8a44188a0b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,135] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 24.6170 ms, throughput: 39.3530 GB/s; offload_time: 24.5828 ms, put_time: 0.0342 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:328] Request job id finishing: 143, time is 1761207009.1372502
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1462] Request GPU size bytes: 203948032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1463] Token size of the request: 1535
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1469] Swap waste for job 143: 0.006331380208333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1479] Accumulated tokens for job 143: 144121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1481] Discard waste for job 143: 18.717284654413593
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1484] Preserve waste for job 143: 0.6539155642191569
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:328] Request job id finishing: 52, time is 1761207009.1374645
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1462] Request GPU size bytes: 194641920
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1463] Token size of the request: 1467
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1469] Swap waste for job 52: 0.00604248046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1479] Accumulated tokens for job 52: 144121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1481] Discard waste for job 52: 18.717284654413593
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1484] Preserve waste for job 52: 0.6539155642191569
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 105, time is 1761207009.1376655
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 105
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '66', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '3', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '24', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,463] LMCache INFO:[0m Storing KV cache for 8192 out of 18432 tokens (skip_leading_tokens=10240) for request chatcmpl-36d1cf71e86b48beac51de8a44188a0b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '52', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,486] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.5257 ms, throughput: 44.3938 GB/s; offload_time: 22.4773 ms, put_time: 0.0483 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:328] Request job id finishing: 111, time is 1761207009.4885466
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1462] Request GPU size bytes: 147849216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1463] Token size of the request: 1108
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1469] Swap waste for job 111: 0.00458984375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1479] Accumulated tokens for job 111: 141119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1481] Discard waste for job 111: 17.99150355521794
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1484] Preserve waste for job 111: 0.6708163857460022
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:328] Request job id finishing: 99, time is 1761207009.488779
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1462] Request GPU size bytes: 147193856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1463] Token size of the request: 1103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1469] Swap waste for job 99: 0.004569498697916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1479] Accumulated tokens for job 99: 141119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1481] Discard waste for job 99: 17.99150355521794
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [scheduler.py:1484] Preserve waste for job 99: 2.5750552730998773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 66, time is 1761207009.48903
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 66
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 3, time is 1761207009.4891136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 3
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 24, time is 1761207009.4891682
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 24
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 52, time is 1761207009.4892218
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 52
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '169', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '143', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58584 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '111', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,913] LMCache INFO:[0m Storing KV cache for 8192 out of 26624 tokens (skip_leading_tokens=18432) for request chatcmpl-36d1cf71e86b48beac51de8a44188a0b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,934] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3367 ms, throughput: 46.8677 GB/s; offload_time: 21.2977 ms, put_time: 0.0390 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 169, time is 1761207009.9371393
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 143, time is 1761207009.9372692
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:307] Request job id arriving: 111, time is 1761207009.9373262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:09 [estimate_with_func.py:315] Request job id: 111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,939] LMCache INFO:[0m Reqid: chatcmpl-88e59ffa36dd476eae6ffb9e3705d68e, Total tokens 5026, LMCache hit tokens: 1024, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:09,942] LMCache INFO:[0m Reqid: chatcmpl-0ab0d28ad705430f9b3573bb8ac468e3, Total tokens 31385, LMCache hit tokens: 19456, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '160', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '110', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58576 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '107', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,274] LMCache INFO:[0m Storing KV cache for 4002 out of 5026 tokens (skip_leading_tokens=1024) for request chatcmpl-88e59ffa36dd476eae6ffb9e3705d68e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,285] LMCache INFO:[0m Stored 4002 out of total 4002 tokens. size: 0.4885 gb, cost 10.4605 ms, throughput: 46.7019 GB/s; offload_time: 10.4324 ms, put_time: 0.0282 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,285] LMCache INFO:[0m Storing KV cache for 1792 out of 21248 tokens (skip_leading_tokens=19456) for request chatcmpl-0ab0d28ad705430f9b3573bb8ac468e3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,290] LMCache INFO:[0m Stored 1792 out of total 1792 tokens. size: 0.2188 gb, cost 4.8578 ms, throughput: 45.0309 GB/s; offload_time: 4.8426 ms, put_time: 0.0151 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,291] LMCache INFO:[0m Storing KV cache for 2659 out of 29283 tokens (skip_leading_tokens=26624) for request chatcmpl-36d1cf71e86b48beac51de8a44188a0b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,298] LMCache INFO:[0m Stored 2659 out of total 2659 tokens. size: 0.3246 gb, cost 7.2492 ms, throughput: 44.7753 GB/s; offload_time: 7.2319 ms, put_time: 0.0173 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:328] Request job id finishing: 78, time is 1761207010.3004825
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1462] Request GPU size bytes: 187957248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1463] Token size of the request: 1412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1469] Swap waste for job 78: 0.0058349609375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1479] Accumulated tokens for job 78: 175319
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1481] Discard waste for job 78: 27.10492100707006
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1484] Preserve waste for job 78: 0.6774809466467964
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 160, time is 1761207010.3011343
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 110, time is 1761207010.3012435
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 110
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 107, time is 1761207010.3012953
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 107
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '152', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:10:10 [loggers.py:123] Engine 000: Avg prompt throughput: 31051.2 tokens/s, Avg generation throughput: 2027.6 tokens/s, Running: 47 reqs, Waiting: 24 reqs, GPU KV cache usage: 14.5%, Prefix cache hit rate: 29.5%
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '91', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,770] LMCache INFO:[0m Storing KV cache for 8192 out of 29440 tokens (skip_leading_tokens=21248) for request chatcmpl-0ab0d28ad705430f9b3573bb8ac468e3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '128', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,792] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3476 ms, throughput: 46.8437 GB/s; offload_time: 21.3017 ms, put_time: 0.0459 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:328] Request job id finishing: 87, time is 1761207010.7948842
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1462] Request GPU size bytes: 210370560
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1463] Token size of the request: 1584
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1469] Swap waste for job 87: 0.00653076171875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1479] Accumulated tokens for job 87: 173907
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1481] Discard waste for job 87: 26.69199320122487
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [scheduler.py:1484] Preserve waste for job 87: 0.6774809466467964
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207010.7953122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 152, time is 1761207010.795414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207010.7954695
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 91, time is 1761207010.7955213
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 91
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207010.7955747
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 97
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207010.7956262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:307] Request job id arriving: 128, time is 1761207010.7956772
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:10 [estimate_with_func.py:315] Request job id: 128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,798] LMCache INFO:[0m Reqid: chatcmpl-dd7c3593701644c2ba5f22b1697d5513, Total tokens 1196, LMCache hit tokens: 256, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:10,799] LMCache INFO:[0m Reqid: chatcmpl-fc9f65feaab341758c7f224e23361105, Total tokens 8727, LMCache hit tokens: 1280, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '78', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '148', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,069] LMCache INFO:[0m Storing KV cache for 940 out of 1196 tokens (skip_leading_tokens=256) for request chatcmpl-dd7c3593701644c2ba5f22b1697d5513 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,072] LMCache INFO:[0m Stored 940 out of total 940 tokens. size: 0.1147 gb, cost 2.6145 ms, throughput: 43.8890 GB/s; offload_time: 2.6017 ms, put_time: 0.0127 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,072] LMCache INFO:[0m Storing KV cache for 5632 out of 6912 tokens (skip_leading_tokens=1280) for request chatcmpl-fc9f65feaab341758c7f224e23361105 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '89', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,087] LMCache INFO:[0m Stored 5632 out of total 5632 tokens. size: 0.6875 gb, cost 14.4510 ms, throughput: 47.5746 GB/s; offload_time: 14.4251 ms, put_time: 0.0259 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,087] LMCache INFO:[0m Storing KV cache for 1945 out of 31385 tokens (skip_leading_tokens=29440) for request chatcmpl-0ab0d28ad705430f9b3573bb8ac468e3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,093] LMCache INFO:[0m Stored 1945 out of total 1945 tokens. size: 0.2374 gb, cost 5.7095 ms, throughput: 41.5841 GB/s; offload_time: 5.6941 ms, put_time: 0.0155 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 78, time is 1761207011.0954285
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 78
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207011.0955546
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 5
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 148, time is 1761207011.095613
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 148
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 89, time is 1761207011.0956628
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 89
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,098] LMCache INFO:[0m Reqid: chatcmpl-72a008781c3043afaf22037c654181e8, Total tokens 19091, LMCache hit tokens: 7168, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '171', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51398 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,373] LMCache INFO:[0m Storing KV cache for 6656 out of 13824 tokens (skip_leading_tokens=7168) for request chatcmpl-72a008781c3043afaf22037c654181e8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,391] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 17.2934 ms, throughput: 46.9833 GB/s; offload_time: 17.2570 ms, put_time: 0.0364 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,391] LMCache INFO:[0m Storing KV cache for 1815 out of 8727 tokens (skip_leading_tokens=6912) for request chatcmpl-fc9f65feaab341758c7f224e23361105 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,396] LMCache INFO:[0m Stored 1815 out of total 1815 tokens. size: 0.2216 gb, cost 4.8567 ms, throughput: 45.6192 GB/s; offload_time: 4.8418 ms, put_time: 0.0149 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:328] Request job id finishing: 76, time is 1761207011.3985848
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1462] Request GPU size bytes: 964296704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1463] Token size of the request: 7317
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1469] Swap waste for job 76: 0.029935709635416665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1479] Accumulated tokens for job 76: 201337
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1481] Discard waste for job 76: 35.278890152038194
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1484] Preserve waste for job 76: 0.715427058808347
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 171, time is 1761207011.3990853
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 171
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,401] LMCache INFO:[0m Reqid: chatcmpl-b25dfbe70c334f39a00a2251c916fbc7, Total tokens 9162, LMCache hit tokens: 1280, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '81', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '11', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '94', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '76', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '99', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,700] LMCache INFO:[0m Storing KV cache for 2816 out of 4096 tokens (skip_leading_tokens=1280) for request chatcmpl-b25dfbe70c334f39a00a2251c916fbc7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '19', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,708] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 7.3698 ms, throughput: 46.6428 GB/s; offload_time: 7.3435 ms, put_time: 0.0263 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,708] LMCache INFO:[0m Storing KV cache for 5267 out of 19091 tokens (skip_leading_tokens=13824) for request chatcmpl-72a008781c3043afaf22037c654181e8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,722] LMCache INFO:[0m Stored 5267 out of total 5267 tokens. size: 0.6429 gb, cost 13.7362 ms, throughput: 46.8066 GB/s; offload_time: 13.7112 ms, put_time: 0.0250 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207011.7245357
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1462] Request GPU size bytes: 160956416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1463] Token size of the request: 1196
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1469] Swap waste for job 68: 0.004996744791666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1479] Accumulated tokens for job 68: 203182
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1481] Discard waste for job 68: 35.899240034933605
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [scheduler.py:1484] Preserve waste for job 68: 0.715427058808347
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 81, time is 1761207011.7250986
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 81
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 11, time is 1761207011.725205
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 11
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207011.725264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 94, time is 1761207011.725318
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 94
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 76, time is 1761207011.7253723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 76
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 99, time is 1761207011.7254221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 99
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 19, time is 1761207011.7254746
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 19
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,728] LMCache INFO:[0m Reqid: chatcmpl-09668b8e62b2439899c946031d1d6bf5, Total tokens 4724, LMCache hit tokens: 1024, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '109', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,942] LMCache INFO:[0m Storing KV cache for 3328 out of 4352 tokens (skip_leading_tokens=1024) for request chatcmpl-09668b8e62b2439899c946031d1d6bf5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,951] LMCache INFO:[0m Stored 3328 out of total 3328 tokens. size: 0.4062 gb, cost 8.6639 ms, throughput: 46.8898 GB/s; offload_time: 8.6435 ms, put_time: 0.0204 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,951] LMCache INFO:[0m Storing KV cache for 5066 out of 9162 tokens (skip_leading_tokens=4096) for request chatcmpl-b25dfbe70c334f39a00a2251c916fbc7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,964] LMCache INFO:[0m Stored 5066 out of total 5066 tokens. size: 0.6184 gb, cost 13.0690 ms, throughput: 47.3187 GB/s; offload_time: 13.0431 ms, put_time: 0.0259 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:307] Request job id arriving: 109, time is 1761207011.9665167
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:11 [estimate_with_func.py:315] Request job id: 109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,968] LMCache INFO:[0m Reqid: chatcmpl-daf87cf5f1b34c2592bc96875e0216b9, Total tokens 5951, LMCache hit tokens: 1280, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,970] LMCache INFO:[0m Reqid: chatcmpl-988574e651f449449280898797498a85, Total tokens 3240, LMCache hit tokens: 1024, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:11,971] LMCache INFO:[0m Reqid: chatcmpl-8bfbdf25135c4ecbaeccccb6205bde8a, Total tokens 3000, LMCache hit tokens: 1024, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,163] LMCache INFO:[0m Storing KV cache for 4671 out of 5951 tokens (skip_leading_tokens=1280) for request chatcmpl-daf87cf5f1b34c2592bc96875e0216b9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,175] LMCache INFO:[0m Stored 4671 out of total 4671 tokens. size: 0.5702 gb, cost 12.2025 ms, throughput: 46.7273 GB/s; offload_time: 12.1723 ms, put_time: 0.0302 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,175] LMCache INFO:[0m Storing KV cache for 2216 out of 3240 tokens (skip_leading_tokens=1024) for request chatcmpl-988574e651f449449280898797498a85 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,181] LMCache INFO:[0m Stored 2216 out of total 2216 tokens. size: 0.2705 gb, cost 5.7691 ms, throughput: 46.8892 GB/s; offload_time: 5.7554 ms, put_time: 0.0137 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,181] LMCache INFO:[0m Storing KV cache for 1280 out of 2304 tokens (skip_leading_tokens=1024) for request chatcmpl-8bfbdf25135c4ecbaeccccb6205bde8a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,185] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.3444 ms, throughput: 46.7193 GB/s; offload_time: 3.3344 ms, put_time: 0.0100 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,185] LMCache INFO:[0m Storing KV cache for 372 out of 4724 tokens (skip_leading_tokens=4352) for request chatcmpl-09668b8e62b2439899c946031d1d6bf5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,186] LMCache INFO:[0m Stored 372 out of total 372 tokens. size: 0.0454 gb, cost 1.0987 ms, throughput: 41.3315 GB/s; offload_time: 1.0908 ms, put_time: 0.0079 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '146', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:307] Request job id arriving: 146, time is 1761207012.1891649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:315] Request job id: 146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,191] LMCache INFO:[0m Reqid: chatcmpl-5d4ec20888de4166b49227bd129a069b, Total tokens 8431, LMCache hit tokens: 1024, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,193] LMCache INFO:[0m Reqid: chatcmpl-9297f34dbead4aa5b7818b7129746294, Total tokens 5211, LMCache hit tokens: 1280, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '60', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,413] LMCache INFO:[0m Storing KV cache for 7407 out of 8431 tokens (skip_leading_tokens=1024) for request chatcmpl-5d4ec20888de4166b49227bd129a069b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,433] LMCache INFO:[0m Stored 7407 out of total 7407 tokens. size: 0.9042 gb, cost 19.0919 ms, throughput: 47.3590 GB/s; offload_time: 19.0592 ms, put_time: 0.0327 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,433] LMCache INFO:[0m Storing KV cache for 256 out of 1536 tokens (skip_leading_tokens=1280) for request chatcmpl-9297f34dbead4aa5b7818b7129746294 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,434] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.8007 ms, throughput: 39.0301 GB/s; offload_time: 0.7153 ms, put_time: 0.0854 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,434] LMCache INFO:[0m Storing KV cache for 696 out of 3000 tokens (skip_leading_tokens=2304) for request chatcmpl-8bfbdf25135c4ecbaeccccb6205bde8a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,436] LMCache INFO:[0m Stored 696 out of total 696 tokens. size: 0.0850 gb, cost 1.9083 ms, throughput: 44.5217 GB/s; offload_time: 1.9003 ms, put_time: 0.0080 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:328] Request job id finishing: 130, time is 1761207012.4383488
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1462] Request GPU size bytes: 324141056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1463] Token size of the request: 2457
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1469] Swap waste for job 130: 0.010062662760416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1479] Accumulated tokens for job 130: 232543
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1481] Discard waste for job 130: 46.49702467385121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1484] Preserve waste for job 130: 0.7073296258846918
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:307] Request job id arriving: 60, time is 1761207012.4387705
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:315] Request job id: 60
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,444] LMCache INFO:[0m Reqid: chatcmpl-b7b08eb54bea413ba83cf6c0646ad3f2, Total tokens 4703, LMCache hit tokens: 1024, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,446] LMCache INFO:[0m Reqid: chatcmpl-0c06873dc53f4663b4a2a127bb3a26c7, Total tokens 5775, LMCache hit tokens: 1024, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '87', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,636] LMCache INFO:[0m Storing KV cache for 3679 out of 4703 tokens (skip_leading_tokens=1024) for request chatcmpl-b7b08eb54bea413ba83cf6c0646ad3f2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,646] LMCache INFO:[0m Stored 3679 out of total 3679 tokens. size: 0.4491 gb, cost 9.6161 ms, throughput: 46.7027 GB/s; offload_time: 9.5906 ms, put_time: 0.0254 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,646] LMCache INFO:[0m Storing KV cache for 1280 out of 2304 tokens (skip_leading_tokens=1024) for request chatcmpl-0c06873dc53f4663b4a2a127bb3a26c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,650] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.3528 ms, throughput: 46.6024 GB/s; offload_time: 3.3432 ms, put_time: 0.0096 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,650] LMCache INFO:[0m Storing KV cache for 3675 out of 5211 tokens (skip_leading_tokens=1536) for request chatcmpl-9297f34dbead4aa5b7818b7129746294 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,659] LMCache INFO:[0m Stored 3675 out of total 3675 tokens. size: 0.4486 gb, cost 9.7946 ms, throughput: 45.8014 GB/s; offload_time: 9.7721 ms, put_time: 0.0225 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:328] Request job id finishing: 168, time is 1761207012.6622047
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1462] Request GPU size bytes: 162922496
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1463] Token size of the request: 1175
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1469] Swap waste for job 168: 0.005057779947916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1479] Accumulated tokens for job 168: 240564
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1481] Discard waste for job 168: 49.629655464109135
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [scheduler.py:1484] Preserve waste for job 168: 0.7073296258846918
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:307] Request job id arriving: 87, time is 1761207012.66276
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:315] Request job id: 87
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,664] LMCache INFO:[0m Reqid: chatcmpl-e4e1650ea610453eb1edb87c8d6d1b4c, Total tokens 5027, LMCache hit tokens: 1280, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,666] LMCache INFO:[0m Reqid: chatcmpl-46ff9822b4f74b4b9cc3fb91b65b0a94, Total tokens 4761, LMCache hit tokens: 1024, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '130', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,877] LMCache INFO:[0m Storing KV cache for 3747 out of 5027 tokens (skip_leading_tokens=1280) for request chatcmpl-e4e1650ea610453eb1edb87c8d6d1b4c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,887] LMCache INFO:[0m Stored 3747 out of total 3747 tokens. size: 0.4574 gb, cost 9.9757 ms, throughput: 45.8510 GB/s; offload_time: 9.9525 ms, put_time: 0.0232 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,887] LMCache INFO:[0m Storing KV cache for 1024 out of 2048 tokens (skip_leading_tokens=1024) for request chatcmpl-46ff9822b4f74b4b9cc3fb91b65b0a94 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,890] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 2.6961 ms, throughput: 46.3632 GB/s; offload_time: 2.6874 ms, put_time: 0.0087 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,890] LMCache INFO:[0m Storing KV cache for 3471 out of 5775 tokens (skip_leading_tokens=2304) for request chatcmpl-0c06873dc53f4663b4a2a127bb3a26c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,899] LMCache INFO:[0m Stored 3471 out of total 3471 tokens. size: 0.4237 gb, cost 9.0296 ms, throughput: 46.9241 GB/s; offload_time: 9.0108 ms, put_time: 0.0188 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:307] Request job id arriving: 130, time is 1761207012.9016201
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:12 [estimate_with_func.py:315] Request job id: 130
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,903] LMCache INFO:[0m Reqid: chatcmpl-7b46421f64264d3a8159cd1f43d42e40, Total tokens 3557, LMCache hit tokens: 1024, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:12,905] LMCache INFO:[0m Reqid: chatcmpl-d627984d82af47f788ffafa7887ddd71, Total tokens 19017, LMCache hit tokens: 5120, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '141', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '168', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,119] LMCache INFO:[0m Storing KV cache for 2533 out of 3557 tokens (skip_leading_tokens=1024) for request chatcmpl-7b46421f64264d3a8159cd1f43d42e40 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,126] LMCache INFO:[0m Stored 2533 out of total 2533 tokens. size: 0.3092 gb, cost 6.7278 ms, throughput: 45.9595 GB/s; offload_time: 6.7055 ms, put_time: 0.0223 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,126] LMCache INFO:[0m Storing KV cache for 3072 out of 8192 tokens (skip_leading_tokens=5120) for request chatcmpl-d627984d82af47f788ffafa7887ddd71 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,134] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 7.9836 ms, throughput: 46.9715 GB/s; offload_time: 7.9679 ms, put_time: 0.0157 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,134] LMCache INFO:[0m Storing KV cache for 2713 out of 4761 tokens (skip_leading_tokens=2048) for request chatcmpl-46ff9822b4f74b4b9cc3fb91b65b0a94 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,141] LMCache INFO:[0m Stored 2713 out of total 2713 tokens. size: 0.3312 gb, cost 7.0732 ms, throughput: 46.8214 GB/s; offload_time: 7.0582 ms, put_time: 0.0149 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207013.1441808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1462] Request GPU size bytes: 171180032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1463] Token size of the request: 1261
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1469] Swap waste for job 138: 0.0053141276041666664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1479] Accumulated tokens for job 138: 271751
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1481] Discard waste for job 138: 62.77827497426019
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1484] Preserve waste for job 138: 2.8079666511432544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:328] Request job id finishing: 112, time is 1761207013.1444533
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1462] Request GPU size bytes: 669908992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1463] Token size of the request: 5095
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1469] Swap waste for job 112: 0.020796712239583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1479] Accumulated tokens for job 112: 271751
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1481] Discard waste for job 112: 62.77827497426019
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1484] Preserve waste for job 112: 2.8079666511432544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:307] Request job id arriving: 141, time is 1761207013.144825
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:315] Request job id: 141
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:307] Request job id arriving: 168, time is 1761207013.1450253
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:315] Request job id: 168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,463] LMCache INFO:[0m Storing KV cache for 8192 out of 16384 tokens (skip_leading_tokens=8192) for request chatcmpl-d627984d82af47f788ffafa7887ddd71 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,485] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.1571 ms, throughput: 47.2655 GB/s; offload_time: 21.1151 ms, put_time: 0.0420 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:328] Request job id finishing: 166, time is 1761207013.4874806
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1462] Request GPU size bytes: 154664960
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1463] Token size of the request: 1109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1469] Swap waste for job 166: 0.004801432291666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1479] Accumulated tokens for job 166: 265395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1481] Discard waste for job 166: 59.973552979157816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1484] Preserve waste for job 166: 2.850417388336999
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,490] LMCache INFO:[0m Reqid: chatcmpl-7bceb7ed93394273ac3c6ebee15f30f8, Total tokens 10046, LMCache hit tokens: 1280, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,756] LMCache INFO:[0m Storing KV cache for 5632 out of 6912 tokens (skip_leading_tokens=1280) for request chatcmpl-7bceb7ed93394273ac3c6ebee15f30f8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,771] LMCache INFO:[0m Stored 5632 out of total 5632 tokens. size: 0.6875 gb, cost 14.5542 ms, throughput: 47.2372 GB/s; offload_time: 14.5257 ms, put_time: 0.0285 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,771] LMCache INFO:[0m Storing KV cache for 2633 out of 19017 tokens (skip_leading_tokens=16384) for request chatcmpl-d627984d82af47f788ffafa7887ddd71 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,778] LMCache INFO:[0m Stored 2633 out of total 2633 tokens. size: 0.3214 gb, cost 7.0341 ms, throughput: 45.6935 GB/s; offload_time: 7.0173 ms, put_time: 0.0168 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207013.7810946
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1462] Request GPU size bytes: 148897792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1463] Token size of the request: 1064
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1469] Swap waste for job 136: 0.004622395833333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1479] Accumulated tokens for job 136: 274332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1481] Discard waste for job 136: 63.93546508778077
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1484] Preserve waste for job 136: 0.7208975623635685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [estimate_with_func.py:328] Request job id finishing: 36, time is 1761207013.7813756
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1462] Request GPU size bytes: 890634240
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1463] Token size of the request: 6756
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1469] Swap waste for job 36: 0.02764892578125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1479] Accumulated tokens for job 36: 274332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1481] Discard waste for job 36: 63.93546508778077
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:13 [scheduler.py:1484] Preserve waste for job 36: 0.7208975623635685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:13,783] LMCache INFO:[0m Reqid: chatcmpl-ce02d30494e841beb42e9ed095993195, Total tokens 10089, LMCache hit tokens: 1280, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '165', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,019] LMCache INFO:[0m Storing KV cache for 5120 out of 6400 tokens (skip_leading_tokens=1280) for request chatcmpl-ce02d30494e841beb42e9ed095993195 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,033] LMCache INFO:[0m Stored 5120 out of total 5120 tokens. size: 0.6250 gb, cost 13.2907 ms, throughput: 47.0252 GB/s; offload_time: 13.2625 ms, put_time: 0.0283 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,033] LMCache INFO:[0m Storing KV cache for 3134 out of 10046 tokens (skip_leading_tokens=6912) for request chatcmpl-7bceb7ed93394273ac3c6ebee15f30f8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,041] LMCache INFO:[0m Stored 3134 out of total 3134 tokens. size: 0.3826 gb, cost 8.2271 ms, throughput: 46.5010 GB/s; offload_time: 8.2091 ms, put_time: 0.0180 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:328] Request job id finishing: 119, time is 1761207014.0437775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1462] Request GPU size bytes: 100401152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1463] Token size of the request: 415
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1469] Swap waste for job 119: 0.003116861979166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1479] Accumulated tokens for job 119: 276601
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1481] Discard waste for job 119: 64.96148566520003
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1484] Preserve waste for job 119: 2.850417388336999
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:328] Request job id finishing: 106, time is 1761207014.0440786
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1462] Request GPU size bytes: 160563200
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1463] Token size of the request: 1183
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1469] Swap waste for job 106: 0.004984537760416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1479] Accumulated tokens for job 106: 276601
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1481] Discard waste for job 106: 64.96148566520003
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1484] Preserve waste for job 106: 0.7208975623635685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:328] Request job id finishing: 23, time is 1761207014.0442271
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1462] Request GPU size bytes: 163840000
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1463] Token size of the request: 1210
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1469] Swap waste for job 23: 0.005086263020833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1479] Accumulated tokens for job 23: 276601
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1481] Discard waste for job 23: 64.96148566520003
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1484] Preserve waste for job 23: 0.7208975623635685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:307] Request job id arriving: 165, time is 1761207014.044529
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:315] Request job id: 165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,046] LMCache INFO:[0m Reqid: chatcmpl-6dd3137be5084121bb4cad296356bffe, Total tokens 1463, LMCache hit tokens: 256, need to load: -432 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,048] LMCache INFO:[0m Reqid: chatcmpl-54fc752822244fa19df573bd230b5d64, Total tokens 16969, LMCache hit tokens: 1024, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '23', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,272] LMCache INFO:[0m Storing KV cache for 1207 out of 1463 tokens (skip_leading_tokens=256) for request chatcmpl-6dd3137be5084121bb4cad296356bffe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,276] LMCache INFO:[0m Stored 1207 out of total 1207 tokens. size: 0.1473 gb, cost 3.2949 ms, throughput: 44.7172 GB/s; offload_time: 3.2788 ms, put_time: 0.0161 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,276] LMCache INFO:[0m Storing KV cache for 3840 out of 4864 tokens (skip_leading_tokens=1024) for request chatcmpl-54fc752822244fa19df573bd230b5d64 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,286] LMCache INFO:[0m Stored 3840 out of total 3840 tokens. size: 0.4688 gb, cost 9.9090 ms, throughput: 47.3055 GB/s; offload_time: 9.8872 ms, put_time: 0.0218 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,286] LMCache INFO:[0m Storing KV cache for 3689 out of 10089 tokens (skip_leading_tokens=6400) for request chatcmpl-ce02d30494e841beb42e9ed095993195 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '36', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,297] LMCache INFO:[0m Stored 3689 out of total 3689 tokens. size: 0.4503 gb, cost 11.1010 ms, throughput: 40.5655 GB/s; offload_time: 11.0686 ms, put_time: 0.0324 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207014.3001091
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1462] Request GPU size bytes: 195166208
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1463] Token size of the request: 1445
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1469] Swap waste for job 150: 0.006058756510416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1479] Accumulated tokens for job 150: 292225
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1481] Discard waste for job 150: 72.24791975610545
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1484] Preserve waste for job 150: 2.8801534661149555
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:307] Request job id arriving: 23, time is 1761207014.3006334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:315] Request job id: 23
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:307] Request job id arriving: 36, time is 1761207014.3007216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:315] Request job id: 36
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,583] LMCache INFO:[0m Storing KV cache for 7936 out of 12800 tokens (skip_leading_tokens=4864) for request chatcmpl-54fc752822244fa19df573bd230b5d64 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,603] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.4655 ms, throughput: 47.3357 GB/s; offload_time: 20.4305 ms, put_time: 0.0350 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:328] Request job id finishing: 129, time is 1761207014.6058834
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1462] Request GPU size bytes: 173408256
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1463] Token size of the request: 1259
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1469] Swap waste for job 129: 0.00538330078125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1479] Accumulated tokens for job 129: 290780
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1481] Discard waste for job 129: 71.55780050097148
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1484] Preserve waste for job 129: 0.7083317063889414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207014.606296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:315] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,608] LMCache INFO:[0m Reqid: chatcmpl-054e518ab29248c5b4f7e4085be77139, Total tokens 22842, LMCache hit tokens: 1792, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,889] LMCache INFO:[0m Storing KV cache for 4352 out of 6144 tokens (skip_leading_tokens=1792) for request chatcmpl-054e518ab29248c5b4f7e4085be77139 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,901] LMCache INFO:[0m Stored 4352 out of total 4352 tokens. size: 0.5312 gb, cost 11.3865 ms, throughput: 46.6561 GB/s; offload_time: 11.3590 ms, put_time: 0.0275 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,901] LMCache INFO:[0m Storing KV cache for 4169 out of 16969 tokens (skip_leading_tokens=12800) for request chatcmpl-54fc752822244fa19df573bd230b5d64 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:14,912] LMCache INFO:[0m Stored 4169 out of total 4169 tokens. size: 0.5089 gb, cost 10.8972 ms, throughput: 46.7010 GB/s; offload_time: 10.8766 ms, put_time: 0.0206 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [estimate_with_func.py:328] Request job id finishing: 32, time is 1761207014.9144392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1462] Request GPU size bytes: 98959360
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1463] Token size of the request: 401
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1469] Swap waste for job 32: 0.0030721028645833335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1479] Accumulated tokens for job 32: 312363
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1481] Discard waste for job 32: 82.20987794501833
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:14 [scheduler.py:1484] Preserve waste for job 32: 2.8801534661149555
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '129', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '106', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,210] LMCache INFO:[0m Storing KV cache for 7936 out of 14080 tokens (skip_leading_tokens=6144) for request chatcmpl-054e518ab29248c5b4f7e4085be77139 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,231] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.4683 ms, throughput: 47.3292 GB/s; offload_time: 20.4279 ms, put_time: 0.0405 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:15 [estimate_with_func.py:307] Request job id arriving: 129, time is 1761207015.233494
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:15 [estimate_with_func.py:315] Request job id: 129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:15 [estimate_with_func.py:307] Request job id arriving: 106, time is 1761207015.233618
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:15 [estimate_with_func.py:315] Request job id: 106
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,634] LMCache INFO:[0m Storing KV cache for 8192 out of 22272 tokens (skip_leading_tokens=14080) for request chatcmpl-054e518ab29248c5b4f7e4085be77139 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,655] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3201 ms, throughput: 46.9041 GB/s; offload_time: 21.2778 ms, put_time: 0.0423 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:15 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207015.6582813
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:15 [estimate_with_func.py:315] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,660] LMCache INFO:[0m Reqid: chatcmpl-3751101f17df4a569d78989c8dd5a00d, Total tokens 5783, LMCache hit tokens: 1280, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,665] LMCache INFO:[0m Reqid: chatcmpl-1872bf6aeb634a65b2c1df0d881e9ef2, Total tokens 2799, LMCache hit tokens: 1536, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,667] LMCache INFO:[0m Reqid: chatcmpl-6eb7b5c4a6644e1d80581d74ed40677d, Total tokens 5245, LMCache hit tokens: 1280, need to load: -272 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,883] LMCache INFO:[0m Storing KV cache for 4503 out of 5783 tokens (skip_leading_tokens=1280) for request chatcmpl-3751101f17df4a569d78989c8dd5a00d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,895] LMCache INFO:[0m Stored 4503 out of total 4503 tokens. size: 0.5497 gb, cost 11.7715 ms, throughput: 46.6962 GB/s; offload_time: 11.7446 ms, put_time: 0.0269 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,895] LMCache INFO:[0m Storing KV cache for 1263 out of 2799 tokens (skip_leading_tokens=1536) for request chatcmpl-1872bf6aeb634a65b2c1df0d881e9ef2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,899] LMCache INFO:[0m Stored 1263 out of total 1263 tokens. size: 0.1542 gb, cost 3.3692 ms, throughput: 45.7602 GB/s; offload_time: 3.3576 ms, put_time: 0.0116 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,899] LMCache INFO:[0m Storing KV cache for 2304 out of 3584 tokens (skip_leading_tokens=1280) for request chatcmpl-6eb7b5c4a6644e1d80581d74ed40677d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,905] LMCache INFO:[0m Stored 2304 out of total 2304 tokens. size: 0.2812 gb, cost 5.9838 ms, throughput: 47.0017 GB/s; offload_time: 5.9679 ms, put_time: 0.0160 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,905] LMCache INFO:[0m Storing KV cache for 570 out of 22842 tokens (skip_leading_tokens=22272) for request chatcmpl-054e518ab29248c5b4f7e4085be77139 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,907] LMCache INFO:[0m Stored 570 out of total 570 tokens. size: 0.0696 gb, cost 1.8554 ms, throughput: 37.5018 GB/s; offload_time: 1.8442 ms, put_time: 0.0112 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,912] LMCache INFO:[0m Reqid: chatcmpl-aa1193c9ab15453589e37615328c8c82, Total tokens 1872, LMCache hit tokens: 1024, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,913] LMCache INFO:[0m Reqid: chatcmpl-caf4bcf55bb14522b41081a40c3351b3, Total tokens 2609, LMCache hit tokens: 1280, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,915] LMCache INFO:[0m Reqid: chatcmpl-e555606bce5e48e2a82c06b9500b766e, Total tokens 2590, LMCache hit tokens: 1280, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,916] LMCache INFO:[0m Reqid: chatcmpl-7aced7e7c3ba44158798a8d17b8a6b13, Total tokens 2715, LMCache hit tokens: 1536, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:15,918] LMCache INFO:[0m Reqid: chatcmpl-8d34a2b436b842519ae64dc3fa35da9e, Total tokens 13250, LMCache hit tokens: 1536, need to load: -48 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,123] LMCache INFO:[0m Storing KV cache for 848 out of 1872 tokens (skip_leading_tokens=1024) for request chatcmpl-aa1193c9ab15453589e37615328c8c82 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,126] LMCache INFO:[0m Stored 848 out of total 848 tokens. size: 0.1035 gb, cost 2.7189 ms, throughput: 38.0730 GB/s; offload_time: 2.7021 ms, put_time: 0.0168 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,126] LMCache INFO:[0m Storing KV cache for 1329 out of 2609 tokens (skip_leading_tokens=1280) for request chatcmpl-caf4bcf55bb14522b41081a40c3351b3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,129] LMCache INFO:[0m Stored 1329 out of total 1329 tokens. size: 0.1622 gb, cost 3.5502 ms, throughput: 45.6964 GB/s; offload_time: 3.5363 ms, put_time: 0.0139 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,129] LMCache INFO:[0m Storing KV cache for 1310 out of 2590 tokens (skip_leading_tokens=1280) for request chatcmpl-e555606bce5e48e2a82c06b9500b766e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,133] LMCache INFO:[0m Stored 1310 out of total 1310 tokens. size: 0.1599 gb, cost 3.4672 ms, throughput: 46.1214 GB/s; offload_time: 3.4570 ms, put_time: 0.0102 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,133] LMCache INFO:[0m Storing KV cache for 1179 out of 2715 tokens (skip_leading_tokens=1536) for request chatcmpl-7aced7e7c3ba44158798a8d17b8a6b13 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,136] LMCache INFO:[0m Stored 1179 out of total 1179 tokens. size: 0.1439 gb, cost 3.1347 ms, throughput: 45.9115 GB/s; offload_time: 3.1228 ms, put_time: 0.0119 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,136] LMCache INFO:[0m Storing KV cache for 2304 out of 3840 tokens (skip_leading_tokens=1536) for request chatcmpl-8d34a2b436b842519ae64dc3fa35da9e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,142] LMCache INFO:[0m Stored 2304 out of total 2304 tokens. size: 0.2812 gb, cost 5.9664 ms, throughput: 47.1390 GB/s; offload_time: 5.9497 ms, put_time: 0.0167 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,142] LMCache INFO:[0m Storing KV cache for 1661 out of 5245 tokens (skip_leading_tokens=3584) for request chatcmpl-6eb7b5c4a6644e1d80581d74ed40677d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,147] LMCache INFO:[0m Stored 1661 out of total 1661 tokens. size: 0.2028 gb, cost 4.7276 ms, throughput: 42.8879 GB/s; offload_time: 4.7140 ms, put_time: 0.0136 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:328] Request job id finishing: 131, time is 1761207016.150149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1462] Request GPU size bytes: 935591936
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1463] Token size of the request: 7090
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1469] Swap waste for job 131: 0.029044596354166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1479] Accumulated tokens for job 131: 348825
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1481] Discard waste for job 131: 101.88152510362644
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1484] Preserve waste for job 131: 2.876943743019773
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,428] LMCache INFO:[0m Storing KV cache for 8192 out of 12032 tokens (skip_leading_tokens=3840) for request chatcmpl-8d34a2b436b842519ae64dc3fa35da9e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,449] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.0999 ms, throughput: 47.3936 GB/s; offload_time: 21.0646 ms, put_time: 0.0353 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207016.4517665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1462] Request GPU size bytes: 159383552
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1463] Token size of the request: 1196
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1469] Swap waste for job 102: 0.0049479166666666664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1479] Accumulated tokens for job 102: 341735
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1481] Discard waste for job 102: 97.89146386410357
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1484] Preserve waste for job 102: 0.7175702112061637
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207016.452182
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:315] Request job id: 150
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,454] LMCache INFO:[0m Reqid: chatcmpl-1a5635ea479a4ff39bf8535a473e5734, Total tokens 2187, LMCache hit tokens: 1280, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,456] LMCache INFO:[0m Reqid: chatcmpl-72a4a007a64a4c88ae6d4dca73ac625a, Total tokens 20115, LMCache hit tokens: 10496, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '119', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,787] LMCache INFO:[0m Storing KV cache for 907 out of 2187 tokens (skip_leading_tokens=1280) for request chatcmpl-1a5635ea479a4ff39bf8535a473e5734 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,790] LMCache INFO:[0m Stored 907 out of total 907 tokens. size: 0.1107 gb, cost 2.6043 ms, throughput: 42.5140 GB/s; offload_time: 2.5872 ms, put_time: 0.0171 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,790] LMCache INFO:[0m Storing KV cache for 6144 out of 16640 tokens (skip_leading_tokens=10496) for request chatcmpl-72a4a007a64a4c88ae6d4dca73ac625a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,806] LMCache INFO:[0m Stored 6144 out of total 6144 tokens. size: 0.7500 gb, cost 15.8800 ms, throughput: 47.2294 GB/s; offload_time: 15.8506 ms, put_time: 0.0293 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,806] LMCache INFO:[0m Storing KV cache for 1218 out of 13250 tokens (skip_leading_tokens=12032) for request chatcmpl-8d34a2b436b842519ae64dc3fa35da9e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,809] LMCache INFO:[0m Stored 1218 out of total 1218 tokens. size: 0.1487 gb, cost 3.3767 ms, throughput: 44.0319 GB/s; offload_time: 3.3647 ms, put_time: 0.0120 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:328] Request job id finishing: 157, time is 1761207016.8121965
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1462] Request GPU size bytes: 725090304
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1463] Token size of the request: 5486
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1469] Swap waste for job 157: 0.022509765625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1479] Accumulated tokens for job 157: 362841
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1481] Discard waste for job 157: 110.00363905234542
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [scheduler.py:1484] Preserve waste for job 157: 2.870640414694081
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:307] Request job id arriving: 119, time is 1761207016.8127818
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:315] Request job id: 119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207016.812887
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:16 [estimate_with_func.py:315] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,815] LMCache INFO:[0m Reqid: chatcmpl-9e9127e73e66430c8b5446fbd9418c39, Total tokens 4213, LMCache hit tokens: 2304, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,816] LMCache INFO:[0m Reqid: chatcmpl-6695d0adee8e41a1b52a45c3e770fb91, Total tokens 2421, LMCache hit tokens: 1280, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,818] LMCache INFO:[0m Reqid: chatcmpl-d79b086db35745e5a65b9269b7c08e46, Total tokens 2111, LMCache hit tokens: 1024, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:16,819] LMCache INFO:[0m Reqid: chatcmpl-979c8568bb934ad8885328560b36ce83, Total tokens 3694, LMCache hit tokens: 1280, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,106] LMCache INFO:[0m Storing KV cache for 1909 out of 4213 tokens (skip_leading_tokens=2304) for request chatcmpl-9e9127e73e66430c8b5446fbd9418c39 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,112] LMCache INFO:[0m Stored 1909 out of total 1909 tokens. size: 0.2330 gb, cost 5.1721 ms, throughput: 45.0555 GB/s; offload_time: 5.1497 ms, put_time: 0.0224 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,112] LMCache INFO:[0m Storing KV cache for 1141 out of 2421 tokens (skip_leading_tokens=1280) for request chatcmpl-6695d0adee8e41a1b52a45c3e770fb91 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,115] LMCache INFO:[0m Stored 1141 out of total 1141 tokens. size: 0.1393 gb, cost 3.0546 ms, throughput: 45.5974 GB/s; offload_time: 3.0425 ms, put_time: 0.0121 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,115] LMCache INFO:[0m Storing KV cache for 1087 out of 2111 tokens (skip_leading_tokens=1024) for request chatcmpl-d79b086db35745e5a65b9269b7c08e46 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,118] LMCache INFO:[0m Stored 1087 out of total 1087 tokens. size: 0.1327 gb, cost 2.8964 ms, throughput: 45.8121 GB/s; offload_time: 2.8845 ms, put_time: 0.0119 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,118] LMCache INFO:[0m Storing KV cache for 1024 out of 2304 tokens (skip_leading_tokens=1280) for request chatcmpl-979c8568bb934ad8885328560b36ce83 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,121] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 2.7027 ms, throughput: 46.2500 GB/s; offload_time: 2.6922 ms, put_time: 0.0105 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,121] LMCache INFO:[0m Storing KV cache for 3475 out of 20115 tokens (skip_leading_tokens=16640) for request chatcmpl-72a4a007a64a4c88ae6d4dca73ac625a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,130] LMCache INFO:[0m Stored 3475 out of total 3475 tokens. size: 0.4242 gb, cost 9.1734 ms, throughput: 46.2417 GB/s; offload_time: 9.1528 ms, put_time: 0.0206 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,135] LMCache INFO:[0m Reqid: chatcmpl-f74d41ab93014559a2adc220b7051386, Total tokens 2231, LMCache hit tokens: 1280, need to load: -48 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,136] LMCache INFO:[0m Reqid: chatcmpl-d7602c761aed46eda7a0e97e84469885, Total tokens 2741, LMCache hit tokens: 1280, need to load: -48 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,138] LMCache INFO:[0m Reqid: chatcmpl-56aa00b3fec04cf3b8f65ef8545507a7, Total tokens 2704, LMCache hit tokens: 1536, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,139] LMCache INFO:[0m Reqid: chatcmpl-4626466ec04d496ab3d17fe72e2f3eee, Total tokens 1513, LMCache hit tokens: 256, need to load: -384 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,141] LMCache INFO:[0m Reqid: chatcmpl-03bc71bfa83946f9bda17ea3053a4dd8, Total tokens 2337, LMCache hit tokens: 1280, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,142] LMCache INFO:[0m Reqid: chatcmpl-3b7dfe5a477c468699405156f0841208, Total tokens 1544, LMCache hit tokens: 256, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,143] LMCache INFO:[0m Reqid: chatcmpl-5b274e58862a48dd94998e84dbc707d1, Total tokens 2470, LMCache hit tokens: 1536, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '112', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,345] LMCache INFO:[0m Storing KV cache for 951 out of 2231 tokens (skip_leading_tokens=1280) for request chatcmpl-f74d41ab93014559a2adc220b7051386 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,348] LMCache INFO:[0m Stored 951 out of total 951 tokens. size: 0.1161 gb, cost 2.6480 ms, throughput: 43.8397 GB/s; offload_time: 2.6352 ms, put_time: 0.0128 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,348] LMCache INFO:[0m Storing KV cache for 1461 out of 2741 tokens (skip_leading_tokens=1280) for request chatcmpl-d7602c761aed46eda7a0e97e84469885 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,352] LMCache INFO:[0m Stored 1461 out of total 1461 tokens. size: 0.1783 gb, cost 3.8624 ms, throughput: 46.1742 GB/s; offload_time: 3.8513 ms, put_time: 0.0111 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,352] LMCache INFO:[0m Storing KV cache for 1168 out of 2704 tokens (skip_leading_tokens=1536) for request chatcmpl-56aa00b3fec04cf3b8f65ef8545507a7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,355] LMCache INFO:[0m Stored 1168 out of total 1168 tokens. size: 0.1426 gb, cost 3.1002 ms, throughput: 45.9900 GB/s; offload_time: 3.0895 ms, put_time: 0.0107 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,355] LMCache INFO:[0m Storing KV cache for 1257 out of 1513 tokens (skip_leading_tokens=256) for request chatcmpl-4626466ec04d496ab3d17fe72e2f3eee [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,358] LMCache INFO:[0m Stored 1257 out of total 1257 tokens. size: 0.1534 gb, cost 3.3069 ms, throughput: 46.4007 GB/s; offload_time: 3.2968 ms, put_time: 0.0101 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,358] LMCache INFO:[0m Storing KV cache for 1057 out of 2337 tokens (skip_leading_tokens=1280) for request chatcmpl-03bc71bfa83946f9bda17ea3053a4dd8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,361] LMCache INFO:[0m Stored 1057 out of total 1057 tokens. size: 0.1290 gb, cost 2.8107 ms, throughput: 45.9066 GB/s; offload_time: 2.7985 ms, put_time: 0.0121 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,361] LMCache INFO:[0m Storing KV cache for 1288 out of 1544 tokens (skip_leading_tokens=256) for request chatcmpl-3b7dfe5a477c468699405156f0841208 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,365] LMCache INFO:[0m Stored 1288 out of total 1288 tokens. size: 0.1572 gb, cost 3.4274 ms, throughput: 45.8736 GB/s; offload_time: 3.4170 ms, put_time: 0.0104 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,365] LMCache INFO:[0m Storing KV cache for 512 out of 2048 tokens (skip_leading_tokens=1536) for request chatcmpl-5b274e58862a48dd94998e84dbc707d1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,366] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.3834 ms, throughput: 45.1785 GB/s; offload_time: 1.3769 ms, put_time: 0.0065 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,366] LMCache INFO:[0m Storing KV cache for 1390 out of 3694 tokens (skip_leading_tokens=2304) for request chatcmpl-979c8568bb934ad8885328560b36ce83 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,370] LMCache INFO:[0m Stored 1390 out of total 1390 tokens. size: 0.1697 gb, cost 3.9551 ms, throughput: 42.9011 GB/s; offload_time: 3.9410 ms, put_time: 0.0141 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:17 [estimate_with_func.py:307] Request job id arriving: 112, time is 1761207017.3736794
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:17 [estimate_with_func.py:315] Request job id: 112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,375] LMCache INFO:[0m Reqid: chatcmpl-4da3ada82d694badb7223d91dfcd9293, Total tokens 2336, LMCache hit tokens: 1280, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,377] LMCache INFO:[0m Reqid: chatcmpl-c7d08a28c70d4076a2424987ab782f5e, Total tokens 19042, LMCache hit tokens: 7168, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '32', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,675] LMCache INFO:[0m Storing KV cache for 1056 out of 2336 tokens (skip_leading_tokens=1280) for request chatcmpl-4da3ada82d694badb7223d91dfcd9293 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,679] LMCache INFO:[0m Stored 1056 out of total 1056 tokens. size: 0.1289 gb, cost 3.0212 ms, throughput: 42.6676 GB/s; offload_time: 3.0027 ms, put_time: 0.0185 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,679] LMCache INFO:[0m Storing KV cache for 6912 out of 14080 tokens (skip_leading_tokens=7168) for request chatcmpl-c7d08a28c70d4076a2424987ab782f5e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,697] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 17.7935 ms, throughput: 47.4190 GB/s; offload_time: 17.7601 ms, put_time: 0.0334 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,697] LMCache INFO:[0m Storing KV cache for 422 out of 2470 tokens (skip_leading_tokens=2048) for request chatcmpl-5b274e58862a48dd94998e84dbc707d1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,698] LMCache INFO:[0m Stored 422 out of total 422 tokens. size: 0.0515 gb, cost 1.2109 ms, throughput: 42.5426 GB/s; offload_time: 1.2019 ms, put_time: 0.0090 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:17 [estimate_with_func.py:307] Request job id arriving: 32, time is 1761207017.7015064
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:17 [estimate_with_func.py:315] Request job id: 32
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,703] LMCache INFO:[0m Reqid: chatcmpl-7580c6fa99e94e8780bb80721360cb5c, Total tokens 2100, LMCache hit tokens: 1024, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,705] LMCache INFO:[0m Reqid: chatcmpl-515b657ccc0647ce94151c25ad568a8f, Total tokens 1186, LMCache hit tokens: 256, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,707] LMCache INFO:[0m Reqid: chatcmpl-8455d34450fc42d682383ab2dfe6db68, Total tokens 2741, LMCache hit tokens: 1536, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:17,708] LMCache INFO:[0m Reqid: chatcmpl-7cca527dd7e44e4f91ea6bd718a88d4a, Total tokens 7831, LMCache hit tokens: 4352, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,022] LMCache INFO:[0m Storing KV cache for 1076 out of 2100 tokens (skip_leading_tokens=1024) for request chatcmpl-7580c6fa99e94e8780bb80721360cb5c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,025] LMCache INFO:[0m Stored 1076 out of total 1076 tokens. size: 0.1313 gb, cost 2.9646 ms, throughput: 44.3061 GB/s; offload_time: 2.9453 ms, put_time: 0.0192 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,026] LMCache INFO:[0m Storing KV cache for 930 out of 1186 tokens (skip_leading_tokens=256) for request chatcmpl-515b657ccc0647ce94151c25ad568a8f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,028] LMCache INFO:[0m Stored 930 out of total 930 tokens. size: 0.1135 gb, cost 2.4924 ms, throughput: 45.5488 GB/s; offload_time: 2.4831 ms, put_time: 0.0093 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,028] LMCache INFO:[0m Storing KV cache for 1205 out of 2741 tokens (skip_leading_tokens=1536) for request chatcmpl-8455d34450fc42d682383ab2dfe6db68 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,032] LMCache INFO:[0m Stored 1205 out of total 1205 tokens. size: 0.1471 gb, cost 3.2075 ms, throughput: 45.8591 GB/s; offload_time: 3.1949 ms, put_time: 0.0127 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,032] LMCache INFO:[0m Storing KV cache for 512 out of 4864 tokens (skip_leading_tokens=4352) for request chatcmpl-7cca527dd7e44e4f91ea6bd718a88d4a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,033] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.4148 ms, throughput: 44.1750 GB/s; offload_time: 1.4071 ms, put_time: 0.0077 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,033] LMCache INFO:[0m Storing KV cache for 4962 out of 19042 tokens (skip_leading_tokens=14080) for request chatcmpl-c7d08a28c70d4076a2424987ab782f5e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,046] LMCache INFO:[0m Stored 4962 out of total 4962 tokens. size: 0.6057 gb, cost 13.0573 ms, throughput: 46.3887 GB/s; offload_time: 13.0274 ms, put_time: 0.0300 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,052] LMCache INFO:[0m Reqid: chatcmpl-d7d851ed12f94b71ac5b9edd43ca603b, Total tokens 1578, LMCache hit tokens: 256, need to load: -336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,053] LMCache INFO:[0m Reqid: chatcmpl-da69efd36edd4fcbbb6f320339dec232, Total tokens 9205, LMCache hit tokens: 1536, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,286] LMCache INFO:[0m Storing KV cache for 1322 out of 1578 tokens (skip_leading_tokens=256) for request chatcmpl-d7d851ed12f94b71ac5b9edd43ca603b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,290] LMCache INFO:[0m Stored 1322 out of total 1322 tokens. size: 0.1614 gb, cost 3.7403 ms, throughput: 43.1451 GB/s; offload_time: 3.7170 ms, put_time: 0.0234 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,291] LMCache INFO:[0m Storing KV cache for 4352 out of 5888 tokens (skip_leading_tokens=1536) for request chatcmpl-da69efd36edd4fcbbb6f320339dec232 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,302] LMCache INFO:[0m Stored 4352 out of total 4352 tokens. size: 0.5312 gb, cost 11.2212 ms, throughput: 47.3435 GB/s; offload_time: 11.1978 ms, put_time: 0.0234 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,302] LMCache INFO:[0m Storing KV cache for 2967 out of 7831 tokens (skip_leading_tokens=4864) for request chatcmpl-7cca527dd7e44e4f91ea6bd718a88d4a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,310] LMCache INFO:[0m Stored 2967 out of total 2967 tokens. size: 0.3622 gb, cost 7.7580 ms, throughput: 46.6851 GB/s; offload_time: 7.7404 ms, put_time: 0.0176 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207018.3131952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1462] Request GPU size bytes: 622067712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1463] Token size of the request: 4724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1469] Swap waste for job 174: 0.0193115234375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1479] Accumulated tokens for job 174: 431353
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1481] Discard waste for job 174: 154.18357737096568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1484] Preserve waste for job 174: 0.7113160585102282
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,316] LMCache INFO:[0m Reqid: chatcmpl-104c5871f0cb4bb5b69151b9a0b4bf1e, Total tokens 6300, LMCache hit tokens: 2304, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,317] LMCache INFO:[0m Reqid: chatcmpl-d713834df80e444282fd7c30e2a55ac6, Total tokens 1415, LMCache hit tokens: 256, need to load: -432 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,319] LMCache INFO:[0m Reqid: chatcmpl-45183f5ccb8e4375b70ecde69a5df42e, Total tokens 4030, LMCache hit tokens: 1024, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,569] LMCache INFO:[0m Storing KV cache for 3996 out of 6300 tokens (skip_leading_tokens=2304) for request chatcmpl-104c5871f0cb4bb5b69151b9a0b4bf1e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,580] LMCache INFO:[0m Stored 3996 out of total 3996 tokens. size: 0.4878 gb, cost 10.5299 ms, throughput: 46.3247 GB/s; offload_time: 10.5025 ms, put_time: 0.0273 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,580] LMCache INFO:[0m Storing KV cache for 1159 out of 1415 tokens (skip_leading_tokens=256) for request chatcmpl-d713834df80e444282fd7c30e2a55ac6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,583] LMCache INFO:[0m Stored 1159 out of total 1159 tokens. size: 0.1415 gb, cost 3.0886 ms, throughput: 45.8068 GB/s; offload_time: 3.0778 ms, put_time: 0.0108 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,583] LMCache INFO:[0m Storing KV cache for 512 out of 1536 tokens (skip_leading_tokens=1024) for request chatcmpl-45183f5ccb8e4375b70ecde69a5df42e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,585] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.3981 ms, throughput: 44.7043 GB/s; offload_time: 1.3899 ms, put_time: 0.0081 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,585] LMCache INFO:[0m Storing KV cache for 3317 out of 9205 tokens (skip_leading_tokens=5888) for request chatcmpl-da69efd36edd4fcbbb6f320339dec232 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,594] LMCache INFO:[0m Stored 3317 out of total 3317 tokens. size: 0.4049 gb, cost 8.6555 ms, throughput: 46.7805 GB/s; offload_time: 8.6379 ms, put_time: 0.0176 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [estimate_with_func.py:328] Request job id finishing: 142, time is 1761207018.5970242
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1462] Request GPU size bytes: 783024128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1463] Token size of the request: 5951
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1469] Swap waste for job 142: 0.024308268229166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1479] Accumulated tokens for job 142: 438374
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1481] Discard waste for job 142: 159.13106977416473
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1484] Preserve waste for job 142: 0.7113160585102282
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,602] LMCache INFO:[0m Reqid: chatcmpl-fb740dec1bd949ae93941e06e60a470a, Total tokens 2411, LMCache hit tokens: 1280, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,604] LMCache INFO:[0m Reqid: chatcmpl-67db9b1590db4e29a1fb0d71ab5d1378, Total tokens 8688, LMCache hit tokens: 1024, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,831] LMCache INFO:[0m Storing KV cache for 1131 out of 2411 tokens (skip_leading_tokens=1280) for request chatcmpl-fb740dec1bd949ae93941e06e60a470a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,834] LMCache INFO:[0m Stored 1131 out of total 1131 tokens. size: 0.1381 gb, cost 3.1976 ms, throughput: 43.1764 GB/s; offload_time: 3.1747 ms, put_time: 0.0230 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,834] LMCache INFO:[0m Storing KV cache for 4608 out of 5632 tokens (skip_leading_tokens=1024) for request chatcmpl-67db9b1590db4e29a1fb0d71ab5d1378 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,846] LMCache INFO:[0m Stored 4608 out of total 4608 tokens. size: 0.5625 gb, cost 11.8749 ms, throughput: 47.3688 GB/s; offload_time: 11.8423 ms, put_time: 0.0327 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,846] LMCache INFO:[0m Storing KV cache for 2494 out of 4030 tokens (skip_leading_tokens=1536) for request chatcmpl-45183f5ccb8e4375b70ecde69a5df42e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,853] LMCache INFO:[0m Stored 2494 out of total 2494 tokens. size: 0.3044 gb, cost 6.5182 ms, throughput: 46.7067 GB/s; offload_time: 6.5037 ms, put_time: 0.0145 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [estimate_with_func.py:328] Request job id finishing: 50, time is 1761207018.8566618
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1462] Request GPU size bytes: 626655232
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1463] Token size of the request: 4761
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1469] Swap waste for job 50: 0.019453938802083334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1479] Accumulated tokens for job 50: 443522
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1481] Discard waste for job 50: 162.8083287944114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [scheduler.py:1484] Preserve waste for job 50: 0.7113160585102282
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207018.8573673
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:18 [estimate_with_func.py:315] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:18,860] LMCache INFO:[0m Reqid: chatcmpl-a1938cf05b724ff787a4b0f13cbd849f, Total tokens 13043, LMCache hit tokens: 6656, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,157] LMCache INFO:[0m Storing KV cache for 5376 out of 12032 tokens (skip_leading_tokens=6656) for request chatcmpl-a1938cf05b724ff787a4b0f13cbd849f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,171] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 14.1682 ms, throughput: 46.3185 GB/s; offload_time: 14.1287 ms, put_time: 0.0395 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,172] LMCache INFO:[0m Storing KV cache for 3056 out of 8688 tokens (skip_leading_tokens=5632) for request chatcmpl-67db9b1590db4e29a1fb0d71ab5d1378 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,180] LMCache INFO:[0m Stored 3056 out of total 3056 tokens. size: 0.3730 gb, cost 7.9983 ms, throughput: 46.6409 GB/s; offload_time: 7.9801 ms, put_time: 0.0182 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '142', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:19 [estimate_with_func.py:328] Request job id finishing: 118, time is 1761207019.184554
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:19 [estimate_with_func.py:307] Request job id arriving: 142, time is 1761207019.185228
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:19 [estimate_with_func.py:315] Request job id: 142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,188] LMCache INFO:[0m Reqid: chatcmpl-65e025eebe344c75af178a47af11aced, Total tokens 5309, LMCache hit tokens: 1024, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,189] LMCache INFO:[0m Reqid: chatcmpl-f6f01f8a02ff4911ad65a6800a61204f, Total tokens 5124, LMCache hit tokens: 1024, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '50', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,434] LMCache INFO:[0m Storing KV cache for 4285 out of 5309 tokens (skip_leading_tokens=1024) for request chatcmpl-65e025eebe344c75af178a47af11aced [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,446] LMCache INFO:[0m Stored 4285 out of total 4285 tokens. size: 0.5231 gb, cost 11.1478 ms, throughput: 46.9214 GB/s; offload_time: 11.1255 ms, put_time: 0.0223 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,446] LMCache INFO:[0m Storing KV cache for 3072 out of 4096 tokens (skip_leading_tokens=1024) for request chatcmpl-f6f01f8a02ff4911ad65a6800a61204f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,454] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 7.9195 ms, throughput: 47.3514 GB/s; offload_time: 7.9033 ms, put_time: 0.0162 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,454] LMCache INFO:[0m Storing KV cache for 1011 out of 13043 tokens (skip_leading_tokens=12032) for request chatcmpl-a1938cf05b724ff787a4b0f13cbd849f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,457] LMCache INFO:[0m Stored 1011 out of total 1011 tokens. size: 0.1234 gb, cost 2.8303 ms, throughput: 43.6037 GB/s; offload_time: 2.8190 ms, put_time: 0.0114 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:19 [estimate_with_func.py:307] Request job id arriving: 50, time is 1761207019.4603593
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:19 [estimate_with_func.py:315] Request job id: 50
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,462] LMCache INFO:[0m Reqid: chatcmpl-d4911ce62a3b491ea775502d0080175c, Total tokens 9865, LMCache hit tokens: 1024, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '131', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,714] LMCache INFO:[0m Storing KV cache for 7424 out of 8448 tokens (skip_leading_tokens=1024) for request chatcmpl-d4911ce62a3b491ea775502d0080175c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,733] LMCache INFO:[0m Stored 7424 out of total 7424 tokens. size: 0.9062 gb, cost 19.1102 ms, throughput: 47.4224 GB/s; offload_time: 19.0674 ms, put_time: 0.0428 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,733] LMCache INFO:[0m Storing KV cache for 1028 out of 5124 tokens (skip_leading_tokens=4096) for request chatcmpl-f6f01f8a02ff4911ad65a6800a61204f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,736] LMCache INFO:[0m Stored 1028 out of total 1028 tokens. size: 0.1255 gb, cost 2.8107 ms, throughput: 44.6459 GB/s; offload_time: 2.7992 ms, put_time: 0.0115 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:19 [estimate_with_func.py:307] Request job id arriving: 131, time is 1761207019.739984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:19 [estimate_with_func.py:315] Request job id: 131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,742] LMCache INFO:[0m Reqid: chatcmpl-9378aa58a74b4907bc18248b24ed76a2, Total tokens 2618, LMCache hit tokens: 1024, need to load: -272 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,744] LMCache INFO:[0m Reqid: chatcmpl-9a9fa2997eff461784b89b39b76e9e0c, Total tokens 2623, LMCache hit tokens: 1280, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,745] LMCache INFO:[0m Reqid: chatcmpl-0d62ce34a5cd4b65afba4812c802f0d7, Total tokens 1735, LMCache hit tokens: 256, need to load: -496 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,746] LMCache INFO:[0m Reqid: chatcmpl-37ea633e9eac40dbac449a3bd2e2f879, Total tokens 2411, LMCache hit tokens: 1024, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,748] LMCache INFO:[0m Reqid: chatcmpl-17c06d9749ed4ef881e6c5d2b17d81ef, Total tokens 9140, LMCache hit tokens: 4864, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,988] LMCache INFO:[0m Storing KV cache for 1594 out of 2618 tokens (skip_leading_tokens=1024) for request chatcmpl-9378aa58a74b4907bc18248b24ed76a2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,993] LMCache INFO:[0m Stored 1594 out of total 1594 tokens. size: 0.1946 gb, cost 4.3917 ms, throughput: 44.3064 GB/s; offload_time: 4.3660 ms, put_time: 0.0257 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,993] LMCache INFO:[0m Storing KV cache for 1343 out of 2623 tokens (skip_leading_tokens=1280) for request chatcmpl-9a9fa2997eff461784b89b39b76e9e0c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,996] LMCache INFO:[0m Stored 1343 out of total 1343 tokens. size: 0.1639 gb, cost 3.5772 ms, throughput: 45.8298 GB/s; offload_time: 3.5652 ms, put_time: 0.0119 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:19,997] LMCache INFO:[0m Storing KV cache for 1479 out of 1735 tokens (skip_leading_tokens=256) for request chatcmpl-0d62ce34a5cd4b65afba4812c802f0d7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,000] LMCache INFO:[0m Stored 1479 out of total 1479 tokens. size: 0.1805 gb, cost 3.8898 ms, throughput: 46.4142 GB/s; offload_time: 3.8791 ms, put_time: 0.0107 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,001] LMCache INFO:[0m Storing KV cache for 1387 out of 2411 tokens (skip_leading_tokens=1024) for request chatcmpl-37ea633e9eac40dbac449a3bd2e2f879 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,004] LMCache INFO:[0m Stored 1387 out of total 1387 tokens. size: 0.1693 gb, cost 3.6519 ms, throughput: 46.3621 GB/s; offload_time: 3.6418 ms, put_time: 0.0101 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,004] LMCache INFO:[0m Storing KV cache for 2048 out of 6912 tokens (skip_leading_tokens=4864) for request chatcmpl-17c06d9749ed4ef881e6c5d2b17d81ef [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,010] LMCache INFO:[0m Stored 2048 out of total 2048 tokens. size: 0.2500 gb, cost 5.3446 ms, throughput: 46.7766 GB/s; offload_time: 5.3320 ms, put_time: 0.0125 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,010] LMCache INFO:[0m Storing KV cache for 1417 out of 9865 tokens (skip_leading_tokens=8448) for request chatcmpl-d4911ce62a3b491ea775502d0080175c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,014] LMCache INFO:[0m Stored 1417 out of total 1417 tokens. size: 0.1730 gb, cost 3.8276 ms, throughput: 45.1907 GB/s; offload_time: 3.8161 ms, put_time: 0.0115 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:328] Request job id finishing: 104, time is 1761207020.017267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1462] Request GPU size bytes: 185466880
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1463] Token size of the request: 1347
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1469] Swap waste for job 104: 0.005757649739583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1479] Accumulated tokens for job 104: 490246
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1481] Discard waste for job 104: 198.1031762636621
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1484] Preserve waste for job 104: 2.886545397654301
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:328] Request job id finishing: 66, time is 1761207020.0176103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1462] Request GPU size bytes: 194379776
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1463] Token size of the request: 1463
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1469] Swap waste for job 66: 0.006034342447916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1479] Accumulated tokens for job 66: 490246
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1481] Discard waste for job 66: 198.1031762636621
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1484] Preserve waste for job 66: 2.886545397654301
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:328] Request job id finishing: 169, time is 1761207020.0177677
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1462] Request GPU size bytes: 368836608
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1463] Token size of the request: 2799
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1469] Swap waste for job 169: 0.0114501953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1479] Accumulated tokens for job 169: 490246
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1481] Discard waste for job 169: 198.1031762636621
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1484] Preserve waste for job 169: 0.7046846985816956
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,020] LMCache INFO:[0m Reqid: chatcmpl-448a17d627004c97a7655b3260583662, Total tokens 1607, LMCache hit tokens: 256, need to load: -496 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,022] LMCache INFO:[0m Reqid: chatcmpl-b2c5229ec20f40cf8233b51cc1ff75ba, Total tokens 11020, LMCache hit tokens: 4608, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '157', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,306] LMCache INFO:[0m Storing KV cache for 1351 out of 1607 tokens (skip_leading_tokens=256) for request chatcmpl-448a17d627004c97a7655b3260583662 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,310] LMCache INFO:[0m Stored 1351 out of total 1351 tokens. size: 0.1649 gb, cost 3.6354 ms, throughput: 45.3647 GB/s; offload_time: 3.6211 ms, put_time: 0.0143 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,310] LMCache INFO:[0m Storing KV cache for 5376 out of 9984 tokens (skip_leading_tokens=4608) for request chatcmpl-b2c5229ec20f40cf8233b51cc1ff75ba [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,324] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 13.8460 ms, throughput: 47.3963 GB/s; offload_time: 13.8208 ms, put_time: 0.0252 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,324] LMCache INFO:[0m Storing KV cache for 2228 out of 9140 tokens (skip_leading_tokens=6912) for request chatcmpl-17c06d9749ed4ef881e6c5d2b17d81ef [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,330] LMCache INFO:[0m Stored 2228 out of total 2228 tokens. size: 0.2720 gb, cost 5.8712 ms, throughput: 46.3229 GB/s; offload_time: 5.8558 ms, put_time: 0.0154 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '169', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207020.3329272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1462] Request GPU size bytes: 159383552
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1463] Token size of the request: 1123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1469] Swap waste for job 133: 0.0049479166666666664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1479] Accumulated tokens for job 133: 497264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1481] Discard waste for job 133: 203.70321007446086
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1484] Preserve waste for job 133: 2.886545397654301
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:307] Request job id arriving: 157, time is 1761207020.3349986
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:315] Request job id: 157
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:307] Request job id arriving: 169, time is 1761207020.335104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:315] Request job id: 169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,337] LMCache INFO:[0m Reqid: chatcmpl-b3a70b8ab147404a898bc105f9c99571, Total tokens 13461, LMCache hit tokens: 5888, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:10:20 [loggers.py:123] Engine 000: Avg prompt throughput: 41381.9 tokens/s, Avg generation throughput: 208.9 tokens/s, Running: 86 reqs, Waiting: 3 reqs, GPU KV cache usage: 43.3%, Prefix cache hit rate: 30.8%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,654] LMCache INFO:[0m Storing KV cache for 7168 out of 13056 tokens (skip_leading_tokens=5888) for request chatcmpl-b3a70b8ab147404a898bc105f9c99571 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,673] LMCache INFO:[0m Stored 7168 out of total 7168 tokens. size: 0.8750 gb, cost 18.4997 ms, throughput: 47.2981 GB/s; offload_time: 18.4574 ms, put_time: 0.0423 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,673] LMCache INFO:[0m Storing KV cache for 1036 out of 11020 tokens (skip_leading_tokens=9984) for request chatcmpl-b2c5229ec20f40cf8233b51cc1ff75ba [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,676] LMCache INFO:[0m Stored 1036 out of total 1036 tokens. size: 0.1265 gb, cost 2.9006 ms, throughput: 43.5996 GB/s; offload_time: 2.8881 ms, put_time: 0.0125 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:328] Request job id finishing: 29, time is 1761207020.6792328
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1462] Request GPU size bytes: 397017088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1463] Token size of the request: 3000
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1469] Swap waste for job 29: 0.012325032552083334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1479] Accumulated tokens for job 29: 509602
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1481] Discard waste for job 29: 213.73749087901243
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1484] Preserve waste for job 29: 0.6983350495823094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:328] Request job id finishing: 24, time is 1761207020.6795497
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1462] Request GPU size bytes: 2996174848
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1463] Token size of the request: 22842
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1469] Swap waste for job 24: 0.09301350911458334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1479] Accumulated tokens for job 24: 509602
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1481] Discard waste for job 24: 213.73749087901243
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1484] Preserve waste for job 24: 0.6983350495823094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207020.679939
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1462] Request GPU size bytes: 288489472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1463] Token size of the request: 2187
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1469] Swap waste for job 79: 0.008955891927083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1479] Accumulated tokens for job 79: 509602
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1481] Discard waste for job 79: 213.73749087901243
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:20 [scheduler.py:1484] Preserve waste for job 79: 0.6983350495823094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,682] LMCache INFO:[0m Reqid: chatcmpl-17a0595460cc409cbfbb9f733e081b97, Total tokens 11448, LMCache hit tokens: 4608, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,685] LMCache INFO:[0m Reqid: chatcmpl-6dcda34c2d0c41db839af0f909b8d272, Total tokens 13401, LMCache hit tokens: 6912, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:20,986] LMCache INFO:[0m Storing KV cache for 6840 out of 11448 tokens (skip_leading_tokens=4608) for request chatcmpl-17a0595460cc409cbfbb9f733e081b97 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,004] LMCache INFO:[0m Stored 6840 out of total 6840 tokens. size: 0.8350 gb, cost 17.8109 ms, throughput: 46.8793 GB/s; offload_time: 17.7723 ms, put_time: 0.0386 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,004] LMCache INFO:[0m Storing KV cache for 1024 out of 7936 tokens (skip_leading_tokens=6912) for request chatcmpl-6dcda34c2d0c41db839af0f909b8d272 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,007] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 2.7854 ms, throughput: 44.8776 GB/s; offload_time: 2.7740 ms, put_time: 0.0114 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,007] LMCache INFO:[0m Storing KV cache for 405 out of 13461 tokens (skip_leading_tokens=13056) for request chatcmpl-b3a70b8ab147404a898bc105f9c99571 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,009] LMCache INFO:[0m Stored 405 out of total 405 tokens. size: 0.0494 gb, cost 1.2788 ms, throughput: 38.6603 GB/s; offload_time: 1.2697 ms, put_time: 0.0091 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 144, time is 1761207021.0116918
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 160956416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 1132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 144: 0.004996744791666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 144: 506422
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 144: 211.1281876620041
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 144: 0.6983350495823094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 127, time is 1761207021.0119593
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 157024256
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 1103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 127: 0.004874674479166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 127: 506422
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 127: 211.1281876620041
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 127: 0.6983350495823094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 91, time is 1761207021.0122185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 2638348288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 20115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 91: 0.08190511067708334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 91: 506422
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 91: 211.1281876620041
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 91: 0.6983350495823094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,015] LMCache INFO:[0m Reqid: chatcmpl-bcb44ad0ecb74da28a1fa7ba0b801faf, Total tokens 9905, LMCache hit tokens: 5376, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '91', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,325] LMCache INFO:[0m Storing KV cache for 2816 out of 8192 tokens (skip_leading_tokens=5376) for request chatcmpl-bcb44ad0ecb74da28a1fa7ba0b801faf [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,333] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 7.3985 ms, throughput: 46.4619 GB/s; offload_time: 7.3804 ms, put_time: 0.0181 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,333] LMCache INFO:[0m Storing KV cache for 5465 out of 13401 tokens (skip_leading_tokens=7936) for request chatcmpl-6dcda34c2d0c41db839af0f909b8d272 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,347] LMCache INFO:[0m Stored 5465 out of total 5465 tokens. size: 0.6671 gb, cost 14.1638 ms, throughput: 47.0999 GB/s; offload_time: 14.1386 ms, put_time: 0.0252 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207021.350888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:315] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:307] Request job id arriving: 91, time is 1761207021.3510232
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:315] Request job id: 91
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,353] LMCache INFO:[0m Reqid: chatcmpl-9e5c251dcba14bc980593ab201df9bb3, Total tokens 10775, LMCache hit tokens: 2560, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '29', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '127', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,635] LMCache INFO:[0m Storing KV cache for 6656 out of 9216 tokens (skip_leading_tokens=2560) for request chatcmpl-9e5c251dcba14bc980593ab201df9bb3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,653] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 17.1948 ms, throughput: 47.2527 GB/s; offload_time: 17.1519 ms, put_time: 0.0429 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,653] LMCache INFO:[0m Storing KV cache for 1713 out of 9905 tokens (skip_leading_tokens=8192) for request chatcmpl-bcb44ad0ecb74da28a1fa7ba0b801faf [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,658] LMCache INFO:[0m Stored 1713 out of total 1713 tokens. size: 0.2091 gb, cost 4.6015 ms, throughput: 45.4429 GB/s; offload_time: 4.5878 ms, put_time: 0.0137 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207021.6610184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 181796864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 1316
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 122: 0.005643717447916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 122: 504752
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 122: 209.764307885351
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 122: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:307] Request job id arriving: 29, time is 1761207021.6617408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:315] Request job id: 29
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:307] Request job id arriving: 127, time is 1761207021.6618538
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:315] Request job id: 127
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,664] LMCache INFO:[0m Reqid: chatcmpl-c0581f8346a742b88b5f421d3c12a059, Total tokens 11331, LMCache hit tokens: 2048, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '144', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '24', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,944] LMCache INFO:[0m Storing KV cache for 6656 out of 8704 tokens (skip_leading_tokens=2048) for request chatcmpl-c0581f8346a742b88b5f421d3c12a059 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,961] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 17.2399 ms, throughput: 47.1290 GB/s; offload_time: 17.1997 ms, put_time: 0.0402 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,961] LMCache INFO:[0m Storing KV cache for 1559 out of 10775 tokens (skip_leading_tokens=9216) for request chatcmpl-9e5c251dcba14bc980593ab201df9bb3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,966] LMCache INFO:[0m Stored 1559 out of total 1559 tokens. size: 0.1903 gb, cost 4.2424 ms, throughput: 44.8584 GB/s; offload_time: 4.2276 ms, put_time: 0.0148 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 92, time is 1761207021.9691253
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '66', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 208273408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 1524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 92: 0.0064656575520833336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 92: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 92: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 92: 0.6960108720339262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 15, time is 1761207021.9693801
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 437518336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 3292
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 15: 0.013582356770833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 15: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 15: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 15: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207021.9695413
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 680656896
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 5149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 16: 0.02113037109375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 16: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 16: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 16: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 111, time is 1761207021.9697742
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 247988224
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 1872
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 111: 0.007698567708333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 111: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 111: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 111: 0.6960108720339262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 160, time is 1761207021.969926
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 344588288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 2609
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 160: 0.010697428385416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 160: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 160: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 160: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 107, time is 1761207021.970062
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 358481920
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 2715
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 107: 0.011128743489583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 107: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 107: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 107: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207021.9702046
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 319553536
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 2421
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 156: 0.009920247395833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 156: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 156: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 156: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 78, time is 1761207021.9703448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 486277120
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 3694
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 78: 0.015096028645833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 78: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 78: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 78: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 81, time is 1761207021.9712152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 308412416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 2337
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 81: 0.009574381510416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 81: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 81: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 81: 0.6960108720339262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:328] Request job id finishing: 94, time is 1761207021.9714122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1462] Request GPU size bytes: 308150272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1463] Token size of the request: 2336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1469] Swap waste for job 94: 0.009566243489583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1479] Accumulated tokens for job 94: 514767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1481] Discard waste for job 94: 218.0096933327844
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [scheduler.py:1484] Preserve waste for job 94: 2.8918475290139516
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:307] Request job id arriving: 144, time is 1761207021.9718025
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:315] Request job id: 144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:307] Request job id arriving: 24, time is 1761207021.9719057
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:315] Request job id: 24
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:307] Request job id arriving: 66, time is 1761207021.971961
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:21 [estimate_with_func.py:315] Request job id: 66
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:21,980] LMCache INFO:[0m Reqid: chatcmpl-8d683e8ab5a44725b7ba61fcf66081dd, Total tokens 32163, LMCache hit tokens: 19968, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '166', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:45022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '81', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '92', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,420] LMCache INFO:[0m Storing KV cache for 5632 out of 25600 tokens (skip_leading_tokens=19968) for request chatcmpl-8d683e8ab5a44725b7ba61fcf66081dd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,435] LMCache INFO:[0m Stored 5632 out of total 5632 tokens. size: 0.6875 gb, cost 14.7935 ms, throughput: 46.4732 GB/s; offload_time: 14.7551 ms, put_time: 0.0384 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,436] LMCache INFO:[0m Storing KV cache for 2627 out of 11331 tokens (skip_leading_tokens=8704) for request chatcmpl-c0581f8346a742b88b5f421d3c12a059 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,443] LMCache INFO:[0m Stored 2627 out of total 2627 tokens. size: 0.3207 gb, cost 6.9831 ms, throughput: 45.9218 GB/s; offload_time: 6.9635 ms, put_time: 0.0197 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207022.4459956
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1462] Request GPU size bytes: 325844992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1463] Token size of the request: 2470
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1469] Swap waste for job 7: 0.010115559895833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1479] Accumulated tokens for job 7: 518981
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1481] Discard waste for job 7: 221.52658285769309
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1484] Preserve waste for job 7: 0.7088535045509907
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:307] Request job id arriving: 166, time is 1761207022.4465866
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:315] Request job id: 166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:307] Request job id arriving: 81, time is 1761207022.4466915
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:315] Request job id: 81
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:307] Request job id arriving: 92, time is 1761207022.4467528
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:315] Request job id: 92
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207022.4468045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:315] Request job id: 16
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,449] LMCache INFO:[0m Reqid: chatcmpl-92ff9423ed4f400ea92836162d7da76d, Total tokens 6281, LMCache hit tokens: 2816, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '78', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '104', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,937] LMCache INFO:[0m Storing KV cache for 1792 out of 4608 tokens (skip_leading_tokens=2816) for request chatcmpl-92ff9423ed4f400ea92836162d7da76d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,942] LMCache INFO:[0m Stored 1792 out of total 1792 tokens. size: 0.2188 gb, cost 4.8836 ms, throughput: 44.7923 GB/s; offload_time: 4.8607 ms, put_time: 0.0229 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,942] LMCache INFO:[0m Storing KV cache for 6563 out of 32163 tokens (skip_leading_tokens=25600) for request chatcmpl-8d683e8ab5a44725b7ba61fcf66081dd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,960] LMCache INFO:[0m Stored 6563 out of total 6563 tokens. size: 0.8011 gb, cost 17.5587 ms, throughput: 45.6267 GB/s; offload_time: 17.5276 ms, put_time: 0.0312 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:328] Request job id finishing: 52, time is 1761207022.963306
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1462] Request GPU size bytes: 761004032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1463] Token size of the request: 5783
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1469] Swap waste for job 52: 0.023624674479166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1479] Accumulated tokens for job 52: 522792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1481] Discard waste for job 52: 224.73136105439647
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1484] Preserve waste for job 52: 0.7021196510480798
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207022.9636073
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1462] Request GPU size bytes: 294780928
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1463] Token size of the request: 2231
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1469] Swap waste for job 5: 0.009151204427083334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1479] Accumulated tokens for job 5: 522792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1481] Discard waste for job 5: 224.73136105439647
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1484] Preserve waste for job 5: 2.9139224358690465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:328] Request job id finishing: 89, time is 1761207022.963777
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1462] Request GPU size bytes: 356777984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1463] Token size of the request: 2704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1469] Swap waste for job 89: 0.011075846354166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1479] Accumulated tokens for job 89: 522792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1481] Discard waste for job 89: 224.73136105439647
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [scheduler.py:1484] Preserve waste for job 89: 2.9139224358690465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:307] Request job id arriving: 78, time is 1761207022.964297
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:315] Request job id: 78
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:307] Request job id arriving: 104, time is 1761207022.9644027
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:315] Request job id: 104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207022.9644628
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:22 [estimate_with_func.py:315] Request job id: 133
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,966] LMCache INFO:[0m Reqid: chatcmpl-95a8d9cd20b8488e9e00753619e4b40e, Total tokens 4747, LMCache hit tokens: 1024, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:22,967] LMCache INFO:[0m Reqid: chatcmpl-24130e29f6d945efba59673930b91697, Total tokens 5307, LMCache hit tokens: 1024, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '111', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,204] LMCache INFO:[0m Storing KV cache for 3723 out of 4747 tokens (skip_leading_tokens=1024) for request chatcmpl-95a8d9cd20b8488e9e00753619e4b40e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,214] LMCache INFO:[0m Stored 3723 out of total 3723 tokens. size: 0.4545 gb, cost 9.7295 ms, throughput: 46.7102 GB/s; offload_time: 9.6981 ms, put_time: 0.0315 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,215] LMCache INFO:[0m Storing KV cache for 3072 out of 4096 tokens (skip_leading_tokens=1024) for request chatcmpl-24130e29f6d945efba59673930b91697 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,223] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 7.9465 ms, throughput: 47.1903 GB/s; offload_time: 7.9272 ms, put_time: 0.0194 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,223] LMCache INFO:[0m Storing KV cache for 1673 out of 6281 tokens (skip_leading_tokens=4608) for request chatcmpl-92ff9423ed4f400ea92836162d7da76d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,227] LMCache INFO:[0m Stored 1673 out of total 1673 tokens. size: 0.2042 gb, cost 4.4374 ms, throughput: 46.0238 GB/s; offload_time: 4.4248 ms, put_time: 0.0126 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:328] Request job id finishing: 19, time is 1761207023.2303765
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1462] Request GPU size bytes: 157679616
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1463] Token size of the request: 1186
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1469] Swap waste for job 19: 0.00489501953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1479] Accumulated tokens for job 19: 522128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1481] Discard waste for job 19: 224.17132964802775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1484] Preserve waste for job 19: 0.7021196510480798
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207023.2308545
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:315] Request job id: 5
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:307] Request job id arriving: 111, time is 1761207023.2309508
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:315] Request job id: 111
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '52', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,236] LMCache INFO:[0m Reqid: chatcmpl-f3056a95ff2142eb83adc98403c2a65e, Total tokens 43824, LMCache hit tokens: 22784, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '19', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51402 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,736] LMCache INFO:[0m Storing KV cache for 7168 out of 29952 tokens (skip_leading_tokens=22784) for request chatcmpl-f3056a95ff2142eb83adc98403c2a65e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,756] LMCache INFO:[0m Stored 7168 out of total 7168 tokens. size: 0.8750 gb, cost 18.8757 ms, throughput: 46.3559 GB/s; offload_time: 18.8333 ms, put_time: 0.0424 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,756] LMCache INFO:[0m Storing KV cache for 1211 out of 5307 tokens (skip_leading_tokens=4096) for request chatcmpl-24130e29f6d945efba59673930b91697 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:23,759] LMCache INFO:[0m Stored 1211 out of total 1211 tokens. size: 0.1478 gb, cost 3.3032 ms, throughput: 44.7526 GB/s; offload_time: 3.2885 ms, put_time: 0.0147 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:328] Request job id finishing: 2, time is 1761207023.7627542
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1462] Request GPU size bytes: 4119199744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1463] Token size of the request: 31385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1469] Swap waste for job 2: 0.12787679036458333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1479] Accumulated tokens for job 2: 564766
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1481] Discard waste for job 2: 261.5505104562802
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [scheduler.py:1484] Preserve waste for job 2: 2.875991721791545
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:307] Request job id arriving: 52, time is 1761207023.763689
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:315] Request job id: 52
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:307] Request job id arriving: 19, time is 1761207023.763804
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:23 [estimate_with_func.py:315] Request job id: 19
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:24,405] LMCache INFO:[0m Storing KV cache for 7936 out of 37888 tokens (skip_leading_tokens=29952) for request chatcmpl-f3056a95ff2142eb83adc98403c2a65e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '94', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:24,427] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.0480 ms, throughput: 43.9382 GB/s; offload_time: 21.9840 ms, put_time: 0.0640 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:24 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207024.431351
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:24 [estimate_with_func.py:315] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:24 [estimate_with_func.py:307] Request job id arriving: 94, time is 1761207024.431522
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:24 [estimate_with_func.py:315] Request job id: 94
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:24,434] LMCache INFO:[0m Reqid: chatcmpl-00f713d26c5b4e148ff3423dbdac4876, Total tokens 2525, LMCache hit tokens: 1280, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:24,436] LMCache INFO:[0m Reqid: chatcmpl-9a80862c3d3345ff9a748d91c339bf04, Total tokens 2193, LMCache hit tokens: 1024, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:24,437] LMCache INFO:[0m Reqid: chatcmpl-3150c005034544a4bafc8f91b1ac0d1c, Total tokens 3286, LMCache hit tokens: 2304, need to load: -48 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '107', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '89', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58432 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '15', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,013] LMCache INFO:[0m Storing KV cache for 1245 out of 2525 tokens (skip_leading_tokens=1280) for request chatcmpl-00f713d26c5b4e148ff3423dbdac4876 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,017] LMCache INFO:[0m Stored 1245 out of total 1245 tokens. size: 0.1520 gb, cost 3.5071 ms, throughput: 43.3346 GB/s; offload_time: 3.4870 ms, put_time: 0.0201 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,017] LMCache INFO:[0m Storing KV cache for 1169 out of 2193 tokens (skip_leading_tokens=1024) for request chatcmpl-9a80862c3d3345ff9a748d91c339bf04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,020] LMCache INFO:[0m Stored 1169 out of total 1169 tokens. size: 0.1427 gb, cost 3.0990 ms, throughput: 46.0474 GB/s; offload_time: 3.0878 ms, put_time: 0.0111 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,020] LMCache INFO:[0m Storing KV cache for 256 out of 2560 tokens (skip_leading_tokens=2304) for request chatcmpl-3150c005034544a4bafc8f91b1ac0d1c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,021] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.7269 ms, throughput: 42.9929 GB/s; offload_time: 0.7207 ms, put_time: 0.0062 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,021] LMCache INFO:[0m Storing KV cache for 5936 out of 43824 tokens (skip_leading_tokens=37888) for request chatcmpl-f3056a95ff2142eb83adc98403c2a65e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,038] LMCache INFO:[0m Stored 5936 out of total 5936 tokens. size: 0.7246 gb, cost 16.2244 ms, throughput: 44.6617 GB/s; offload_time: 16.1927 ms, put_time: 0.0317 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:328] Request job id finishing: 159, time is 1761207025.0409973
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1462] Request GPU size bytes: 101974016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1463] Token size of the request: 396
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1469] Swap waste for job 159: 0.0031656901041666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1479] Accumulated tokens for job 159: 541385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1481] Discard waste for job 159: 240.69665033301118
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1484] Preserve waste for job 159: 2.8727428410202265
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:328] Request job id finishing: 90, time is 1761207025.0412767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1462] Request GPU size bytes: 320995328
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1463] Token size of the request: 2356
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1469] Swap waste for job 90: 0.009965006510416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1479] Accumulated tokens for job 90: 541385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1481] Discard waste for job 90: 240.69665033301118
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1484] Preserve waste for job 90: 2.8727428410202265
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:328] Request job id finishing: 141, time is 1761207025.0415752
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1462] Request GPU size bytes: 187826176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1463] Token size of the request: 1415
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1469] Swap waste for job 141: 0.005830891927083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1479] Accumulated tokens for job 141: 541385
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1481] Discard waste for job 141: 240.69665033301118
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1484] Preserve waste for job 141: 2.8727428410202265
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 107, time is 1761207025.042198
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 107
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 89, time is 1761207025.0423334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 89
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207025.0423937
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 15, time is 1761207025.0424535
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 15
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,044] LMCache INFO:[0m Reqid: chatcmpl-8bd8b66b2559494eb480e4f326b53817, Total tokens 6489, LMCache hit tokens: 1280, need to load: -304 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,046] LMCache INFO:[0m Reqid: chatcmpl-b5a970726de4495a9ac2e8c716d18fbd, Total tokens 9108, LMCache hit tokens: 5120, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '90', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,311] LMCache INFO:[0m Storing KV cache for 5209 out of 6489 tokens (skip_leading_tokens=1280) for request chatcmpl-8bd8b66b2559494eb480e4f326b53817 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,324] LMCache INFO:[0m Stored 5209 out of total 5209 tokens. size: 0.6359 gb, cost 13.4985 ms, throughput: 47.1064 GB/s; offload_time: 13.4729 ms, put_time: 0.0256 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,324] LMCache INFO:[0m Storing KV cache for 2560 out of 7680 tokens (skip_leading_tokens=5120) for request chatcmpl-b5a970726de4495a9ac2e8c716d18fbd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,331] LMCache INFO:[0m Stored 2560 out of total 2560 tokens. size: 0.3125 gb, cost 6.6629 ms, throughput: 46.9018 GB/s; offload_time: 6.6468 ms, put_time: 0.0161 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,331] LMCache INFO:[0m Storing KV cache for 726 out of 3286 tokens (skip_leading_tokens=2560) for request chatcmpl-3150c005034544a4bafc8f91b1ac0d1c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,333] LMCache INFO:[0m Stored 726 out of total 726 tokens. size: 0.0886 gb, cost 1.9899 ms, throughput: 44.5368 GB/s; offload_time: 1.9814 ms, put_time: 0.0085 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:328] Request job id finishing: 114, time is 1761207025.3362586
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1462] Request GPU size bytes: 671219712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1463] Token size of the request: 5050
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1469] Swap waste for job 114: 0.02083740234375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1479] Accumulated tokens for job 114: 552815
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1481] Discard waste for job 114: 250.78305153260936
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1484] Preserve waste for job 114: 2.871266301834222
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:328] Request job id finishing: 83, time is 1761207025.3365192
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1462] Request GPU size bytes: 175505408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1463] Token size of the request: 1271
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1469] Swap waste for job 83: 0.005448404947916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1479] Accumulated tokens for job 83: 552815
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1481] Discard waste for job 83: 250.78305153260936
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1484] Preserve waste for job 83: 0.7263922495384739
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207025.3367708
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1462] Request GPU size bytes: 345636864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1463] Token size of the request: 2623
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1469] Swap waste for job 150: 0.01072998046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1479] Accumulated tokens for job 150: 552815
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1481] Discard waste for job 150: 250.78305153260936
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [scheduler.py:1484] Preserve waste for job 150: 0.7263922495384739
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 90, time is 1761207025.3370895
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 90
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,339] LMCache INFO:[0m Reqid: chatcmpl-8f993af2f707403a95efbcbd78edc4fb, Total tokens 6105, LMCache hit tokens: 3584, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,340] LMCache INFO:[0m Reqid: chatcmpl-c42d4d31f7a94fc7864a9bd5b80a0bed, Total tokens 2539, LMCache hit tokens: 1280, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,341] LMCache INFO:[0m Reqid: chatcmpl-a70c5296bd5b4c74ba55cac4a8b96b98, Total tokens 2215, LMCache hit tokens: 1024, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,342] LMCache INFO:[0m Reqid: chatcmpl-c290af766f834388bfb7284644961c05, Total tokens 3273, LMCache hit tokens: 2048, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,343] LMCache INFO:[0m Reqid: chatcmpl-627822231390464c9eb1d88daf42da1b, Total tokens 5033, LMCache hit tokens: 1792, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '2', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '83', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,597] LMCache INFO:[0m Storing KV cache for 2521 out of 6105 tokens (skip_leading_tokens=3584) for request chatcmpl-8f993af2f707403a95efbcbd78edc4fb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,606] LMCache INFO:[0m Stored 2521 out of total 2521 tokens. size: 0.3077 gb, cost 8.8640 ms, throughput: 34.7180 GB/s; offload_time: 8.8302 ms, put_time: 0.0338 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,606] LMCache INFO:[0m Storing KV cache for 1259 out of 2539 tokens (skip_leading_tokens=1280) for request chatcmpl-c42d4d31f7a94fc7864a9bd5b80a0bed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,610] LMCache INFO:[0m Stored 1259 out of total 1259 tokens. size: 0.1537 gb, cost 3.3675 ms, throughput: 45.6381 GB/s; offload_time: 3.3567 ms, put_time: 0.0109 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,610] LMCache INFO:[0m Storing KV cache for 1191 out of 2215 tokens (skip_leading_tokens=1024) for request chatcmpl-a70c5296bd5b4c74ba55cac4a8b96b98 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,613] LMCache INFO:[0m Stored 1191 out of total 1191 tokens. size: 0.1454 gb, cost 3.1505 ms, throughput: 46.1474 GB/s; offload_time: 3.1409 ms, put_time: 0.0096 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,613] LMCache INFO:[0m Storing KV cache for 1225 out of 3273 tokens (skip_leading_tokens=2048) for request chatcmpl-c290af766f834388bfb7284644961c05 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,618] LMCache INFO:[0m Stored 1225 out of total 1225 tokens. size: 0.1495 gb, cost 4.3645 ms, throughput: 34.2619 GB/s; offload_time: 4.3510 ms, put_time: 0.0135 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,618] LMCache INFO:[0m Storing KV cache for 1280 out of 3072 tokens (skip_leading_tokens=1792) for request chatcmpl-627822231390464c9eb1d88daf42da1b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,621] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.3617 ms, throughput: 46.4798 GB/s; offload_time: 3.3493 ms, put_time: 0.0124 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,621] LMCache INFO:[0m Storing KV cache for 1428 out of 9108 tokens (skip_leading_tokens=7680) for request chatcmpl-b5a970726de4495a9ac2e8c716d18fbd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,625] LMCache INFO:[0m Stored 1428 out of total 1428 tokens. size: 0.1743 gb, cost 3.8353 ms, throughput: 45.4507 GB/s; offload_time: 3.8226 ms, put_time: 0.0127 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 2, time is 1761207025.628991
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 2
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 83, time is 1761207025.629137
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 83
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207025.6292036
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:25 [estimate_with_func.py:315] Request job id: 150
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,631] LMCache INFO:[0m Reqid: chatcmpl-38fc2cf9dfea48e596a24d9618003e59, Total tokens 13307, LMCache hit tokens: 5632, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,938] LMCache INFO:[0m Storing KV cache for 6144 out of 11776 tokens (skip_leading_tokens=5632) for request chatcmpl-38fc2cf9dfea48e596a24d9618003e59 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,954] LMCache INFO:[0m Stored 6144 out of total 6144 tokens. size: 0.7500 gb, cost 16.0173 ms, throughput: 46.8244 GB/s; offload_time: 15.8099 ms, put_time: 0.2074 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,954] LMCache INFO:[0m Storing KV cache for 1961 out of 5033 tokens (skip_leading_tokens=3072) for request chatcmpl-627822231390464c9eb1d88daf42da1b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,959] LMCache INFO:[0m Stored 1961 out of total 1961 tokens. size: 0.2394 gb, cost 5.1623 ms, throughput: 46.3709 GB/s; offload_time: 5.1488 ms, put_time: 0.0135 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:25,964] LMCache INFO:[0m Reqid: chatcmpl-a270dad3229b4b81a956d99c29951a68, Total tokens 19247, LMCache hit tokens: 1024, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,256] LMCache INFO:[0m Storing KV cache for 6912 out of 7936 tokens (skip_leading_tokens=1024) for request chatcmpl-a270dad3229b4b81a956d99c29951a68 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,275] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 17.9079 ms, throughput: 47.1160 GB/s; offload_time: 17.8702 ms, put_time: 0.0377 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,275] LMCache INFO:[0m Storing KV cache for 1531 out of 13307 tokens (skip_leading_tokens=11776) for request chatcmpl-38fc2cf9dfea48e596a24d9618003e59 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,279] LMCache INFO:[0m Stored 1531 out of total 1531 tokens. size: 0.1869 gb, cost 4.1673 ms, throughput: 44.8470 GB/s; offload_time: 4.1546 ms, put_time: 0.0126 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '141', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51418 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,651] LMCache INFO:[0m Storing KV cache for 7936 out of 15872 tokens (skip_leading_tokens=7936) for request chatcmpl-a270dad3229b4b81a956d99c29951a68 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,672] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.5163 ms, throughput: 47.2185 GB/s; offload_time: 20.4817 ms, put_time: 0.0347 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207026.6747644
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [scheduler.py:1462] Request GPU size bytes: 698482688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [scheduler.py:1463] Token size of the request: 5309
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [scheduler.py:1469] Swap waste for job 136: 0.021683756510416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [scheduler.py:1479] Accumulated tokens for job 136: 595590
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [scheduler.py:1481] Discard waste for job 136: 290.3661523478441
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [scheduler.py:1484] Preserve waste for job 136: 0.7148228359222412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [estimate_with_func.py:307] Request job id arriving: 141, time is 1761207026.6752038
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:26 [estimate_with_func.py:315] Request job id: 141
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,677] LMCache INFO:[0m Reqid: chatcmpl-1032598e8f304189ba6ab43106345afd, Total tokens 6111, LMCache hit tokens: 2304, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,679] LMCache INFO:[0m Reqid: chatcmpl-fcd71ee8002f4a48a75adb936f1bea2c, Total tokens 3602, LMCache hit tokens: 2304, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:26,680] LMCache INFO:[0m Reqid: chatcmpl-57ddc4c7510641f18714e5f3d0d3c172, Total tokens 4143, LMCache hit tokens: 2560, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,010] LMCache INFO:[0m Storing KV cache for 3807 out of 6111 tokens (skip_leading_tokens=2304) for request chatcmpl-1032598e8f304189ba6ab43106345afd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,020] LMCache INFO:[0m Stored 3807 out of total 3807 tokens. size: 0.4647 gb, cost 9.9748 ms, throughput: 46.5897 GB/s; offload_time: 9.9469 ms, put_time: 0.0278 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,020] LMCache INFO:[0m Storing KV cache for 1298 out of 3602 tokens (skip_leading_tokens=2304) for request chatcmpl-fcd71ee8002f4a48a75adb936f1bea2c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,023] LMCache INFO:[0m Stored 1298 out of total 1298 tokens. size: 0.1584 gb, cost 3.4596 ms, throughput: 45.7991 GB/s; offload_time: 3.4450 ms, put_time: 0.0146 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,024] LMCache INFO:[0m Storing KV cache for 3375 out of 19247 tokens (skip_leading_tokens=15872) for request chatcmpl-a270dad3229b4b81a956d99c29951a68 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,033] LMCache INFO:[0m Stored 3375 out of total 3375 tokens. size: 0.4120 gb, cost 8.9314 ms, throughput: 46.1277 GB/s; offload_time: 8.9085 ms, put_time: 0.0230 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:328] Request job id finishing: 151, time is 1761207027.0358279
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1462] Request GPU size bytes: 217055232
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1463] Token size of the request: 1584
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1469] Swap waste for job 151: 0.00673828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1479] Accumulated tokens for job 151: 604137
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1481] Discard waste for job 151: 298.622772879052
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1484] Preserve waste for job 151: 0.7148228359222412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:328] Request job id finishing: 112, time is 1761207027.0362895
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1462] Request GPU size bytes: 1200357376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1463] Token size of the request: 9140
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1469] Swap waste for job 112: 0.03726399739583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1479] Accumulated tokens for job 112: 604137
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1481] Discard waste for job 112: 298.622772879052
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1484] Preserve waste for job 112: 2.8355771047097664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,039] LMCache INFO:[0m Reqid: chatcmpl-ee994ac8ea37490c8b22b24bcb9deb75, Total tokens 4097, LMCache hit tokens: 2560, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,040] LMCache INFO:[0m Reqid: chatcmpl-78d7cb832da0485f800c1840f6f778da, Total tokens 3705, LMCache hit tokens: 2304, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,042] LMCache INFO:[0m Reqid: chatcmpl-6c531c2b9169498ca5f58164a4dd1d44, Total tokens 5446, LMCache hit tokens: 3072, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,043] LMCache INFO:[0m Reqid: chatcmpl-470095eb0b264b4685fa397004993b41, Total tokens 4164, LMCache hit tokens: 2304, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,046] LMCache INFO:[0m Reqid: chatcmpl-bfdc078410994f3999fec877b5aa34ef, Total tokens 43467, LMCache hit tokens: 31232, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '114', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59314 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,315] LMCache INFO:[0m Storing KV cache for 1537 out of 4097 tokens (skip_leading_tokens=2560) for request chatcmpl-ee994ac8ea37490c8b22b24bcb9deb75 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,319] LMCache INFO:[0m Stored 1537 out of total 1537 tokens. size: 0.1876 gb, cost 4.2300 ms, throughput: 44.3548 GB/s; offload_time: 4.2098 ms, put_time: 0.0202 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,319] LMCache INFO:[0m Storing KV cache for 1401 out of 3705 tokens (skip_leading_tokens=2304) for request chatcmpl-78d7cb832da0485f800c1840f6f778da [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,323] LMCache INFO:[0m Stored 1401 out of total 1401 tokens. size: 0.1710 gb, cost 3.6962 ms, throughput: 46.2688 GB/s; offload_time: 3.6848 ms, put_time: 0.0115 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,323] LMCache INFO:[0m Storing KV cache for 2374 out of 5446 tokens (skip_leading_tokens=3072) for request chatcmpl-6c531c2b9169498ca5f58164a4dd1d44 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '159', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58878 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,330] LMCache INFO:[0m Stored 2374 out of total 2374 tokens. size: 0.2898 gb, cost 6.2048 ms, throughput: 46.7051 GB/s; offload_time: 6.1888 ms, put_time: 0.0160 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,330] LMCache INFO:[0m Storing KV cache for 1860 out of 4164 tokens (skip_leading_tokens=2304) for request chatcmpl-470095eb0b264b4685fa397004993b41 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,335] LMCache INFO:[0m Stored 1860 out of total 1860 tokens. size: 0.2271 gb, cost 4.8776 ms, throughput: 46.5496 GB/s; offload_time: 4.8649 ms, put_time: 0.0127 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,335] LMCache INFO:[0m Storing KV cache for 256 out of 31488 tokens (skip_leading_tokens=31232) for request chatcmpl-bfdc078410994f3999fec877b5aa34ef [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,336] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 1.0323 ms, throughput: 30.2718 GB/s; offload_time: 1.0246 ms, put_time: 0.0077 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,336] LMCache INFO:[0m Storing KV cache for 1583 out of 4143 tokens (skip_leading_tokens=2560) for request chatcmpl-57ddc4c7510641f18714e5f3d0d3c172 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:27,340] LMCache INFO:[0m Stored 1583 out of total 1583 tokens. size: 0.1932 gb, cost 4.2211 ms, throughput: 45.7792 GB/s; offload_time: 4.2082 ms, put_time: 0.0128 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:328] Request job id finishing: 11, time is 1761207027.343804
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1462] Request GPU size bytes: 206176256
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1463] Token size of the request: 1544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1469] Swap waste for job 11: 0.006400553385416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1479] Accumulated tokens for job 11: 654292
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1481] Discard waste for job 11: 349.4055456622427
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [scheduler.py:1484] Preserve waste for job 11: 0.7148228359222412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:307] Request job id arriving: 114, time is 1761207027.3443985
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:315] Request job id: 114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207027.3445146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:315] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:307] Request job id arriving: 159, time is 1761207027.3445747
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:27 [estimate_with_func.py:315] Request job id: 159
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,017] LMCache INFO:[0m Storing KV cache for 8192 out of 39680 tokens (skip_leading_tokens=31488) for request chatcmpl-bfdc078410994f3999fec877b5aa34ef [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,040] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1296 ms, throughput: 45.1884 GB/s; offload_time: 22.0733 ms, put_time: 0.0563 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207028.043821
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1462] Request GPU size bytes: 689045504
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1463] Token size of the request: 5211
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1469] Swap waste for job 10: 0.021390787760416665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1479] Accumulated tokens for job 10: 652748
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1481] Discard waste for job 10: 347.78277723262994
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1484] Preserve waste for job 10: 2.8256539515335195
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:328] Request job id finishing: 103, time is 1761207028.0442982
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1462] Request GPU size bytes: 664797184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1463] Token size of the request: 5027
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1469] Swap waste for job 103: 0.020638020833333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1479] Accumulated tokens for job 103: 652748
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1481] Discard waste for job 103: 347.78277723262994
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1484] Preserve waste for job 103: 2.8256539515335195
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207028.0446084
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1462] Request GPU size bytes: 345899008
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1463] Token size of the request: 2618
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1469] Swap waste for job 138: 0.010738118489583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1479] Accumulated tokens for job 138: 652748
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1481] Discard waste for job 138: 347.78277723262994
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1484] Preserve waste for job 138: 0.7142291821931538
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,047] LMCache INFO:[0m Reqid: chatcmpl-61f187fef47344b9a5dc7a906e62c659, Total tokens 4097, LMCache hit tokens: 1024, need to load: -304 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,049] LMCache INFO:[0m Reqid: chatcmpl-9de15d57ba564dc4acba736da0035d1d, Total tokens 17731, LMCache hit tokens: 2560, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '151', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '11', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,523] LMCache INFO:[0m Storing KV cache for 3073 out of 4097 tokens (skip_leading_tokens=1024) for request chatcmpl-61f187fef47344b9a5dc7a906e62c659 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,532] LMCache INFO:[0m Stored 3073 out of total 3073 tokens. size: 0.3751 gb, cost 8.3044 ms, throughput: 45.1715 GB/s; offload_time: 8.2734 ms, put_time: 0.0310 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,532] LMCache INFO:[0m Storing KV cache for 1536 out of 4096 tokens (skip_leading_tokens=2560) for request chatcmpl-9de15d57ba564dc4acba736da0035d1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,536] LMCache INFO:[0m Stored 1536 out of total 1536 tokens. size: 0.1875 gb, cost 4.0133 ms, throughput: 46.7202 GB/s; offload_time: 4.0003 ms, put_time: 0.0129 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,536] LMCache INFO:[0m Storing KV cache for 3787 out of 43467 tokens (skip_leading_tokens=39680) for request chatcmpl-bfdc078410994f3999fec877b5aa34ef [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,547] LMCache INFO:[0m Stored 3787 out of total 3787 tokens. size: 0.4623 gb, cost 10.7574 ms, throughput: 42.9733 GB/s; offload_time: 10.7327 ms, put_time: 0.0247 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:307] Request job id arriving: 151, time is 1761207028.5521648
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:315] Request job id: 151
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207028.5523365
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:315] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:307] Request job id arriving: 11, time is 1761207028.5523994
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:315] Request job id: 11
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,898] LMCache INFO:[0m Storing KV cache for 8192 out of 12288 tokens (skip_leading_tokens=4096) for request chatcmpl-9de15d57ba564dc4acba736da0035d1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,920] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.1126 ms, throughput: 47.3650 GB/s; offload_time: 21.0706 ms, put_time: 0.0420 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:328] Request job id finishing: 77, time is 1761207028.9230826
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1462] Request GPU size bytes: 622723072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1463] Token size of the request: 4703
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1469] Swap waste for job 77: 0.019331868489583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1479] Accumulated tokens for job 77: 661720
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1481] Discard waste for job 77: 357.2652722312165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1484] Preserve waste for job 77: 2.8256539515335195
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207028.9236042
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1462] Request GPU size bytes: 1447165952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1463] Token size of the request: 11020
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1469] Swap waste for job 174: 0.04492594401041667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1479] Accumulated tokens for job 174: 661720
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1481] Discard waste for job 174: 357.2652722312165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [scheduler.py:1484] Preserve waste for job 174: 2.8256539515335195
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207028.9241092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:28 [estimate_with_func.py:315] Request job id: 122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,926] LMCache INFO:[0m Reqid: chatcmpl-e7bc8be701874510b367a83c3bd019d8, Total tokens 2157, LMCache hit tokens: 1280, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:28,928] LMCache INFO:[0m Reqid: chatcmpl-4e56b786de124002aac2847b0d2f1234, Total tokens 9312, LMCache hit tokens: 4864, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '112', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,302] LMCache INFO:[0m Storing KV cache for 877 out of 2157 tokens (skip_leading_tokens=1280) for request chatcmpl-e7bc8be701874510b367a83c3bd019d8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,304] LMCache INFO:[0m Stored 877 out of total 877 tokens. size: 0.1071 gb, cost 2.4422 ms, throughput: 43.8350 GB/s; offload_time: 2.4291 ms, put_time: 0.0131 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,305] LMCache INFO:[0m Storing KV cache for 2048 out of 6912 tokens (skip_leading_tokens=4864) for request chatcmpl-4e56b786de124002aac2847b0d2f1234 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,310] LMCache INFO:[0m Stored 2048 out of total 2048 tokens. size: 0.2500 gb, cost 5.3591 ms, throughput: 46.6498 GB/s; offload_time: 5.3447 ms, put_time: 0.0144 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,310] LMCache INFO:[0m Storing KV cache for 5443 out of 17731 tokens (skip_leading_tokens=12288) for request chatcmpl-9de15d57ba564dc4acba736da0035d1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,324] LMCache INFO:[0m Stored 5443 out of total 5443 tokens. size: 0.6644 gb, cost 14.1456 ms, throughput: 46.9708 GB/s; offload_time: 14.1171 ms, put_time: 0.0285 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:328] Request job id finishing: 25, time is 1761207029.3275824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1462] Request GPU size bytes: 153354240
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1463] Token size of the request: 1055
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1469] Swap waste for job 25: 0.0047607421875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1479] Accumulated tokens for job 25: 657466
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1481] Discard waste for job 25: 352.7533297992123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1484] Preserve waste for job 25: 0.7280266224583493
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:328] Request job id finishing: 50, time is 1761207029.327906
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1462] Request GPU size bytes: 1503264768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1463] Token size of the request: 11448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1469] Swap waste for job 50: 0.04666748046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1479] Accumulated tokens for job 50: 657466
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1481] Discard waste for job 50: 352.7533297992123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1484] Preserve waste for job 50: 2.8578091583390166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:328] Request job id finishing: 169, time is 1761207029.3281193
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1462] Request GPU size bytes: 1414660096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1463] Token size of the request: 10775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1469] Swap waste for job 169: 0.04391682942708333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1479] Accumulated tokens for job 169: 657466
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1481] Discard waste for job 169: 352.7533297992123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1484] Preserve waste for job 169: 2.8578091583390166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:307] Request job id arriving: 112, time is 1761207029.3285685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:315] Request job id: 112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,330] LMCache INFO:[0m Reqid: chatcmpl-260439715ce4445a818165eec2b37190, Total tokens 13126, LMCache hit tokens: 5120, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '25', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,654] LMCache INFO:[0m Storing KV cache for 6144 out of 11264 tokens (skip_leading_tokens=5120) for request chatcmpl-260439715ce4445a818165eec2b37190 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,670] LMCache INFO:[0m Stored 6144 out of total 6144 tokens. size: 0.7500 gb, cost 15.9682 ms, throughput: 46.9683 GB/s; offload_time: 15.9299 ms, put_time: 0.0383 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,670] LMCache INFO:[0m Storing KV cache for 2400 out of 9312 tokens (skip_leading_tokens=6912) for request chatcmpl-4e56b786de124002aac2847b0d2f1234 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,677] LMCache INFO:[0m Stored 2400 out of total 2400 tokens. size: 0.2930 gb, cost 6.3203 ms, throughput: 46.3533 GB/s; offload_time: 6.3016 ms, put_time: 0.0188 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:328] Request job id finishing: 3, time is 1761207029.6799653
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1462] Request GPU size bytes: 2229665792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1463] Token size of the request: 16969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1469] Swap waste for job 3: 0.06921793619791666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1479] Accumulated tokens for job 3: 647314
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1481] Discard waste for job 3: 342.1015880881486
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1484] Preserve waste for job 3: 2.8537408636628294
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207029.6803932
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1462] Request GPU size bytes: 1487536128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1463] Token size of the request: 11331
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1469] Swap waste for job 79: 0.04617919921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1479] Accumulated tokens for job 79: 647314
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1481] Discard waste for job 79: 342.1015880881486
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1484] Preserve waste for job 79: 2.8537408636628294
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:307] Request job id arriving: 25, time is 1761207029.6807945
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:315] Request job id: 25
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,682] LMCache INFO:[0m Reqid: chatcmpl-73535048d2814fcbb5732c46d309f3f9, Total tokens 1740, LMCache hit tokens: 256, need to load: -512 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,683] LMCache INFO:[0m Reqid: chatcmpl-77f2fa8e1f6f4bc6ac42ea54f9a0f1fe, Total tokens 5118, LMCache hit tokens: 1536, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,685] LMCache INFO:[0m Reqid: chatcmpl-cb668adc14124203a7e246ff98c25665, Total tokens 15286, LMCache hit tokens: 2560, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,967] LMCache INFO:[0m Storing KV cache for 1484 out of 1740 tokens (skip_leading_tokens=256) for request chatcmpl-73535048d2814fcbb5732c46d309f3f9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,971] LMCache INFO:[0m Stored 1484 out of total 1484 tokens. size: 0.1812 gb, cost 3.9924 ms, throughput: 45.3741 GB/s; offload_time: 3.9786 ms, put_time: 0.0138 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,971] LMCache INFO:[0m Storing KV cache for 3582 out of 5118 tokens (skip_leading_tokens=1536) for request chatcmpl-77f2fa8e1f6f4bc6ac42ea54f9a0f1fe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,980] LMCache INFO:[0m Stored 3582 out of total 3582 tokens. size: 0.4373 gb, cost 9.2777 ms, throughput: 47.1296 GB/s; offload_time: 9.2587 ms, put_time: 0.0190 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,980] LMCache INFO:[0m Storing KV cache for 1792 out of 4352 tokens (skip_leading_tokens=2560) for request chatcmpl-cb668adc14124203a7e246ff98c25665 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,985] LMCache INFO:[0m Stored 1792 out of total 1792 tokens. size: 0.2188 gb, cost 4.6922 ms, throughput: 46.6195 GB/s; offload_time: 4.6793 ms, put_time: 0.0129 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,985] LMCache INFO:[0m Storing KV cache for 1862 out of 13126 tokens (skip_leading_tokens=11264) for request chatcmpl-260439715ce4445a818165eec2b37190 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:29,990] LMCache INFO:[0m Stored 1862 out of total 1862 tokens. size: 0.2273 gb, cost 4.9953 ms, throughput: 45.5021 GB/s; offload_time: 4.9813 ms, put_time: 0.0140 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [estimate_with_func.py:328] Request job id finishing: 92, time is 1761207029.9935718
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1462] Request GPU size bytes: 852230144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1463] Token size of the request: 6489
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1469] Swap waste for job 92: 0.026456705729166665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1479] Accumulated tokens for job 92: 641158
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1481] Discard waste for job 92: 335.7220621868192
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:29 [scheduler.py:1484] Preserve waste for job 92: 0.7233413308858871
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,320] LMCache INFO:[0m Storing KV cache for 8192 out of 12544 tokens (skip_leading_tokens=4352) for request chatcmpl-cb668adc14124203a7e246ff98c25665 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,342] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.1048 ms, throughput: 47.3826 GB/s; offload_time: 21.0587 ms, put_time: 0.0461 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [estimate_with_func.py:328] Request job id finishing: 78, time is 1761207030.3449028
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1462] Request GPU size bytes: 801898496
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1463] Token size of the request: 6105
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1469] Swap waste for job 78: 0.024894205729166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1479] Accumulated tokens for job 78: 634669
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1481] Discard waste for job 78: 329.06243001345666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1484] Preserve waste for job 78: 0.7233413308858871
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,347] LMCache INFO:[0m Reqid: chatcmpl-58a92c8039384fc49f0c658073abb224, Total tokens 7339, LMCache hit tokens: 1536, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:10:30 [loggers.py:123] Engine 000: Avg prompt throughput: 37699.7 tokens/s, Avg generation throughput: 199.2 tokens/s, Running: 80 reqs, Waiting: 4 reqs, GPU KV cache usage: 54.7%, Prefix cache hit rate: 36.1%
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '92', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,664] LMCache INFO:[0m Storing KV cache for 5376 out of 6912 tokens (skip_leading_tokens=1536) for request chatcmpl-58a92c8039384fc49f0c658073abb224 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,679] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 14.0106 ms, throughput: 46.8394 GB/s; offload_time: 13.9765 ms, put_time: 0.0342 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,679] LMCache INFO:[0m Storing KV cache for 2742 out of 15286 tokens (skip_leading_tokens=12544) for request chatcmpl-cb668adc14124203a7e246ff98c25665 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,686] LMCache INFO:[0m Stored 2742 out of total 2742 tokens. size: 0.3347 gb, cost 7.2554 ms, throughput: 46.1333 GB/s; offload_time: 7.2373 ms, put_time: 0.0182 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '78', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [estimate_with_func.py:328] Request job id finishing: 134, time is 1761207030.6914704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1462] Request GPU size bytes: 203161600
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1463] Token size of the request: 1454
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1469] Swap waste for job 134: 0.006306966145833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1479] Accumulated tokens for job 134: 635903
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1481] Discard waste for job 134: 330.3237430291792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [scheduler.py:1484] Preserve waste for job 134: 2.8537408636628294
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [estimate_with_func.py:307] Request job id arriving: 92, time is 1761207030.6921191
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [estimate_with_func.py:315] Request job id: 92
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [estimate_with_func.py:307] Request job id arriving: 78, time is 1761207030.6922264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:30 [estimate_with_func.py:315] Request job id: 78
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,694] LMCache INFO:[0m Reqid: chatcmpl-b1642f14ebff419c952482e9fd7de005, Total tokens 2457, LMCache hit tokens: 1280, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,695] LMCache INFO:[0m Reqid: chatcmpl-b8a8066d1ed640678e189526254f5bd6, Total tokens 13596, LMCache hit tokens: 8960, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,700] LMCache INFO:[0m Reqid: chatcmpl-7aa7827afc78497898b1a67553795e27, Total tokens 2340, LMCache hit tokens: 1024, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:30,702] LMCache INFO:[0m Reqid: chatcmpl-ee62ac4e86f943249afab86f93607347, Total tokens 47881, LMCache hit tokens: 6400, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,022] LMCache INFO:[0m Storing KV cache for 1177 out of 2457 tokens (skip_leading_tokens=1280) for request chatcmpl-b1642f14ebff419c952482e9fd7de005 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,026] LMCache INFO:[0m Stored 1177 out of total 1177 tokens. size: 0.1437 gb, cost 3.2391 ms, throughput: 44.3565 GB/s; offload_time: 3.2198 ms, put_time: 0.0193 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,026] LMCache INFO:[0m Storing KV cache for 4636 out of 13596 tokens (skip_leading_tokens=8960) for request chatcmpl-b8a8066d1ed640678e189526254f5bd6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,038] LMCache INFO:[0m Stored 4636 out of total 4636 tokens. size: 0.5659 gb, cost 12.0651 ms, throughput: 46.9054 GB/s; offload_time: 12.0364 ms, put_time: 0.0287 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,038] LMCache INFO:[0m Storing KV cache for 1316 out of 2340 tokens (skip_leading_tokens=1024) for request chatcmpl-7aa7827afc78497898b1a67553795e27 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,042] LMCache INFO:[0m Stored 1316 out of total 1316 tokens. size: 0.1606 gb, cost 3.4747 ms, throughput: 46.2324 GB/s; offload_time: 3.4629 ms, put_time: 0.0118 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,042] LMCache INFO:[0m Storing KV cache for 1024 out of 7424 tokens (skip_leading_tokens=6400) for request chatcmpl-ee62ac4e86f943249afab86f93607347 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,045] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 2.7371 ms, throughput: 45.6683 GB/s; offload_time: 2.7251 ms, put_time: 0.0120 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,045] LMCache INFO:[0m Storing KV cache for 427 out of 7339 tokens (skip_leading_tokens=6912) for request chatcmpl-58a92c8039384fc49f0c658073abb224 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,046] LMCache INFO:[0m Stored 427 out of total 427 tokens. size: 0.0521 gb, cost 1.2822 ms, throughput: 40.6532 GB/s; offload_time: 1.2730 ms, put_time: 0.0092 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207031.0493662
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1462] Request GPU size bytes: 163708928
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1463] Token size of the request: 1155
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1469] Swap waste for job 173: 0.005082194010416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1479] Accumulated tokens for job 173: 700723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1481] Discard waste for job 173: 399.96942878793027
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1484] Preserve waste for job 173: 2.8537408636628294
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:328] Request job id finishing: 128, time is 1761207031.0497506
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1462] Request GPU size bytes: 281804800
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1463] Token size of the request: 2111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1469] Swap waste for job 128: 0.008748372395833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1479] Accumulated tokens for job 128: 700723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1481] Discard waste for job 128: 399.96942878793027
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1484] Preserve waste for job 128: 0.7184528781146537
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207031.0500114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1462] Request GPU size bytes: 1195769856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1463] Token size of the request: 9108
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1469] Swap waste for job 16: 0.03712158203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1479] Accumulated tokens for job 16: 700723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1481] Discard waste for job 16: 399.96942878793027
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1484] Preserve waste for job 16: 0.7184528781146537
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207031.050596
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:315] Request job id: 10
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '160', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,421] LMCache INFO:[0m Storing KV cache for 7936 out of 15360 tokens (skip_leading_tokens=7424) for request chatcmpl-ee62ac4e86f943249afab86f93607347 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,442] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.6105 ms, throughput: 47.0028 GB/s; offload_time: 20.5633 ms, put_time: 0.0471 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:307] Request job id arriving: 160, time is 1761207031.4459856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:315] Request job id: 160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207031.4461365
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:315] Request job id: 16
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '128', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,918] LMCache INFO:[0m Storing KV cache for 8192 out of 23552 tokens (skip_leading_tokens=15360) for request chatcmpl-ee62ac4e86f943249afab86f93607347 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:31,940] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3473 ms, throughput: 46.8443 GB/s; offload_time: 21.2865 ms, put_time: 0.0608 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '169', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:328] Request job id finishing: 162, time is 1761207031.9450216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1462] Request GPU size bytes: 168558592
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1463] Token size of the request: 1185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1469] Swap waste for job 162: 0.005232747395833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1479] Accumulated tokens for job 162: 688349
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1481] Discard waste for job 162: 386.16024387076124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1484] Preserve waste for job 162: 0.7145696490643972
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207031.9456167
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1462] Request GPU size bytes: 292552704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1463] Token size of the request: 2215
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1469] Swap waste for job 133: 0.00908203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1479] Accumulated tokens for job 133: 688349
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1481] Discard waste for job 133: 386.16024387076124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [scheduler.py:1484] Preserve waste for job 133: 0.7145696490643972
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:307] Request job id arriving: 128, time is 1761207031.9460337
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:315] Request job id: 128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207031.9461427
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:307] Request job id arriving: 169, time is 1761207031.9462059
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:31 [estimate_with_func.py:315] Request job id: 169
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '50', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '3', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '77', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '103', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '162', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:32,520] LMCache INFO:[0m Storing KV cache for 8192 out of 31744 tokens (skip_leading_tokens=23552) for request chatcmpl-ee62ac4e86f943249afab86f93607347 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:32,545] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.4160 ms, throughput: 40.9567 GB/s; offload_time: 24.3580 ms, put_time: 0.0580 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:328] Request job id finishing: 101, time is 1761207032.5486782
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1462] Request GPU size bytes: 190447616
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1463] Token size of the request: 1358
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1469] Swap waste for job 101: 0.005912272135416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1479] Accumulated tokens for job 101: 684949
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1481] Discard waste for job 101: 382.4083739793232
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1484] Preserve waste for job 101: 0.9462021210614373
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:328] Request job id finishing: 24, time is 1761207032.5492237
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1462] Request GPU size bytes: 5746720768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1463] Token size of the request: 43824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1469] Swap waste for job 24: 0.17840169270833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1479] Accumulated tokens for job 24: 684949
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1481] Discard waste for job 24: 382.4083739793232
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1484] Preserve waste for job 24: 0.9462021210614373
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:328] Request job id finishing: 66, time is 1761207032.5497935
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1462] Request GPU size bytes: 333578240
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1463] Token size of the request: 2525
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1469] Swap waste for job 66: 0.010355631510416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1479] Accumulated tokens for job 66: 684949
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1481] Discard waste for job 66: 382.4083739793232
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [scheduler.py:1484] Preserve waste for job 66: 2.8997955557326196
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:307] Request job id arriving: 50, time is 1761207032.5502372
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:315] Request job id: 50
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207032.5503714
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:315] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:307] Request job id arriving: 3, time is 1761207032.55044
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:315] Request job id: 3
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:307] Request job id arriving: 77, time is 1761207032.5505078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:315] Request job id: 77
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:307] Request job id arriving: 103, time is 1761207032.5505712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:315] Request job id: 103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:307] Request job id arriving: 162, time is 1761207032.5506318
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:315] Request job id: 162
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207032.550689
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:32 [estimate_with_func.py:315] Request job id: 133
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:33,219] LMCache INFO:[0m Storing KV cache for 8192 out of 39936 tokens (skip_leading_tokens=31744) for request chatcmpl-ee62ac4e86f943249afab86f93607347 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:33,242] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.8971 ms, throughput: 45.6681 GB/s; offload_time: 21.8432 ms, put_time: 0.0540 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:33,248] LMCache INFO:[0m Reqid: chatcmpl-54b6dae913494657b41093a526278768, Total tokens 26823, LMCache hit tokens: 5888, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '101', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '24', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,005] LMCache INFO:[0m Storing KV cache for 256 out of 6144 tokens (skip_leading_tokens=5888) for request chatcmpl-54b6dae913494657b41093a526278768 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,007] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.9848 ms, throughput: 31.7318 GB/s; offload_time: 0.9631 ms, put_time: 0.0217 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,007] LMCache INFO:[0m Storing KV cache for 7945 out of 47881 tokens (skip_leading_tokens=39936) for request chatcmpl-ee62ac4e86f943249afab86f93607347 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,029] LMCache INFO:[0m Stored 7945 out of total 7945 tokens. size: 0.9698 gb, cost 21.5041 ms, throughput: 45.1006 GB/s; offload_time: 21.4603 ms, put_time: 0.0438 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:328] Request job id finishing: 39, time is 1761207034.0322058
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1462] Request GPU size bytes: 3846963200
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1463] Token size of the request: 29283
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1469] Swap waste for job 39: 0.11942545572916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1479] Accumulated tokens for job 39: 664065
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1481] Discard waste for job 39: 359.76471762573937
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1484] Preserve waste for job 39: 0.938365530693668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:328] Request job id finishing: 2, time is 1761207034.03307
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1462] Request GPU size bytes: 5699010560
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1463] Token size of the request: 43467
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1469] Swap waste for job 2: 0.17692057291666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1479] Accumulated tokens for job 2: 664065
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1481] Discard waste for job 2: 359.76471762573937
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1484] Preserve waste for job 2: 0.938365530693668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 101, time is 1761207034.0341387
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207034.0342708
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 24, time is 1761207034.0343366
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 24
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '134', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '2', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,377] LMCache INFO:[0m Storing KV cache for 8192 out of 14336 tokens (skip_leading_tokens=6144) for request chatcmpl-54b6dae913494657b41093a526278768 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,398] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.1024 ms, throughput: 47.3880 GB/s; offload_time: 21.0574 ms, put_time: 0.0449 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207034.4012165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1462] Request GPU size bytes: 667680768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1463] Token size of the request: 5026
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1469] Swap waste for job 44: 0.0207275390625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1479] Accumulated tokens for job 44: 591315
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1481] Discard waste for job 44: 286.27980493283286
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1484] Preserve waste for job 44: 2.9322845806946627
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207034.4016795
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1462] Request GPU size bytes: 487718912
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1463] Token size of the request: 3705
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1469] Swap waste for job 156: 0.015140787760416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1479] Accumulated tokens for job 156: 591315
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1481] Discard waste for job 156: 286.27980493283286
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1484] Preserve waste for job 156: 2.9322845806946627
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 134, time is 1761207034.4020057
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 134
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 2, time is 1761207034.4021068
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 2
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '39', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58762 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,849] LMCache INFO:[0m Storing KV cache for 8192 out of 22528 tokens (skip_leading_tokens=14336) for request chatcmpl-54b6dae913494657b41093a526278768 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '66', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,871] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.8977 ms, throughput: 45.6670 GB/s; offload_time: 21.8507 ms, put_time: 0.0470 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:328] Request job id finishing: 148, time is 1761207034.8741362
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1462] Request GPU size bytes: 365166592
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1463] Token size of the request: 2741
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1469] Swap waste for job 148: 0.011336263020833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1479] Accumulated tokens for job 148: 582584
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1481] Discard waste for job 148: 278.024031627121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1484] Preserve waste for job 148: 2.937507589391414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:328] Request job id finishing: 171, time is 1761207034.8744102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1462] Request GPU size bytes: 204210176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1463] Token size of the request: 1513
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1469] Swap waste for job 171: 0.006339518229166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1479] Accumulated tokens for job 171: 582584
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1481] Discard waste for job 171: 278.024031627121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [scheduler.py:1484] Preserve waste for job 171: 2.937507589391414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 39, time is 1761207034.8748455
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 39
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207034.8750832
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:307] Request job id arriving: 66, time is 1761207034.875159
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:34 [estimate_with_func.py:315] Request job id: 66
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:34,878] LMCache INFO:[0m Reqid: chatcmpl-d817a6a75f294e5d8bfc3badecc55030, Total tokens 9188, LMCache hit tokens: 5120, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,290] LMCache INFO:[0m Storing KV cache for 3840 out of 8960 tokens (skip_leading_tokens=5120) for request chatcmpl-d817a6a75f294e5d8bfc3badecc55030 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,300] LMCache INFO:[0m Stored 3840 out of total 3840 tokens. size: 0.4688 gb, cost 10.1547 ms, throughput: 46.1610 GB/s; offload_time: 10.1213 ms, put_time: 0.0334 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,301] LMCache INFO:[0m Storing KV cache for 4295 out of 26823 tokens (skip_leading_tokens=22528) for request chatcmpl-54b6dae913494657b41093a526278768 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,312] LMCache INFO:[0m Stored 4295 out of total 4295 tokens. size: 0.5243 gb, cost 11.4259 ms, throughput: 45.8864 GB/s; offload_time: 11.3943 ms, put_time: 0.0316 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [estimate_with_func.py:328] Request job id finishing: 76, time is 1761207035.315429
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1462] Request GPU size bytes: 2501640192
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1463] Token size of the request: 19042
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1469] Swap waste for job 76: 0.0776611328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1479] Accumulated tokens for job 76: 587518
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1481] Discard waste for job 76: 282.67463757490304
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1484] Preserve waste for job 76: 2.939335783585807
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,319] LMCache INFO:[0m Reqid: chatcmpl-7c87332f1979484ea0855fb8d4020723, Total tokens 4234, LMCache hit tokens: 2560, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,321] LMCache INFO:[0m Reqid: chatcmpl-480c86894a7441a78c50287e5dbf8baa, Total tokens 20915, LMCache hit tokens: 8960, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,663] LMCache INFO:[0m Storing KV cache for 1674 out of 4234 tokens (skip_leading_tokens=2560) for request chatcmpl-7c87332f1979484ea0855fb8d4020723 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,668] LMCache INFO:[0m Stored 1674 out of total 1674 tokens. size: 0.2043 gb, cost 4.6149 ms, throughput: 44.2793 GB/s; offload_time: 4.5910 ms, put_time: 0.0239 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,668] LMCache INFO:[0m Storing KV cache for 6400 out of 15360 tokens (skip_leading_tokens=8960) for request chatcmpl-480c86894a7441a78c50287e5dbf8baa [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,685] LMCache INFO:[0m Stored 6400 out of total 6400 tokens. size: 0.7812 gb, cost 16.4896 ms, throughput: 47.3784 GB/s; offload_time: 16.4596 ms, put_time: 0.0299 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207035.6878006
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1462] Request GPU size bytes: 2511077376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1463] Token size of the request: 19091
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1469] Swap waste for job 164: 0.0779541015625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1479] Accumulated tokens for job 164: 593625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1481] Discard waste for job 164: 288.48427140569845
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1484] Preserve waste for job 164: 2.939335783585807
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [estimate_with_func.py:328] Request job id finishing: 35, time is 1761207035.6882365
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1462] Request GPU size bytes: 1209532416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1463] Token size of the request: 9162
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1469] Swap waste for job 35: 0.037548828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1479] Accumulated tokens for job 35: 593625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1481] Discard waste for job 35: 288.48427140569845
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1484] Preserve waste for job 35: 0.9430786384331001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [estimate_with_func.py:328] Request job id finishing: 81, time is 1761207035.6885684
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1462] Request GPU size bytes: 433979392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1463] Token size of the request: 3286
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1469] Swap waste for job 81: 0.013472493489583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1479] Accumulated tokens for job 81: 593625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1481] Discard waste for job 81: 288.48427140569845
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:35 [scheduler.py:1484] Preserve waste for job 81: 0.9430786384331001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:35,691] LMCache INFO:[0m Reqid: chatcmpl-044af4d6b8754fefbffdcbc9f9ea1ca7, Total tokens 12275, LMCache hit tokens: 2048, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '81', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,069] LMCache INFO:[0m Storing KV cache for 2816 out of 4864 tokens (skip_leading_tokens=2048) for request chatcmpl-044af4d6b8754fefbffdcbc9f9ea1ca7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,077] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 7.3773 ms, throughput: 46.5957 GB/s; offload_time: 7.3589 ms, put_time: 0.0184 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,077] LMCache INFO:[0m Storing KV cache for 5555 out of 20915 tokens (skip_leading_tokens=15360) for request chatcmpl-480c86894a7441a78c50287e5dbf8baa [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,092] LMCache INFO:[0m Stored 5555 out of total 5555 tokens. size: 0.6781 gb, cost 14.4390 ms, throughput: 46.9631 GB/s; offload_time: 14.4127 ms, put_time: 0.0263 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:328] Request job id finishing: 168, time is 1761207036.0945725
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1462] Request GPU size bytes: 533856256
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1463] Token size of the request: 4030
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1469] Swap waste for job 168: 0.016573079427083335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1479] Accumulated tokens for job 168: 574361
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1481] Discard waste for job 168: 270.3590207352297
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1484] Preserve waste for job 168: 2.939335783585807
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:307] Request job id arriving: 81, time is 1761207036.0951622
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:315] Request job id: 81
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,106] LMCache INFO:[0m Reqid: chatcmpl-b5cbbc7f4a574a8cbe8e04f7f0fea608, Total tokens 1983, LMCache hit tokens: 1024, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,421] LMCache INFO:[0m Storing KV cache for 768 out of 1792 tokens (skip_leading_tokens=1024) for request chatcmpl-b5cbbc7f4a574a8cbe8e04f7f0fea608 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,423] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.1453 ms, throughput: 43.6995 GB/s; offload_time: 2.1306 ms, put_time: 0.0147 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,423] LMCache INFO:[0m Storing KV cache for 7411 out of 12275 tokens (skip_leading_tokens=4864) for request chatcmpl-044af4d6b8754fefbffdcbc9f9ea1ca7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,442] LMCache INFO:[0m Stored 7411 out of total 7411 tokens. size: 0.9047 gb, cost 19.0957 ms, throughput: 47.3752 GB/s; offload_time: 19.0569 ms, put_time: 0.0388 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:328] Request job id finishing: 146, time is 1761207036.4454064
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1462] Request GPU size bytes: 1032454144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1463] Token size of the request: 7831
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1469] Swap waste for job 146: 0.03205159505208333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1479] Accumulated tokens for job 146: 572314
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1481] Discard waste for job 146: 268.4675739112787
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1484] Preserve waste for job 146: 0.9372477946074113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:328] Request job id finishing: 87, time is 1761207036.4457786
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1462] Request GPU size bytes: 1212416000
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1463] Token size of the request: 9205
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1469] Swap waste for job 87: 0.037638346354166664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1479] Accumulated tokens for job 87: 572314
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1481] Discard waste for job 87: 268.4675739112787
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1484] Preserve waste for job 87: 2.939335783585807
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207036.4460616
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1462] Request GPU size bytes: 432406528
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1463] Token size of the request: 3273
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1469] Swap waste for job 5: 0.013423665364583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1479] Accumulated tokens for job 5: 572314
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1481] Discard waste for job 5: 268.4675739112787
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1484] Preserve waste for job 5: 0.9372477946074113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,449] LMCache INFO:[0m Reqid: chatcmpl-a1025803e02f4d53940b1ce8bc691eb9, Total tokens 18897, LMCache hit tokens: 10752, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '35', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,846] LMCache INFO:[0m Storing KV cache for 7936 out of 18688 tokens (skip_leading_tokens=10752) for request chatcmpl-a1025803e02f4d53940b1ce8bc691eb9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,867] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.6037 ms, throughput: 47.0182 GB/s; offload_time: 20.5583 ms, put_time: 0.0455 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:328] Request job id finishing: 141, time is 1761207036.8700879
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1462] Request GPU size bytes: 285081600
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1463] Token size of the request: 2157
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1469] Swap waste for job 141: 0.00885009765625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1479] Accumulated tokens for job 141: 570902
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1481] Discard waste for job 141: 267.1667410655158
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1484] Preserve waste for job 141: 2.939335783585807
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:328] Request job id finishing: 25, time is 1761207036.870353
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1462] Request GPU size bytes: 308412416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1463] Token size of the request: 2340
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1469] Swap waste for job 25: 0.009574381510416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1479] Accumulated tokens for job 25: 570902
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1481] Discard waste for job 25: 267.1667410655158
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [scheduler.py:1484] Preserve waste for job 25: 0.9372477946074113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:307] Request job id arriving: 35, time is 1761207036.8706176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:315] Request job id: 35
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207036.8707187
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:36 [estimate_with_func.py:315] Request job id: 44
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,874] LMCache INFO:[0m Reqid: chatcmpl-50efb609fbc547bab20f0049cdb2dd91, Total tokens 18359, LMCache hit tokens: 11264, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:36,877] LMCache INFO:[0m Reqid: chatcmpl-23db9ef7db1642c6a16cd73e53bc9921, Total tokens 17289, LMCache hit tokens: 11008, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '146', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '25', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '171', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51398 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,273] LMCache INFO:[0m Storing KV cache for 7095 out of 18359 tokens (skip_leading_tokens=11264) for request chatcmpl-50efb609fbc547bab20f0049cdb2dd91 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,292] LMCache INFO:[0m Stored 7095 out of total 7095 tokens. size: 0.8661 gb, cost 18.5873 ms, throughput: 46.5958 GB/s; offload_time: 18.5356 ms, put_time: 0.0516 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,292] LMCache INFO:[0m Storing KV cache for 1024 out of 12032 tokens (skip_leading_tokens=11008) for request chatcmpl-23db9ef7db1642c6a16cd73e53bc9921 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,296] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 3.6653 ms, throughput: 34.1035 GB/s; offload_time: 3.6496 ms, put_time: 0.0157 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:328] Request job id finishing: 165, time is 1761207037.2989607
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1462] Request GPU size bytes: 322043904
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1463] Token size of the request: 2411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1469] Swap waste for job 165: 0.00999755859375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1479] Accumulated tokens for job 165: 602053
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1481] Discard waste for job 165: 296.5989084385814
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1484] Preserve waste for job 165: 2.936244547367096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:328] Request job id finishing: 23, time is 1761207037.2992864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1462] Request GPU size bytes: 1144651776
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1463] Token size of the request: 8688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1469] Swap waste for job 23: 0.03553466796875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1479] Accumulated tokens for job 23: 602053
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1481] Discard waste for job 23: 296.5989084385814
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1484] Preserve waste for job 23: 2.936244547367096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:307] Request job id arriving: 146, time is 1761207037.3000941
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:315] Request job id: 146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:307] Request job id arriving: 25, time is 1761207037.3002214
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:315] Request job id: 25
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:307] Request job id arriving: 171, time is 1761207037.300297
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:315] Request job id: 171
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,304] LMCache INFO:[0m Reqid: chatcmpl-9040a4d175dd417f9156652ca446e76b, Total tokens 33107, LMCache hit tokens: 16896, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,727] LMCache INFO:[0m Storing KV cache for 3072 out of 19968 tokens (skip_leading_tokens=16896) for request chatcmpl-9040a4d175dd417f9156652ca446e76b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,736] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 9.3140 ms, throughput: 40.2618 GB/s; offload_time: 9.2652 ms, put_time: 0.0489 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,737] LMCache INFO:[0m Storing KV cache for 5257 out of 17289 tokens (skip_leading_tokens=12032) for request chatcmpl-23db9ef7db1642c6a16cd73e53bc9921 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:37,751] LMCache INFO:[0m Stored 5257 out of total 5257 tokens. size: 0.6417 gb, cost 13.7131 ms, throughput: 46.7965 GB/s; offload_time: 13.6821 ms, put_time: 0.0309 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:328] Request job id finishing: 151, time is 1761207037.7537484
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1462] Request GPU size bytes: 673185792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1463] Token size of the request: 5118
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1469] Swap waste for job 151: 0.0208984375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1479] Accumulated tokens for job 151: 624061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1481] Discard waste for job 151: 318.31912453395665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [scheduler.py:1484] Preserve waste for job 151: 0.9336188441828678
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207037.7544613
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:315] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207037.7546036
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:37 [estimate_with_func.py:315] Request job id: 5
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '168', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,267] LMCache INFO:[0m Storing KV cache for 8192 out of 28160 tokens (skip_leading_tokens=19968) for request chatcmpl-9040a4d175dd417f9156652ca446e76b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,289] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.4457 ms, throughput: 46.6294 GB/s; offload_time: 21.3880 ms, put_time: 0.0577 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207038.2924232
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:307] Request job id arriving: 168, time is 1761207038.292878
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:315] Request job id: 168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,296] LMCache INFO:[0m Reqid: chatcmpl-36b6194c808342bd86ef46601c279a92, Total tokens 8510, LMCache hit tokens: 4608, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '76', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '151', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,778] LMCache INFO:[0m Storing KV cache for 3328 out of 7936 tokens (skip_leading_tokens=4608) for request chatcmpl-36b6194c808342bd86ef46601c279a92 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,787] LMCache INFO:[0m Stored 3328 out of total 3328 tokens. size: 0.4062 gb, cost 8.8756 ms, throughput: 45.7713 GB/s; offload_time: 8.8463 ms, put_time: 0.0293 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,788] LMCache INFO:[0m Storing KV cache for 4947 out of 33107 tokens (skip_leading_tokens=28160) for request chatcmpl-9040a4d175dd417f9156652ca446e76b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,801] LMCache INFO:[0m Stored 4947 out of total 4947 tokens. size: 0.6039 gb, cost 13.5657 ms, throughput: 44.5155 GB/s; offload_time: 13.5362 ms, put_time: 0.0294 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207038.8047273
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1462] Request GPU size bytes: 2326921216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1463] Token size of the request: 17731
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1469] Swap waste for job 150: 0.07223714192708333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1479] Accumulated tokens for job 150: 627453
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1481] Discard waste for job 150: 321.7350044847597
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1484] Preserve waste for job 150: 2.9287894475154386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:328] Request job id finishing: 112, time is 1761207038.8051596
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1462] Request GPU size bytes: 1784283136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1463] Token size of the request: 13596
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1469] Swap waste for job 112: 0.05539143880208333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1479] Accumulated tokens for job 112: 627453
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1481] Discard waste for job 112: 321.7350044847597
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [scheduler.py:1484] Preserve waste for job 112: 0.9375244354208311
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:307] Request job id arriving: 76, time is 1761207038.8058326
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:315] Request job id: 76
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:307] Request job id arriving: 151, time is 1761207038.8059657
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:38 [estimate_with_func.py:315] Request job id: 151
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,808] LMCache INFO:[0m Reqid: chatcmpl-0e91e6372b2b4f3f8ad16b7f6f9eaec1, Total tokens 9082, LMCache hit tokens: 4864, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:38,810] LMCache INFO:[0m Reqid: chatcmpl-34de79e88cf5489682f5302b51fba3c6, Total tokens 4881, LMCache hit tokens: 1024, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,091] LMCache INFO:[0m Storing KV cache for 4218 out of 9082 tokens (skip_leading_tokens=4864) for request chatcmpl-0e91e6372b2b4f3f8ad16b7f6f9eaec1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,102] LMCache INFO:[0m Stored 4218 out of total 4218 tokens. size: 0.5149 gb, cost 11.0950 ms, throughput: 46.4076 GB/s; offload_time: 11.0607 ms, put_time: 0.0344 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,102] LMCache INFO:[0m Storing KV cache for 3584 out of 4608 tokens (skip_leading_tokens=1024) for request chatcmpl-34de79e88cf5489682f5302b51fba3c6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '148', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,112] LMCache INFO:[0m Stored 3584 out of total 3584 tokens. size: 0.4375 gb, cost 10.1023 ms, throughput: 43.3069 GB/s; offload_time: 10.0724 ms, put_time: 0.0300 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,112] LMCache INFO:[0m Storing KV cache for 574 out of 8510 tokens (skip_leading_tokens=7936) for request chatcmpl-36b6194c808342bd86ef46601c279a92 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,114] LMCache INFO:[0m Stored 574 out of total 574 tokens. size: 0.0701 gb, cost 1.7002 ms, throughput: 41.2126 GB/s; offload_time: 1.6888 ms, put_time: 0.0114 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [estimate_with_func.py:307] Request job id arriving: 148, time is 1761207039.1177096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [estimate_with_func.py:315] Request job id: 148
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,120] LMCache INFO:[0m Reqid: chatcmpl-f1a85cb2bc494e259a579ea0589f8ab1, Total tokens 6326, LMCache hit tokens: 2048, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,122] LMCache INFO:[0m Reqid: chatcmpl-c10eb71578624af3a5fa6051ed37751d, Total tokens 5716, LMCache hit tokens: 1280, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '112', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,387] LMCache INFO:[0m Storing KV cache for 4278 out of 6326 tokens (skip_leading_tokens=2048) for request chatcmpl-f1a85cb2bc494e259a579ea0589f8ab1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,398] LMCache INFO:[0m Stored 4278 out of total 4278 tokens. size: 0.5222 gb, cost 11.1188 ms, throughput: 46.9672 GB/s; offload_time: 11.0939 ms, put_time: 0.0249 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,398] LMCache INFO:[0m Storing KV cache for 4096 out of 5376 tokens (skip_leading_tokens=1280) for request chatcmpl-c10eb71578624af3a5fa6051ed37751d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,409] LMCache INFO:[0m Stored 4096 out of total 4096 tokens. size: 0.5000 gb, cost 10.5466 ms, throughput: 47.4089 GB/s; offload_time: 10.5262 ms, put_time: 0.0204 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,409] LMCache INFO:[0m Storing KV cache for 273 out of 4881 tokens (skip_leading_tokens=4608) for request chatcmpl-34de79e88cf5489682f5302b51fba3c6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,410] LMCache INFO:[0m Stored 273 out of total 273 tokens. size: 0.0333 gb, cost 0.8590 ms, throughput: 38.7954 GB/s; offload_time: 0.8508 ms, put_time: 0.0082 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [estimate_with_func.py:328] Request job id finishing: 15, time is 1761207039.413149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [scheduler.py:1462] Request GPU size bytes: 717488128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [scheduler.py:1463] Token size of the request: 5446
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [scheduler.py:1469] Swap waste for job 15: 0.022273763020833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [scheduler.py:1479] Accumulated tokens for job 15: 622131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [scheduler.py:1481] Discard waste for job 15: 316.38367201904026
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [scheduler.py:1484] Preserve waste for job 15: 0.9387063242725491
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [estimate_with_func.py:307] Request job id arriving: 112, time is 1761207039.4136357
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [estimate_with_func.py:315] Request job id: 112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,416] LMCache INFO:[0m Reqid: chatcmpl-3f712fbb9238419da3b17df80669c019, Total tokens 20681, LMCache hit tokens: 11264, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '23', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,836] LMCache INFO:[0m Storing KV cache for 7680 out of 18944 tokens (skip_leading_tokens=11264) for request chatcmpl-3f712fbb9238419da3b17df80669c019 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,857] LMCache INFO:[0m Stored 7680 out of total 7680 tokens. size: 0.9375 gb, cost 20.1044 ms, throughput: 46.6315 GB/s; offload_time: 20.0585 ms, put_time: 0.0459 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,857] LMCache INFO:[0m Storing KV cache for 340 out of 5716 tokens (skip_leading_tokens=5376) for request chatcmpl-c10eb71578624af3a5fa6051ed37751d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,858] LMCache INFO:[0m Stored 340 out of total 340 tokens. size: 0.0415 gb, cost 1.0943 ms, throughput: 37.9267 GB/s; offload_time: 1.0839 ms, put_time: 0.0105 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [estimate_with_func.py:307] Request job id arriving: 23, time is 1761207039.8619595
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:39 [estimate_with_func.py:315] Request job id: 23
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:39,868] LMCache INFO:[0m Reqid: chatcmpl-10efd24d27624affab894eebd39a8f04, Total tokens 67172, LMCache hit tokens: 43776, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '87', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '15', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:10:40 [loggers.py:123] Engine 000: Avg prompt throughput: 28645.6 tokens/s, Avg generation throughput: 152.2 tokens/s, Running: 70 reqs, Waiting: 20 reqs, GPU KV cache usage: 55.6%, Prefix cache hit rate: 37.3%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:40,629] LMCache INFO:[0m Storing KV cache for 6656 out of 50432 tokens (skip_leading_tokens=43776) for request chatcmpl-10efd24d27624affab894eebd39a8f04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:40,648] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 18.3508 ms, throughput: 44.2759 GB/s; offload_time: 18.3052 ms, put_time: 0.0457 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:40,649] LMCache INFO:[0m Storing KV cache for 1737 out of 20681 tokens (skip_leading_tokens=18944) for request chatcmpl-3f712fbb9238419da3b17df80669c019 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:40,654] LMCache INFO:[0m Stored 1737 out of total 1737 tokens. size: 0.2120 gb, cost 4.8420 ms, throughput: 43.7907 GB/s; offload_time: 4.8224 ms, put_time: 0.0197 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [estimate_with_func.py:328] Request job id finishing: 142, time is 1761207040.6570644
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [scheduler.py:1462] Request GPU size bytes: 1770389504
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [scheduler.py:1463] Token size of the request: 13461
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [scheduler.py:1469] Swap waste for job 142: 0.05496012369791667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [scheduler.py:1479] Accumulated tokens for job 142: 704538
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [scheduler.py:1481] Discard waste for job 142: 404.27582120392833
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [scheduler.py:1484] Preserve waste for job 142: 2.9382890620321596
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [estimate_with_func.py:307] Request job id arriving: 87, time is 1761207040.6581447
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [estimate_with_func.py:315] Request job id: 87
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [estimate_with_func.py:307] Request job id arriving: 15, time is 1761207040.6583028
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:40 [estimate_with_func.py:315] Request job id: 15
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:41,566] LMCache INFO:[0m Storing KV cache for 7936 out of 58368 tokens (skip_leading_tokens=50432) for request chatcmpl-10efd24d27624affab894eebd39a8f04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:41,589] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.6991 ms, throughput: 44.6448 GB/s; offload_time: 21.6430 ms, put_time: 0.0561 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [estimate_with_func.py:328] Request job id finishing: 17, time is 1761207041.5921915
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [scheduler.py:1462] Request GPU size bytes: 1325924352
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [scheduler.py:1463] Token size of the request: 10046
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [scheduler.py:1469] Swap waste for job 17: 0.041162109375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [scheduler.py:1479] Accumulated tokens for job 17: 691077
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [scheduler.py:1481] Discard waste for job 17: 389.1838074670231
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [scheduler.py:1484] Preserve waste for job 17: 0.9384663008680247
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207041.593077
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:41 [estimate_with_func.py:315] Request job id: 150
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '17', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:42,611] LMCache INFO:[0m Storing KV cache for 8192 out of 66560 tokens (skip_leading_tokens=58368) for request chatcmpl-10efd24d27624affab894eebd39a8f04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:42,634] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.4861 ms, throughput: 44.4720 GB/s; offload_time: 22.4373 ms, put_time: 0.0487 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207042.637835
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [scheduler.py:1462] Request GPU size bytes: 1206124544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [scheduler.py:1463] Token size of the request: 9188
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [scheduler.py:1469] Swap waste for job 10: 0.03744303385416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [scheduler.py:1479] Accumulated tokens for job 10: 681031
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [scheduler.py:1481] Discard waste for job 10: 378.10760340014065
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [scheduler.py:1484] Preserve waste for job 10: 0.9384663008680247
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [estimate_with_func.py:307] Request job id arriving: 17, time is 1761207042.6384456
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:42 [estimate_with_func.py:315] Request job id: 17
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:42,641] LMCache INFO:[0m Reqid: chatcmpl-e7e76b5249084048b44bb7313881fb7c, Total tokens 2755, LMCache hit tokens: 1280, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:42,646] LMCache INFO:[0m Reqid: chatcmpl-77cacff2a7b8460dad2e328ebe020f04, Total tokens 60725, LMCache hit tokens: 43264, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '142', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:43,394] LMCache INFO:[0m Storing KV cache for 1475 out of 2755 tokens (skip_leading_tokens=1280) for request chatcmpl-e7e76b5249084048b44bb7313881fb7c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:43,398] LMCache INFO:[0m Stored 1475 out of total 1475 tokens. size: 0.1801 gb, cost 4.0548 ms, throughput: 44.4049 GB/s; offload_time: 4.0338 ms, put_time: 0.0210 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:43,399] LMCache INFO:[0m Storing KV cache for 6400 out of 49664 tokens (skip_leading_tokens=43264) for request chatcmpl-77cacff2a7b8460dad2e328ebe020f04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:43,417] LMCache INFO:[0m Stored 6400 out of total 6400 tokens. size: 0.7812 gb, cost 17.4081 ms, throughput: 44.8785 GB/s; offload_time: 17.3676 ms, put_time: 0.0405 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:43,418] LMCache INFO:[0m Storing KV cache for 612 out of 67172 tokens (skip_leading_tokens=66560) for request chatcmpl-10efd24d27624affab894eebd39a8f04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:43,421] LMCache INFO:[0m Stored 612 out of total 612 tokens. size: 0.0747 gb, cost 3.1661 ms, throughput: 23.5959 GB/s; offload_time: 3.1487 ms, put_time: 0.0174 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:43 [estimate_with_func.py:307] Request job id arriving: 142, time is 1761207043.425532
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:43 [estimate_with_func.py:315] Request job id: 142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:43 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207043.4257
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:43 [estimate_with_func.py:315] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:44,331] LMCache INFO:[0m Storing KV cache for 8192 out of 57856 tokens (skip_leading_tokens=49664) for request chatcmpl-77cacff2a7b8460dad2e328ebe020f04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:44,355] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.3855 ms, throughput: 44.6718 GB/s; offload_time: 22.3246 ms, put_time: 0.0609 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:44,363] LMCache INFO:[0m Reqid: chatcmpl-be0fe9c19c0f47789ae027be401fec23, Total tokens 76936, LMCache hit tokens: 29184, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '141', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '165', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:45,131] LMCache INFO:[0m Storing KV cache for 5376 out of 34560 tokens (skip_leading_tokens=29184) for request chatcmpl-be0fe9c19c0f47789ae027be401fec23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:45,146] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 14.8157 ms, throughput: 44.2941 GB/s; offload_time: 14.7765 ms, put_time: 0.0392 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:45,147] LMCache INFO:[0m Storing KV cache for 2869 out of 60725 tokens (skip_leading_tokens=57856) for request chatcmpl-77cacff2a7b8460dad2e328ebe020f04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:45,156] LMCache INFO:[0m Stored 2869 out of total 2869 tokens. size: 0.3502 gb, cost 8.6156 ms, throughput: 40.6495 GB/s; offload_time: 8.5954 ms, put_time: 0.0202 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [estimate_with_func.py:328] Request job id finishing: 144, time is 1761207045.1586797
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [scheduler.py:1462] Request GPU size bytes: 701366272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [scheduler.py:1463] Token size of the request: 5307
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [scheduler.py:1469] Swap waste for job 144: 0.021773274739583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [scheduler.py:1479] Accumulated tokens for job 144: 812259
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [scheduler.py:1481] Discard waste for job 144: 535.387376056761
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [scheduler.py:1484] Preserve waste for job 144: 0.9380420977526372
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [estimate_with_func.py:307] Request job id arriving: 141, time is 1761207045.1596947
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [estimate_with_func.py:315] Request job id: 141
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [estimate_with_func.py:307] Request job id arriving: 165, time is 1761207045.1599495
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:45 [estimate_with_func.py:315] Request job id: 165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:45,891] LMCache INFO:[0m Storing KV cache for 8192 out of 42752 tokens (skip_leading_tokens=34560) for request chatcmpl-be0fe9c19c0f47789ae027be401fec23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:45,914] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0084 ms, throughput: 45.4373 GB/s; offload_time: 21.9533 ms, put_time: 0.0550 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '144', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:46,748] LMCache INFO:[0m Storing KV cache for 8192 out of 50944 tokens (skip_leading_tokens=42752) for request chatcmpl-be0fe9c19c0f47789ae027be401fec23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:46,771] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.2647 ms, throughput: 44.9142 GB/s; offload_time: 22.2030 ms, put_time: 0.0616 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [estimate_with_func.py:328] Request job id finishing: 126, time is 1761207046.7738287
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1462] Request GPU size bytes: 179961856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1463] Token size of the request: 1249
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1469] Swap waste for job 126: 0.005586751302083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1479] Accumulated tokens for job 126: 806952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1481] Discard waste for job 126: 528.4975607696344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1484] Preserve waste for job 126: 0.9380420977526372
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [estimate_with_func.py:328] Request job id finishing: 123, time is 1761207046.7741604
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1462] Request GPU size bytes: 942538752
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1463] Token size of the request: 7095
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1469] Swap waste for job 123: 0.02926025390625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1479] Accumulated tokens for job 123: 806952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1481] Discard waste for job 123: 528.4975607696344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1484] Preserve waste for job 123: 3.0067579179275326
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [estimate_with_func.py:328] Request job id finishing: 127, time is 1761207046.7744977
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1462] Request GPU size bytes: 628359168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1463] Token size of the request: 4747
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1469] Swap waste for job 127: 0.0195068359375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1479] Accumulated tokens for job 127: 806952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1481] Discard waste for job 127: 528.4975607696344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1484] Preserve waste for job 127: 3.0067579179275326
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [estimate_with_func.py:328] Request job id finishing: 78, time is 1761207046.7747579
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1462] Request GPU size bytes: 3518365696
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1463] Token size of the request: 26823
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1469] Swap waste for job 78: 0.10922444661458333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1479] Accumulated tokens for job 78: 806952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1481] Discard waste for job 78: 528.4975607696344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [scheduler.py:1484] Preserve waste for job 78: 3.0067579179275326
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [estimate_with_func.py:307] Request job id arriving: 144, time is 1761207046.7753751
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:46 [estimate_with_func.py:315] Request job id: 144
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '126', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:47,700] LMCache INFO:[0m Storing KV cache for 8192 out of 59136 tokens (skip_leading_tokens=50944) for request chatcmpl-be0fe9c19c0f47789ae027be401fec23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:47,723] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.3308 ms, throughput: 44.7812 GB/s; offload_time: 22.2854 ms, put_time: 0.0454 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [estimate_with_func.py:328] Request job id finishing: 50, time is 1761207047.7260633
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [scheduler.py:1462] Request GPU size bytes: 2408448000
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [scheduler.py:1463] Token size of the request: 18359
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [scheduler.py:1469] Swap waste for job 50: 0.07476806640625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [scheduler.py:1479] Accumulated tokens for job 50: 767038
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [scheduler.py:1481] Discard waste for job 50: 478.1086847593783
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [scheduler.py:1484] Preserve waste for job 50: 0.9446955475152707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [estimate_with_func.py:307] Request job id arriving: 126, time is 1761207047.7266972
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:47 [estimate_with_func.py:315] Request job id: 126
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '50', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:48,750] LMCache INFO:[0m Storing KV cache for 7936 out of 67072 tokens (skip_leading_tokens=59136) for request chatcmpl-be0fe9c19c0f47789ae027be401fec23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:48,773] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.7734 ms, throughput: 44.4924 GB/s; offload_time: 21.7237 ms, put_time: 0.0497 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:48 [estimate_with_func.py:307] Request job id arriving: 50, time is 1761207048.776469
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:48 [estimate_with_func.py:315] Request job id: 50
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '123', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '78', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:49,908] LMCache INFO:[0m Storing KV cache for 8192 out of 75264 tokens (skip_leading_tokens=67072) for request chatcmpl-be0fe9c19c0f47789ae027be401fec23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:49,933] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.9569 ms, throughput: 43.5599 GB/s; offload_time: 22.8933 ms, put_time: 0.0635 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [estimate_with_func.py:328] Request job id finishing: 111, time is 1761207049.9365547
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [scheduler.py:1462] Request GPU size bytes: 665452544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [scheduler.py:1463] Token size of the request: 5033
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [scheduler.py:1469] Swap waste for job 111: 0.020658365885416665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [scheduler.py:1479] Accumulated tokens for job 111: 748679
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [scheduler.py:1481] Discard waste for job 111: 455.7789118677829
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [scheduler.py:1484] Preserve waste for job 111: 0.9457908295668088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [estimate_with_func.py:307] Request job id arriving: 123, time is 1761207049.937403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [estimate_with_func.py:315] Request job id: 123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [estimate_with_func.py:307] Request job id arriving: 78, time is 1761207049.9377422
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:49 [estimate_with_func.py:315] Request job id: 78
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:49,940] LMCache INFO:[0m Reqid: chatcmpl-eb54152c4f4a42988a9527fad435d39b, Total tokens 2594, LMCache hit tokens: 1024, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:49,942] LMCache INFO:[0m Reqid: chatcmpl-3ee439c8b2734a76bdc85fc283d5dd97, Total tokens 3824, LMCache hit tokens: 2304, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:49,944] LMCache INFO:[0m Reqid: chatcmpl-63c97fe515684cafbd15d491c39e1349, Total tokens 6272, LMCache hit tokens: 3072, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:49,947] LMCache INFO:[0m Reqid: chatcmpl-35c057f823504c01befe40acd905989f, Total tokens 18557, LMCache hit tokens: 8960, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,428] LMCache INFO:[0m Storing KV cache for 1570 out of 2594 tokens (skip_leading_tokens=1024) for request chatcmpl-eb54152c4f4a42988a9527fad435d39b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,433] LMCache INFO:[0m Stored 1570 out of total 1570 tokens. size: 0.1917 gb, cost 4.3927 ms, throughput: 43.6294 GB/s; offload_time: 4.3675 ms, put_time: 0.0252 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,433] LMCache INFO:[0m Storing KV cache for 1520 out of 3824 tokens (skip_leading_tokens=2304) for request chatcmpl-3ee439c8b2734a76bdc85fc283d5dd97 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,437] LMCache INFO:[0m Stored 1520 out of total 1520 tokens. size: 0.1855 gb, cost 4.0310 ms, throughput: 46.0304 GB/s; offload_time: 4.0181 ms, put_time: 0.0129 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,437] LMCache INFO:[0m Storing KV cache for 3200 out of 6272 tokens (skip_leading_tokens=3072) for request chatcmpl-63c97fe515684cafbd15d491c39e1349 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,445] LMCache INFO:[0m Stored 3200 out of total 3200 tokens. size: 0.3906 gb, cost 8.3465 ms, throughput: 46.8013 GB/s; offload_time: 8.3270 ms, put_time: 0.0194 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,446] LMCache INFO:[0m Storing KV cache for 1024 out of 9984 tokens (skip_leading_tokens=8960) for request chatcmpl-35c057f823504c01befe40acd905989f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,448] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 2.7960 ms, throughput: 44.7072 GB/s; offload_time: 2.7838 ms, put_time: 0.0122 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,449] LMCache INFO:[0m Storing KV cache for 1672 out of 76936 tokens (skip_leading_tokens=75264) for request chatcmpl-be0fe9c19c0f47789ae027be401fec23 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,455] LMCache INFO:[0m Stored 1672 out of total 1672 tokens. size: 0.2041 gb, cost 5.8891 ms, throughput: 34.6575 GB/s; offload_time: 5.8729 ms, put_time: 0.0162 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:10:50 [loggers.py:123] Engine 000: Avg prompt throughput: 24093.9 tokens/s, Avg generation throughput: 81.3 tokens/s, Running: 68 reqs, Waiting: 26 reqs, GPU KV cache usage: 67.0%, Prefix cache hit rate: 40.0%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,885] LMCache INFO:[0m Storing KV cache for 8192 out of 18176 tokens (skip_leading_tokens=9984) for request chatcmpl-35c057f823504c01befe40acd905989f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,907] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.1480 ms, throughput: 47.2858 GB/s; offload_time: 21.0924 ms, put_time: 0.0556 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207050.9098377
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1462] Request GPU size bytes: 806617088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1463] Token size of the request: 6111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1469] Swap waste for job 7: 0.025040690104166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1479] Accumulated tokens for job 7: 774893
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1481] Discard waste for job 7: 487.82568030745784
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1484] Preserve waste for job 7: 3.008643383003143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207050.9102886
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1462] Request GPU size bytes: 262668288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1463] Token size of the request: 1983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1469] Swap waste for job 68: 0.008154296875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1479] Accumulated tokens for job 68: 774893
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1481] Discard waste for job 68: 487.82568030745784
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1484] Preserve waste for job 68: 0.9457908295668088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207050.9104965
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1462] Request GPU size bytes: 2712403968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1463] Token size of the request: 20681
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1469] Swap waste for job 79: 0.0842041015625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1479] Accumulated tokens for job 79: 774893
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1481] Discard waste for job 79: 487.82568030745784
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:50 [scheduler.py:1484] Preserve waste for job 79: 0.9457908295668088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,921] LMCache INFO:[0m Reqid: chatcmpl-d9138c5735a14cc99ed82912cf034f4b, Total tokens 9057, LMCache hit tokens: 4864, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '111', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:50,923] LMCache INFO:[0m Reqid: chatcmpl-b1b02b2f70db47fc827fffbcd83acafa, Total tokens 13793, LMCache hit tokens: 7680, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,280] LMCache INFO:[0m Storing KV cache for 4193 out of 9057 tokens (skip_leading_tokens=4864) for request chatcmpl-d9138c5735a14cc99ed82912cf034f4b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,292] LMCache INFO:[0m Stored 4193 out of total 4193 tokens. size: 0.5118 gb, cost 11.4213 ms, throughput: 44.8145 GB/s; offload_time: 11.3780 ms, put_time: 0.0433 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,292] LMCache INFO:[0m Storing KV cache for 4096 out of 11776 tokens (skip_leading_tokens=7680) for request chatcmpl-b1b02b2f70db47fc827fffbcd83acafa [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,303] LMCache INFO:[0m Stored 4096 out of total 4096 tokens. size: 0.5000 gb, cost 10.6547 ms, throughput: 46.9276 GB/s; offload_time: 10.6309 ms, put_time: 0.0238 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,303] LMCache INFO:[0m Storing KV cache for 381 out of 18557 tokens (skip_leading_tokens=18176) for request chatcmpl-35c057f823504c01befe40acd905989f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,305] LMCache INFO:[0m Stored 381 out of total 381 tokens. size: 0.0465 gb, cost 1.3447 ms, throughput: 34.5867 GB/s; offload_time: 1.3334 ms, put_time: 0.0113 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [estimate_with_func.py:328] Request job id finishing: 3, time is 1761207051.3081136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [scheduler.py:1462] Request GPU size bytes: 4341760000
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [scheduler.py:1463] Token size of the request: 33107
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [scheduler.py:1469] Swap waste for job 3: 0.13478597005208334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [scheduler.py:1479] Accumulated tokens for job 3: 768968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [scheduler.py:1481] Discard waste for job 3: 480.48712680421716
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [scheduler.py:1484] Preserve waste for job 3: 0.9457908295668088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [estimate_with_func.py:307] Request job id arriving: 111, time is 1761207051.3091757
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [estimate_with_func.py:315] Request job id: 111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207051.309329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,312] LMCache INFO:[0m Reqid: chatcmpl-fab90019615a402dae316b44cd78db27, Total tokens 4587, LMCache hit tokens: 2304, need to load: -48 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,314] LMCache INFO:[0m Reqid: chatcmpl-f3c59e187d384775b1e166c12797aae0, Total tokens 2686, LMCache hit tokens: 1280, need to load: -272 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,315] LMCache INFO:[0m Reqid: chatcmpl-9e18edae888341bf831295cf01bc07f0, Total tokens 5362, LMCache hit tokens: 3584, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,317] LMCache INFO:[0m Reqid: chatcmpl-10444813541840d7a923dbfc2ffa1d70, Total tokens 5322, LMCache hit tokens: 3072, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,632] LMCache INFO:[0m Storing KV cache for 2283 out of 4587 tokens (skip_leading_tokens=2304) for request chatcmpl-fab90019615a402dae316b44cd78db27 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,638] LMCache INFO:[0m Stored 2283 out of total 2283 tokens. size: 0.2787 gb, cost 6.1608 ms, throughput: 45.2358 GB/s; offload_time: 6.1391 ms, put_time: 0.0217 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,638] LMCache INFO:[0m Storing KV cache for 1406 out of 2686 tokens (skip_leading_tokens=1280) for request chatcmpl-f3c59e187d384775b1e166c12797aae0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,642] LMCache INFO:[0m Stored 1406 out of total 1406 tokens. size: 0.1716 gb, cost 3.7307 ms, throughput: 46.0053 GB/s; offload_time: 3.7198 ms, put_time: 0.0109 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,642] LMCache INFO:[0m Storing KV cache for 1778 out of 5362 tokens (skip_leading_tokens=3584) for request chatcmpl-9e18edae888341bf831295cf01bc07f0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,648] LMCache INFO:[0m Stored 1778 out of total 1778 tokens. size: 0.2170 gb, cost 5.5902 ms, throughput: 38.8252 GB/s; offload_time: 5.5743 ms, put_time: 0.0159 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,648] LMCache INFO:[0m Storing KV cache for 1280 out of 4352 tokens (skip_leading_tokens=3072) for request chatcmpl-10444813541840d7a923dbfc2ffa1d70 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,652] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.3728 ms, throughput: 46.3267 GB/s; offload_time: 3.3622 ms, put_time: 0.0106 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,652] LMCache INFO:[0m Storing KV cache for 2017 out of 13793 tokens (skip_leading_tokens=11776) for request chatcmpl-b1b02b2f70db47fc827fffbcd83acafa [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,657] LMCache INFO:[0m Stored 2017 out of total 2017 tokens. size: 0.2462 gb, cost 5.3959 ms, throughput: 45.6301 GB/s; offload_time: 5.3796 ms, put_time: 0.0163 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207051.6607254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:51 [estimate_with_func.py:315] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:51,664] LMCache INFO:[0m Reqid: chatcmpl-685951cd111346b2957244aba6e487c7, Total tokens 31074, LMCache hit tokens: 18944, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '3', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,174] LMCache INFO:[0m Storing KV cache for 7168 out of 26112 tokens (skip_leading_tokens=18944) for request chatcmpl-685951cd111346b2957244aba6e487c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,194] LMCache INFO:[0m Stored 7168 out of total 7168 tokens. size: 0.8750 gb, cost 18.7997 ms, throughput: 46.5433 GB/s; offload_time: 18.7430 ms, put_time: 0.0567 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,194] LMCache INFO:[0m Storing KV cache for 970 out of 5322 tokens (skip_leading_tokens=4352) for request chatcmpl-10444813541840d7a923dbfc2ffa1d70 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,197] LMCache INFO:[0m Stored 970 out of total 970 tokens. size: 0.1184 gb, cost 2.7133 ms, throughput: 43.6399 GB/s; offload_time: 2.7022 ms, put_time: 0.0111 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207052.2002037
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1462] Request GPU size bytes: 2268987392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1463] Token size of the request: 17289
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1469] Swap waste for job 174: 0.07043863932291666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1479] Accumulated tokens for job 174: 784892
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1481] Discard waste for job 174: 500.33628907435747
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1484] Preserve waste for job 174: 3.008643383003143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [estimate_with_func.py:307] Request job id arriving: 3, time is 1761207052.2010038
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [estimate_with_func.py:315] Request job id: 3
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,204] LMCache INFO:[0m Reqid: chatcmpl-fe057b27c2a442f5bb745dd1acec3ffb, Total tokens 7338, LMCache hit tokens: 3840, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,208] LMCache INFO:[0m Reqid: chatcmpl-ce015a16646e4215b57dbceeeb81010f, Total tokens 30964, LMCache hit tokens: 18944, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,697] LMCache INFO:[0m Storing KV cache for 3498 out of 7338 tokens (skip_leading_tokens=3840) for request chatcmpl-fe057b27c2a442f5bb745dd1acec3ffb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,706] LMCache INFO:[0m Stored 3498 out of total 3498 tokens. size: 0.4270 gb, cost 9.2636 ms, throughput: 46.0947 GB/s; offload_time: 9.2307 ms, put_time: 0.0329 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,707] LMCache INFO:[0m Storing KV cache for 256 out of 19200 tokens (skip_leading_tokens=18944) for request chatcmpl-ce015a16646e4215b57dbceeeb81010f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,708] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.9087 ms, throughput: 34.3914 GB/s; offload_time: 0.8985 ms, put_time: 0.0102 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,708] LMCache INFO:[0m Storing KV cache for 4962 out of 31074 tokens (skip_leading_tokens=26112) for request chatcmpl-685951cd111346b2957244aba6e487c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:52,722] LMCache INFO:[0m Stored 4962 out of total 4962 tokens. size: 0.6057 gb, cost 13.4802 ms, throughput: 44.9336 GB/s; offload_time: 13.4436 ms, put_time: 0.0365 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [estimate_with_func.py:328] Request job id finishing: 83, time is 1761207052.7251258
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1462] Request GPU size bytes: 542769152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1463] Token size of the request: 4097
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1469] Swap waste for job 83: 0.016849772135416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1479] Accumulated tokens for job 83: 805905
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1481] Discard waste for job 83: 527.1435613066039
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:52 [scheduler.py:1484] Preserve waste for job 83: 3.008643383003143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,275] LMCache INFO:[0m Storing KV cache for 7936 out of 27136 tokens (skip_leading_tokens=19200) for request chatcmpl-ce015a16646e4215b57dbceeeb81010f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,296] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.6964 ms, throughput: 46.8076 GB/s; offload_time: 20.6534 ms, put_time: 0.0430 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [estimate_with_func.py:328] Request job id finishing: 109, time is 1761207053.29881
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1462] Request GPU size bytes: 368836608
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1463] Token size of the request: 2741
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1469] Swap waste for job 109: 0.0114501953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1479] Accumulated tokens for job 109: 801808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1481] Discard waste for job 109: 521.8619373635544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1484] Preserve waste for job 109: 3.008643383003143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [estimate_with_func.py:328] Request job id finishing: 101, time is 1761207053.2992024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1462] Request GPU size bytes: 751697920
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1463] Token size of the request: 5716
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1469] Swap waste for job 101: 0.023335774739583332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1479] Accumulated tokens for job 101: 801808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1481] Discard waste for job 101: 521.8619373635544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:53 [scheduler.py:1484] Preserve waste for job 101: 3.008643383003143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,302] LMCache INFO:[0m Reqid: chatcmpl-08bf9d3f1ab74d86892d9c5012469a6c, Total tokens 10834, LMCache hit tokens: 4864, need to load: -256 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,772] LMCache INFO:[0m Storing KV cache for 4608 out of 9472 tokens (skip_leading_tokens=4864) for request chatcmpl-08bf9d3f1ab74d86892d9c5012469a6c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,784] LMCache INFO:[0m Stored 4608 out of total 4608 tokens. size: 0.5625 gb, cost 12.1064 ms, throughput: 46.4631 GB/s; offload_time: 12.0555 ms, put_time: 0.0509 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,785] LMCache INFO:[0m Storing KV cache for 3828 out of 30964 tokens (skip_leading_tokens=27136) for request chatcmpl-ce015a16646e4215b57dbceeeb81010f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,795] LMCache INFO:[0m Stored 3828 out of total 3828 tokens. size: 0.4673 gb, cost 10.3814 ms, throughput: 45.0119 GB/s; offload_time: 10.3579 ms, put_time: 0.0235 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,801] LMCache INFO:[0m Reqid: chatcmpl-feeb51c96c9d4073a0364d72e71dd396, Total tokens 4258, LMCache hit tokens: 2560, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:53,804] LMCache INFO:[0m Reqid: chatcmpl-196153a257db4e39b63ae689d20ea37d, Total tokens 27934, LMCache hit tokens: 13568, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '127', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:43098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,224] LMCache INFO:[0m Storing KV cache for 1698 out of 4258 tokens (skip_leading_tokens=2560) for request chatcmpl-feeb51c96c9d4073a0364d72e71dd396 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,229] LMCache INFO:[0m Stored 1698 out of total 1698 tokens. size: 0.2073 gb, cost 4.6063 ms, throughput: 44.9979 GB/s; offload_time: 4.5850 ms, put_time: 0.0214 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,229] LMCache INFO:[0m Storing KV cache for 5376 out of 18944 tokens (skip_leading_tokens=13568) for request chatcmpl-196153a257db4e39b63ae689d20ea37d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,243] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 13.9691 ms, throughput: 46.9786 GB/s; offload_time: 13.9336 ms, put_time: 0.0355 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,243] LMCache INFO:[0m Storing KV cache for 1362 out of 10834 tokens (skip_leading_tokens=9472) for request chatcmpl-08bf9d3f1ab74d86892d9c5012469a6c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,247] LMCache INFO:[0m Stored 1362 out of total 1362 tokens. size: 0.1663 gb, cost 3.7125 ms, throughput: 44.7839 GB/s; offload_time: 3.7002 ms, put_time: 0.0123 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [estimate_with_func.py:328] Request job id finishing: 1, time is 1761207054.2501452
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1462] Request GPU size bytes: 1156710400
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1463] Token size of the request: 8727
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1469] Swap waste for job 1: 0.035909016927083336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1479] Accumulated tokens for job 1: 836377
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1481] Discard waste for job 1: 567.2606305717103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1484] Preserve waste for job 1: 3.008643383003143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [estimate_with_func.py:307] Request job id arriving: 127, time is 1761207054.2510443
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [estimate_with_func.py:315] Request job id: 127
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,803] LMCache INFO:[0m Storing KV cache for 8192 out of 27136 tokens (skip_leading_tokens=18944) for request chatcmpl-196153a257db4e39b63ae689d20ea37d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,825] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3915 ms, throughput: 46.7475 GB/s; offload_time: 21.3410 ms, put_time: 0.0505 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [estimate_with_func.py:328] Request job id finishing: 124, time is 1761207054.8278775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1462] Request GPU size bytes: 1117519872
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1463] Token size of the request: 8431
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1469] Swap waste for job 124: 0.0346923828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1479] Accumulated tokens for job 124: 827650
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1481] Discard waste for job 124: 555.6210461218059
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1484] Preserve waste for job 124: 0.9423806115433022
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207054.828298
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1462] Request GPU size bytes: 325058560
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1463] Token size of the request: 2411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1469] Swap waste for job 102: 0.010091145833333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1479] Accumulated tokens for job 102: 827650
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1481] Discard waste for job 102: 555.6210461218059
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [scheduler.py:1484] Preserve waste for job 102: 3.035397618116733
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207054.8287442
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:54 [estimate_with_func.py:315] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:54,831] LMCache INFO:[0m Reqid: chatcmpl-139f6f2a96724b4b8bce540b14ca1ee4, Total tokens 16329, LMCache hit tokens: 8448, need to load: -272 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,268] LMCache INFO:[0m Storing KV cache for 7424 out of 15872 tokens (skip_leading_tokens=8448) for request chatcmpl-139f6f2a96724b4b8bce540b14ca1ee4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,287] LMCache INFO:[0m Stored 7424 out of total 7424 tokens. size: 0.9062 gb, cost 19.2400 ms, throughput: 47.1023 GB/s; offload_time: 19.1847 ms, put_time: 0.0554 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,288] LMCache INFO:[0m Storing KV cache for 798 out of 27934 tokens (skip_leading_tokens=27136) for request chatcmpl-196153a257db4e39b63ae689d20ea37d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,290] LMCache INFO:[0m Stored 798 out of total 798 tokens. size: 0.0974 gb, cost 2.6467 ms, throughput: 36.8046 GB/s; offload_time: 2.6351 ms, put_time: 0.0116 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [estimate_with_func.py:328] Request job id finishing: 119, time is 1761207055.2934968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1462] Request GPU size bytes: 236584960
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1463] Token size of the request: 1735
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1469] Swap waste for job 119: 0.007344563802083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1479] Accumulated tokens for job 119: 833137
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1481] Discard waste for job 119: 562.9252199941383
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1484] Preserve waste for job 119: 3.0329757148311254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,297] LMCache INFO:[0m Reqid: chatcmpl-a7c9a10aed8f45d5b5e808a27b62e051, Total tokens 17047, LMCache hit tokens: 8960, need to load: -288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,300] LMCache INFO:[0m Reqid: chatcmpl-9cd6c323bb5342deb09a5eda2c3ed9d6, Total tokens 8503, LMCache hit tokens: 5376, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,732] LMCache INFO:[0m Storing KV cache for 8087 out of 17047 tokens (skip_leading_tokens=8960) for request chatcmpl-a7c9a10aed8f45d5b5e808a27b62e051 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,754] LMCache INFO:[0m Stored 8087 out of total 8087 tokens. size: 0.9872 gb, cost 21.0220 ms, throughput: 46.9594 GB/s; offload_time: 20.9813 ms, put_time: 0.0407 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,754] LMCache INFO:[0m Storing KV cache for 457 out of 16329 tokens (skip_leading_tokens=15872) for request chatcmpl-139f6f2a96724b4b8bce540b14ca1ee4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,755] LMCache INFO:[0m Stored 457 out of total 457 tokens. size: 0.0558 gb, cost 1.4351 ms, throughput: 38.8722 GB/s; offload_time: 1.4258 ms, put_time: 0.0093 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [estimate_with_func.py:328] Request job id finishing: 117, time is 1761207055.7583506
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1462] Request GPU size bytes: 437518336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1463] Token size of the request: 3240
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1469] Swap waste for job 117: 0.013582356770833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1479] Accumulated tokens for job 117: 856952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1481] Discard waste for job 117: 595.1798932830744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1484] Preserve waste for job 117: 3.0329757148311254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207055.758686
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1462] Request GPU size bytes: 1726480384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1463] Token size of the request: 13126
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1469] Swap waste for job 136: 0.05359700520833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1479] Accumulated tokens for job 136: 856952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1481] Discard waste for job 136: 595.1798932830744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1484] Preserve waste for job 136: 0.9423806115433022
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207055.758949
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1462] Request GPU size bytes: 2009333760
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1463] Token size of the request: 15286
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1469] Swap waste for job 138: 0.0623779296875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1479] Accumulated tokens for job 138: 856952
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1481] Discard waste for job 138: 595.1798932830744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:55 [scheduler.py:1484] Preserve waste for job 138: 3.0329757148311254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:55,763] LMCache INFO:[0m Reqid: chatcmpl-1d7d1555a6874dc19b2c689c717ba8e5, Total tokens 33165, LMCache hit tokens: 17664, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '124', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '101', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '109', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:56,218] LMCache INFO:[0m Storing KV cache for 5120 out of 22784 tokens (skip_leading_tokens=17664) for request chatcmpl-1d7d1555a6874dc19b2c689c717ba8e5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:56,232] LMCache INFO:[0m Stored 5120 out of total 5120 tokens. size: 0.6250 gb, cost 13.4304 ms, throughput: 46.5362 GB/s; offload_time: 13.3865 ms, put_time: 0.0439 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:56,232] LMCache INFO:[0m Storing KV cache for 3127 out of 8503 tokens (skip_leading_tokens=5376) for request chatcmpl-9cd6c323bb5342deb09a5eda2c3ed9d6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:56,241] LMCache INFO:[0m Stored 3127 out of total 3127 tokens. size: 0.3817 gb, cost 8.2490 ms, throughput: 46.2738 GB/s; offload_time: 8.2273 ms, put_time: 0.0217 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:328] Request job id finishing: 32, time is 1761207056.2437787
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1462] Request GPU size bytes: 219938816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1463] Token size of the request: 1607
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1469] Swap waste for job 32: 0.006827799479166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1479] Accumulated tokens for job 32: 858465
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1481] Discard waste for job 32: 597.2594272943098
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1484] Preserve waste for job 32: 3.0329757148311254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:307] Request job id arriving: 124, time is 1761207056.2445168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:315] Request job id: 124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:307] Request job id arriving: 101, time is 1761207056.244646
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:315] Request job id: 101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:307] Request job id arriving: 109, time is 1761207056.2447205
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:315] Request job id: 109
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '1', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '83', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:56,851] LMCache INFO:[0m Storing KV cache for 8192 out of 30976 tokens (skip_leading_tokens=22784) for request chatcmpl-1d7d1555a6874dc19b2c689c717ba8e5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:56,873] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3819 ms, throughput: 46.7686 GB/s; offload_time: 21.3205 ms, put_time: 0.0613 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:328] Request job id finishing: 107, time is 1761207056.8758404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1462] Request GPU size bytes: 550109184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1463] Token size of the request: 4143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1469] Swap waste for job 107: 0.01707763671875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1479] Accumulated tokens for job 107: 856858
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1481] Discard waste for job 107: 595.0508151678359
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [scheduler.py:1484] Preserve waste for job 107: 0.9467314733277767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207056.87641
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:315] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:307] Request job id arriving: 1, time is 1761207056.876526
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:315] Request job id: 1
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:307] Request job id arriving: 83, time is 1761207056.876725
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:56 [estimate_with_func.py:315] Request job id: 83
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:56,880] LMCache INFO:[0m Reqid: chatcmpl-fed362fe7a9c45f491392ae79e2fc75f, Total tokens 21780, LMCache hit tokens: 9984, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,373] LMCache INFO:[0m Storing KV cache for 5888 out of 15872 tokens (skip_leading_tokens=9984) for request chatcmpl-fed362fe7a9c45f491392ae79e2fc75f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,388] LMCache INFO:[0m Stored 5888 out of total 5888 tokens. size: 0.7188 gb, cost 15.2405 ms, throughput: 47.1605 GB/s; offload_time: 15.2103 ms, put_time: 0.0302 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,389] LMCache INFO:[0m Storing KV cache for 2189 out of 33165 tokens (skip_leading_tokens=30976) for request chatcmpl-1d7d1555a6874dc19b2c689c717ba8e5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,396] LMCache INFO:[0m Stored 2189 out of total 2189 tokens. size: 0.2672 gb, cost 6.6758 ms, throughput: 40.0269 GB/s; offload_time: 6.6589 ms, put_time: 0.0169 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207057.3988254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1462] Request GPU size bytes: 1188823040
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1463] Token size of the request: 9057
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1469] Swap waste for job 44: 0.036905924479166664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1479] Accumulated tokens for job 44: 874495
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1481] Discard waste for job 44: 619.5144845640731
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1484] Preserve waste for job 44: 0.9482863036069002
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,403] LMCache INFO:[0m Reqid: chatcmpl-dabf5c7a18d54a229254047be88797e2, Total tokens 21545, LMCache hit tokens: 13312, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '107', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '117', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,897] LMCache INFO:[0m Storing KV cache for 2560 out of 15872 tokens (skip_leading_tokens=13312) for request chatcmpl-dabf5c7a18d54a229254047be88797e2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,905] LMCache INFO:[0m Stored 2560 out of total 2560 tokens. size: 0.3125 gb, cost 6.9566 ms, throughput: 44.9213 GB/s; offload_time: 6.9318 ms, put_time: 0.0248 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,905] LMCache INFO:[0m Storing KV cache for 5908 out of 21780 tokens (skip_leading_tokens=15872) for request chatcmpl-fed362fe7a9c45f491392ae79e2fc75f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,921] LMCache INFO:[0m Stored 5908 out of total 5908 tokens. size: 0.7212 gb, cost 16.2182 ms, throughput: 44.4681 GB/s; offload_time: 16.1824 ms, put_time: 0.0358 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:328] Request job id finishing: 98, time is 1761207057.9241142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1462] Request GPU size bytes: 2505179136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1463] Token size of the request: 19017
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1469] Swap waste for job 98: 0.07777099609375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1479] Accumulated tokens for job 98: 886983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1481] Discard waste for job 98: 637.134100546221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1484] Preserve waste for job 98: 3.0361003446024517
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207057.924677
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1462] Request GPU size bytes: 342097920
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1463] Token size of the request: 2594
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1469] Swap waste for job 173: 0.0106201171875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1479] Accumulated tokens for job 173: 886983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1481] Discard waste for job 173: 637.134100546221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [scheduler.py:1484] Preserve waste for job 173: 3.0361003446024517
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:307] Request job id arriving: 107, time is 1761207057.9251816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:315] Request job id: 107
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207057.9254203
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:315] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207057.9255247
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:315] Request job id: 44
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:307] Request job id arriving: 117, time is 1761207057.9255872
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:57 [estimate_with_func.py:315] Request job id: 117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:57,928] LMCache INFO:[0m Reqid: chatcmpl-f10b8529a1c3484fbaca85804f3fd878, Total tokens 13815, LMCache hit tokens: 8960, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '119', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58658 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,396] LMCache INFO:[0m Storing KV cache for 2560 out of 11520 tokens (skip_leading_tokens=8960) for request chatcmpl-f10b8529a1c3484fbaca85804f3fd878 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,404] LMCache INFO:[0m Stored 2560 out of total 2560 tokens. size: 0.3125 gb, cost 6.8186 ms, throughput: 45.8302 GB/s; offload_time: 6.7936 ms, put_time: 0.0250 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,404] LMCache INFO:[0m Storing KV cache for 5673 out of 21545 tokens (skip_leading_tokens=15872) for request chatcmpl-dabf5c7a18d54a229254047be88797e2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,419] LMCache INFO:[0m Stored 5673 out of total 5673 tokens. size: 0.6925 gb, cost 14.9403 ms, throughput: 46.3514 GB/s; offload_time: 14.9050 ms, put_time: 0.0353 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:328] Request job id finishing: 91, time is 1761207058.4218674
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1462] Request GPU size bytes: 4224581632
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1463] Token size of the request: 32163
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1469] Swap waste for job 91: 0.13114827473958332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1479] Accumulated tokens for job 91: 879187
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1481] Discard waste for job 91: 626.1055689959793
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1484] Preserve waste for job 91: 3.031457606403307
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207058.4226208
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1462] Request GPU size bytes: 704643072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1463] Token size of the request: 5362
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1469] Swap waste for job 156: 0.021875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1479] Accumulated tokens for job 156: 879187
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1481] Discard waste for job 156: 626.1055689959793
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1484] Preserve waste for job 156: 0.9454249782221658
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:307] Request job id arriving: 119, time is 1761207058.423212
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:315] Request job id: 119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,425] LMCache INFO:[0m Reqid: chatcmpl-de7d568b82774fbf93f63dfad487bae3, Total tokens 3375, LMCache hit tokens: 2048, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,427] LMCache INFO:[0m Reqid: chatcmpl-d54df4d22985425c96bff610edef4687, Total tokens 3807, LMCache hit tokens: 2304, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,429] LMCache INFO:[0m Reqid: chatcmpl-0ec165ea702a4505939c09b46cc2d463, Total tokens 16407, LMCache hit tokens: 5120, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '32', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,780] LMCache INFO:[0m Storing KV cache for 1327 out of 3375 tokens (skip_leading_tokens=2048) for request chatcmpl-de7d568b82774fbf93f63dfad487bae3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,784] LMCache INFO:[0m Stored 1327 out of total 1327 tokens. size: 0.1620 gb, cost 3.7353 ms, throughput: 43.3666 GB/s; offload_time: 3.7152 ms, put_time: 0.0201 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,784] LMCache INFO:[0m Storing KV cache for 1503 out of 3807 tokens (skip_leading_tokens=2304) for request chatcmpl-d54df4d22985425c96bff610edef4687 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,788] LMCache INFO:[0m Stored 1503 out of total 1503 tokens. size: 0.1835 gb, cost 3.9728 ms, throughput: 46.1815 GB/s; offload_time: 3.9598 ms, put_time: 0.0130 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,789] LMCache INFO:[0m Storing KV cache for 3584 out of 8704 tokens (skip_leading_tokens=5120) for request chatcmpl-0ec165ea702a4505939c09b46cc2d463 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,798] LMCache INFO:[0m Stored 3584 out of total 3584 tokens. size: 0.4375 gb, cost 9.2709 ms, throughput: 47.1907 GB/s; offload_time: 9.2515 ms, put_time: 0.0194 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,798] LMCache INFO:[0m Storing KV cache for 2295 out of 13815 tokens (skip_leading_tokens=11520) for request chatcmpl-f10b8529a1c3484fbaca85804f3fd878 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,804] LMCache INFO:[0m Stored 2295 out of total 2295 tokens. size: 0.2802 gb, cost 6.1016 ms, throughput: 45.9147 GB/s; offload_time: 6.0860 ms, put_time: 0.0156 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207058.8073723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1462] Request GPU size bytes: 699400192
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1463] Token size of the request: 5322
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1469] Swap waste for job 5: 0.021712239583333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1479] Accumulated tokens for job 5: 865251
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1481] Discard waste for job 5: 606.6310075647491
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1484] Preserve waste for job 5: 0.9454249782221658
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207058.8076546
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1462] Request GPU size bytes: 4074635264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1463] Token size of the request: 31074
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1469] Swap waste for job 164: 0.12649332682291667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1479] Accumulated tokens for job 164: 865251
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1481] Discard waste for job 164: 606.6310075647491
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [scheduler.py:1484] Preserve waste for job 164: 0.9454249782221658
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:307] Request job id arriving: 32, time is 1761207058.8083045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:58 [estimate_with_func.py:315] Request job id: 32
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,811] LMCache INFO:[0m Reqid: chatcmpl-cbc42128ddf6492fbe4b94ed2f504928, Total tokens 2648, LMCache hit tokens: 1024, need to load: 1008 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:58,816] LMCache INFO:[0m Retrieved 1024 out of 1024 required tokens (from 1024 total tokens). size: 0.1250 gb, cost 2.9884 ms, throughput: 41.8283 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,222] LMCache INFO:[0m Storing KV cache for 512 out of 1536 tokens (skip_leading_tokens=1024) for request chatcmpl-cbc42128ddf6492fbe4b94ed2f504928 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,224] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.4848 ms, throughput: 42.0929 GB/s; offload_time: 1.4737 ms, put_time: 0.0111 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,224] LMCache INFO:[0m Storing KV cache for 7703 out of 16407 tokens (skip_leading_tokens=8704) for request chatcmpl-0ec165ea702a4505939c09b46cc2d463 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,244] LMCache INFO:[0m Stored 7703 out of total 7703 tokens. size: 0.9403 gb, cost 19.8976 ms, throughput: 47.2573 GB/s; offload_time: 19.8596 ms, put_time: 0.0380 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207059.2481167
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:315] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,253] LMCache INFO:[0m Reqid: chatcmpl-a81d0a4776ac4611857cdb91070e46ee, Total tokens 34179, LMCache hit tokens: 18176, need to load: -192 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:39140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,753] LMCache INFO:[0m Storing KV cache for 7168 out of 25344 tokens (skip_leading_tokens=18176) for request chatcmpl-a81d0a4776ac4611857cdb91070e46ee [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,772] LMCache INFO:[0m Stored 7168 out of total 7168 tokens. size: 0.8750 gb, cost 18.9179 ms, throughput: 46.2525 GB/s; offload_time: 18.8628 ms, put_time: 0.0551 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,772] LMCache INFO:[0m Storing KV cache for 1112 out of 2648 tokens (skip_leading_tokens=1536) for request chatcmpl-cbc42128ddf6492fbe4b94ed2f504928 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:10:59,776] LMCache INFO:[0m Stored 1112 out of total 1112 tokens. size: 0.1357 gb, cost 3.0577 ms, throughput: 44.3942 GB/s; offload_time: 3.0441 ms, put_time: 0.0136 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:328] Request job id finishing: 160, time is 1761207059.778923
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [scheduler.py:1462] Request GPU size bytes: 560463872
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [scheduler.py:1463] Token size of the request: 4234
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [scheduler.py:1469] Swap waste for job 160: 0.017399088541666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [scheduler.py:1479] Accumulated tokens for job 160: 865682
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [scheduler.py:1481] Discard waste for job 160: 607.2286893122136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [scheduler.py:1484] Preserve waste for job 160: 3.0293628695336254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207059.7797253
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207059.7798576
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:315] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207059.7799323
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:10:59 [estimate_with_func.py:315] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,420] LMCache INFO:[0m Storing KV cache for 7936 out of 33280 tokens (skip_leading_tokens=25344) for request chatcmpl-a81d0a4776ac4611857cdb91070e46ee [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,442] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.1589 ms, throughput: 45.7845 GB/s; offload_time: 21.0942 ms, put_time: 0.0647 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [estimate_with_func.py:328] Request job id finishing: 146, time is 1761207060.4453838
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1462] Request GPU size bytes: 1810235392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1463] Token size of the request: 13793
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1469] Swap waste for job 146: 0.056197102864583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1479] Accumulated tokens for job 146: 861448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1481] Discard waste for job 146: 601.3700159746404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1484] Preserve waste for job 146: 3.0677462642112476
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [estimate_with_func.py:328] Request job id finishing: 76, time is 1761207060.4458678
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1462] Request GPU size bytes: 4060348416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1463] Token size of the request: 30964
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1469] Swap waste for job 76: 0.1260498046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1479] Accumulated tokens for job 76: 861448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1481] Discard waste for job 76: 601.3700159746404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1484] Preserve waste for job 76: 0.9446077054007012
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,449] LMCache INFO:[0m Reqid: chatcmpl-2c22ccaed0434aaaa3c093ac27688928, Total tokens 13283, LMCache hit tokens: 6912, need to load: 6896 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,453] LMCache INFO:[0m Reqid: chatcmpl-a4a31075fdad47dcb4e0b3db7b9af732, Total tokens 47815, LMCache hit tokens: 26624, need to load: 20608 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,479] LMCache INFO:[0m Retrieved 6912 out of 6912 required tokens (from 6912 total tokens). size: 0.8438 gb, cost 18.2997 ms, throughput: 46.1072 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,534] LMCache INFO:[0m Retrieved 20736 out of 20736 required tokens (from 26624 total tokens). size: 2.5312 gb, cost 54.7030 ms, throughput: 46.2726 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:11:00 [loggers.py:123] Engine 000: Avg prompt throughput: 33017.3 tokens/s, Avg generation throughput: 136.3 tokens/s, Running: 65 reqs, Waiting: 24 reqs, GPU KV cache usage: 71.3%, Prefix cache hit rate: 42.6%
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '76', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58674 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '91', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,972] LMCache INFO:[0m Storing KV cache for 6371 out of 13283 tokens (skip_leading_tokens=6912) for request chatcmpl-2c22ccaed0434aaaa3c093ac27688928 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,989] LMCache INFO:[0m Stored 6371 out of total 6371 tokens. size: 0.7777 gb, cost 16.8971 ms, throughput: 46.0262 GB/s; offload_time: 16.8515 ms, put_time: 0.0456 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,989] LMCache INFO:[0m Storing KV cache for 1024 out of 27648 tokens (skip_leading_tokens=26624) for request chatcmpl-a4a31075fdad47dcb4e0b3db7b9af732 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,993] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 3.0104 ms, throughput: 41.5225 GB/s; offload_time: 2.9971 ms, put_time: 0.0133 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,993] LMCache INFO:[0m Storing KV cache for 899 out of 34179 tokens (skip_leading_tokens=33280) for request chatcmpl-a81d0a4776ac4611857cdb91070e46ee [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:00,996] LMCache INFO:[0m Stored 899 out of total 899 tokens. size: 0.1097 gb, cost 3.0482 ms, throughput: 36.0023 GB/s; offload_time: 3.0325 ms, put_time: 0.0157 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [estimate_with_func.py:328] Request job id finishing: 110, time is 1761207060.9996712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1462] Request GPU size bytes: 351797248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1463] Token size of the request: 2590
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1469] Swap waste for job 110: 0.010921223958333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1479] Accumulated tokens for job 110: 877789
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1481] Discard waste for job 110: 624.1380821621057
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:00 [scheduler.py:1484] Preserve waste for job 110: 3.0677462642112476
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207061.0007164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:315] Request job id: 173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:307] Request job id arriving: 76, time is 1761207061.0008705
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:315] Request job id: 76
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207061.000943
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:315] Request job id: 5
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:307] Request job id arriving: 91, time is 1761207061.0010076
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:315] Request job id: 91
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:01,668] LMCache INFO:[0m Storing KV cache for 8192 out of 35840 tokens (skip_leading_tokens=27648) for request chatcmpl-a4a31075fdad47dcb4e0b3db7b9af732 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:01,691] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.8178 ms, throughput: 45.8341 GB/s; offload_time: 21.7532 ms, put_time: 0.0647 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [estimate_with_func.py:328] Request job id finishing: 23, time is 1761207061.6938086
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [scheduler.py:1462] Request GPU size bytes: 2141847552
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [scheduler.py:1463] Token size of the request: 16329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [scheduler.py:1469] Swap waste for job 23: 0.06649169921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [scheduler.py:1479] Accumulated tokens for job 23: 875199
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [scheduler.py:1481] Discard waste for job 23: 620.5012046405211
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:01 [scheduler.py:1484] Preserve waste for job 23: 0.95201575756073
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '98', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '160', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '23', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:02,461] LMCache INFO:[0m Storing KV cache for 7936 out of 43776 tokens (skip_leading_tokens=35840) for request chatcmpl-a4a31075fdad47dcb4e0b3db7b9af732 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:02,483] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3408 ms, throughput: 45.3943 GB/s; offload_time: 21.2941 ms, put_time: 0.0467 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:328] Request job id finishing: 90, time is 1761207062.486628
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1462] Request GPU size bytes: 554172416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1463] Token size of the request: 4164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1469] Swap waste for job 90: 0.017203776041666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1479] Accumulated tokens for job 90: 858870
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1481] Discard waste for job 90: 597.8166923841435
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1484] Preserve waste for job 90: 0.95201575756073
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:328] Request job id finishing: 171, time is 1761207062.4870176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1462] Request GPU size bytes: 354811904
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1463] Token size of the request: 2686
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1469] Swap waste for job 171: 0.011014811197916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1479] Accumulated tokens for job 171: 858870
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1481] Discard waste for job 171: 597.8166923841435
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [scheduler.py:1484] Preserve waste for job 171: 3.0650779472457037
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:307] Request job id arriving: 98, time is 1761207062.4874043
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:315] Request job id: 98
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:307] Request job id arriving: 160, time is 1761207062.4875414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:315] Request job id: 160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:307] Request job id arriving: 23, time is 1761207062.4876263
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:02 [estimate_with_func.py:315] Request job id: 23
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:02,490] LMCache INFO:[0m Reqid: chatcmpl-c445c83a559a400c8ef0daaf18d17dd4, Total tokens 29975, LMCache hit tokens: 4864, need to load: 4848 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:02,508] LMCache INFO:[0m Retrieved 4864 out of 4864 required tokens (from 4864 total tokens). size: 0.5938 gb, cost 12.9207 ms, throughput: 45.9535 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '110', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:03,080] LMCache INFO:[0m Storing KV cache for 4096 out of 8960 tokens (skip_leading_tokens=4864) for request chatcmpl-c445c83a559a400c8ef0daaf18d17dd4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:03,091] LMCache INFO:[0m Stored 4096 out of total 4096 tokens. size: 0.5000 gb, cost 10.7560 ms, throughput: 46.4858 GB/s; offload_time: 10.7179 ms, put_time: 0.0381 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:03,091] LMCache INFO:[0m Storing KV cache for 4039 out of 47815 tokens (skip_leading_tokens=43776) for request chatcmpl-a4a31075fdad47dcb4e0b3db7b9af732 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:03,116] LMCache INFO:[0m Stored 4039 out of total 4039 tokens. size: 0.4930 gb, cost 24.4661 ms, throughput: 20.1520 GB/s; offload_time: 24.4357 ms, put_time: 0.0305 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [estimate_with_func.py:328] Request job id finishing: 151, time is 1761207063.1192508
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1462] Request GPU size bytes: 1422262272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1463] Token size of the request: 10834
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1469] Swap waste for job 151: 0.04415283203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1479] Accumulated tokens for job 151: 881995
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1481] Discard waste for job 151: 630.0667846568457
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1484] Preserve waste for job 151: 3.0713510539505506
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [estimate_with_func.py:307] Request job id arriving: 110, time is 1761207063.1201625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [estimate_with_func.py:315] Request job id: 110
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '90', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:03,546] LMCache INFO:[0m Storing KV cache for 8192 out of 17152 tokens (skip_leading_tokens=8960) for request chatcmpl-c445c83a559a400c8ef0daaf18d17dd4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:03,568] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.1715 ms, throughput: 47.2333 GB/s; offload_time: 21.1248 ms, put_time: 0.0467 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [estimate_with_func.py:328] Request job id finishing: 94, time is 1761207063.570698
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1462] Request GPU size bytes: 480903168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1463] Token size of the request: 3602
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1469] Swap waste for job 94: 0.01492919921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1479] Accumulated tokens for job 94: 871161
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1481] Discard waste for job 94: 614.8522423572068
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [scheduler.py:1484] Preserve waste for job 94: 3.0661550219593154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [estimate_with_func.py:307] Request job id arriving: 90, time is 1761207063.5711772
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:03 [estimate_with_func.py:315] Request job id: 90
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,100] LMCache INFO:[0m Storing KV cache for 8192 out of 25344 tokens (skip_leading_tokens=17152) for request chatcmpl-c445c83a559a400c8ef0daaf18d17dd4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,121] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3479 ms, throughput: 46.8429 GB/s; offload_time: 21.2995 ms, put_time: 0.0485 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:04 [estimate_with_func.py:328] Request job id finishing: 6, time is 1761207064.1243966
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:04 [scheduler.py:1462] Request GPU size bytes: 1044905984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:04 [scheduler.py:1463] Token size of the request: 7849
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:04 [scheduler.py:1469] Swap waste for job 6: 0.03243815104166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:04 [scheduler.py:1479] Accumulated tokens for job 6: 867559
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:04 [scheduler.py:1481] Discard waste for job 6: 609.8350173583493
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:04 [scheduler.py:1484] Preserve waste for job 6: 3.0661550219593154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,128] LMCache INFO:[0m Reqid: chatcmpl-c91c9fe3dd3440849c34369f632bc121, Total tokens 5196, LMCache hit tokens: 1792, need to load: 1776 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,131] LMCache INFO:[0m Reqid: chatcmpl-6cf469945f6b4da9b51628421ab878ab, Total tokens 30062, LMCache hit tokens: 20480, need to load: 20464 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,141] LMCache INFO:[0m Retrieved 1792 out of 1792 required tokens (from 1792 total tokens). size: 0.2188 gb, cost 4.8733 ms, throughput: 44.8872 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,195] LMCache INFO:[0m Retrieved 20480 out of 20480 required tokens (from 20480 total tokens). size: 2.5000 gb, cost 53.8221 ms, throughput: 46.4494 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,668] LMCache INFO:[0m Storing KV cache for 3404 out of 5196 tokens (skip_leading_tokens=1792) for request chatcmpl-c91c9fe3dd3440849c34369f632bc121 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,678] LMCache INFO:[0m Stored 3404 out of total 3404 tokens. size: 0.4155 gb, cost 9.0793 ms, throughput: 45.7664 GB/s; offload_time: 9.0467 ms, put_time: 0.0326 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,678] LMCache INFO:[0m Storing KV cache for 4631 out of 29975 tokens (skip_leading_tokens=25344) for request chatcmpl-c445c83a559a400c8ef0daaf18d17dd4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:04,690] LMCache INFO:[0m Stored 4631 out of total 4631 tokens. size: 0.5653 gb, cost 12.3691 ms, throughput: 45.7032 GB/s; offload_time: 12.3429 ms, put_time: 0.0262 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:05,268] LMCache INFO:[0m Storing KV cache for 8192 out of 28672 tokens (skip_leading_tokens=20480) for request chatcmpl-6cf469945f6b4da9b51628421ab878ab [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:05,289] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.4033 ms, throughput: 46.7218 GB/s; offload_time: 21.3416 ms, put_time: 0.0617 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:05 [estimate_with_func.py:328] Request job id finishing: 162, time is 1761207065.292647
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:05 [scheduler.py:1462] Request GPU size bytes: 645267456
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:05 [scheduler.py:1463] Token size of the request: 4881
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:05 [scheduler.py:1469] Swap waste for job 162: 0.02003173828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:05 [scheduler.py:1479] Accumulated tokens for job 162: 894968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:05 [scheduler.py:1481] Discard waste for job 162: 648.5297980203964
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:05 [scheduler.py:1484] Preserve waste for job 162: 3.0661550219593154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:05,297] LMCache INFO:[0m Reqid: chatcmpl-ef71ac18a367400d8de3b829d23bd51b, Total tokens 50255, LMCache hit tokens: 33024, need to load: 33008 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:05,393] LMCache INFO:[0m Retrieved 33024 out of 33024 required tokens (from 33024 total tokens). size: 4.0312 gb, cost 86.4570 ms, throughput: 46.6272 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '94', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '151', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,090] LMCache INFO:[0m Storing KV cache for 6656 out of 39680 tokens (skip_leading_tokens=33024) for request chatcmpl-ef71ac18a367400d8de3b829d23bd51b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,109] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 18.1440 ms, throughput: 44.7806 GB/s; offload_time: 18.0864 ms, put_time: 0.0576 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,109] LMCache INFO:[0m Storing KV cache for 1390 out of 30062 tokens (skip_leading_tokens=28672) for request chatcmpl-6cf469945f6b4da9b51628421ab878ab [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,113] LMCache INFO:[0m Stored 1390 out of total 1390 tokens. size: 0.1697 gb, cost 4.0714 ms, throughput: 41.6759 GB/s; offload_time: 4.0555 ms, put_time: 0.0158 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:328] Request job id finishing: 148, time is 1761207066.1164484
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [scheduler.py:1462] Request GPU size bytes: 560988160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [scheduler.py:1463] Token size of the request: 4258
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [scheduler.py:1469] Swap waste for job 148: 0.017415364583333332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [scheduler.py:1479] Accumulated tokens for job 148: 940342
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [scheduler.py:1481] Discard waste for job 148: 715.2022438042906
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [scheduler.py:1484] Preserve waste for job 148: 3.0661550219593154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:307] Request job id arriving: 94, time is 1761207066.1172185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:315] Request job id: 94
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:307] Request job id arriving: 151, time is 1761207066.117374
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:315] Request job id: 151
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '146', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:39144 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '171', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51398 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,935] LMCache INFO:[0m Storing KV cache for 8192 out of 47872 tokens (skip_leading_tokens=39680) for request chatcmpl-ef71ac18a367400d8de3b829d23bd51b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,960] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.4463 ms, throughput: 40.9059 GB/s; offload_time: 24.3608 ms, put_time: 0.0856 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:307] Request job id arriving: 146, time is 1761207066.9642463
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:315] Request job id: 146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:307] Request job id arriving: 171, time is 1761207066.964598
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:06 [estimate_with_func.py:315] Request job id: 171
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,967] LMCache INFO:[0m Reqid: chatcmpl-c9e995e1d4e8486bb3ca8a5c9425b71b, Total tokens 8869, LMCache hit tokens: 4608, need to load: 4592 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,970] LMCache INFO:[0m Reqid: chatcmpl-e2c76b2525c741d7bee19471316fc400, Total tokens 24015, LMCache hit tokens: 17152, need to load: 17136 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:06,987] LMCache INFO:[0m Retrieved 4608 out of 4608 required tokens (from 4608 total tokens). size: 0.5625 gb, cost 12.2474 ms, throughput: 45.9280 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,032] LMCache INFO:[0m Retrieved 17152 out of 17152 required tokens (from 17152 total tokens). size: 2.0938 gb, cost 44.7934 ms, throughput: 46.7424 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '6', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59222 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '162', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,560] LMCache INFO:[0m Storing KV cache for 4261 out of 8869 tokens (skip_leading_tokens=4608) for request chatcmpl-c9e995e1d4e8486bb3ca8a5c9425b71b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,572] LMCache INFO:[0m Stored 4261 out of total 4261 tokens. size: 0.5201 gb, cost 11.6391 ms, throughput: 44.6890 GB/s; offload_time: 11.5761 ms, put_time: 0.0631 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,572] LMCache INFO:[0m Storing KV cache for 1536 out of 18688 tokens (skip_leading_tokens=17152) for request chatcmpl-e2c76b2525c741d7bee19471316fc400 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,577] LMCache INFO:[0m Stored 1536 out of total 1536 tokens. size: 0.1875 gb, cost 4.4515 ms, throughput: 42.1205 GB/s; offload_time: 4.4221 ms, put_time: 0.0295 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,578] LMCache INFO:[0m Storing KV cache for 2383 out of 50255 tokens (skip_leading_tokens=47872) for request chatcmpl-ef71ac18a367400d8de3b829d23bd51b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,586] LMCache INFO:[0m Stored 2383 out of total 2383 tokens. size: 0.2909 gb, cost 7.8137 ms, throughput: 37.2285 GB/s; offload_time: 7.7912 ms, put_time: 0.0226 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207067.589181
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [scheduler.py:1462] Request GPU size bytes: 835059712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [scheduler.py:1463] Token size of the request: 6326
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [scheduler.py:1469] Swap waste for job 133: 0.025923665364583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [scheduler.py:1479] Accumulated tokens for job 133: 968968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [scheduler.py:1481] Discard waste for job 133: 758.9428991200571
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [scheduler.py:1484] Preserve waste for job 133: 0.9517976793192201
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [estimate_with_func.py:307] Request job id arriving: 6, time is 1761207067.5903254
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [estimate_with_func.py:315] Request job id: 6
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [estimate_with_func.py:307] Request job id arriving: 162, time is 1761207067.590488
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:07 [estimate_with_func.py:315] Request job id: 162
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,594] LMCache INFO:[0m Reqid: chatcmpl-1c8657f7573e4cc88abca2eddfb2178d, Total tokens 27366, LMCache hit tokens: 8192, need to load: 8176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:07,623] LMCache INFO:[0m Retrieved 8192 out of 8192 required tokens (from 8192 total tokens). size: 1.0000 gb, cost 21.4770 ms, throughput: 46.5615 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:08,104] LMCache INFO:[0m Storing KV cache for 2816 out of 11008 tokens (skip_leading_tokens=8192) for request chatcmpl-1c8657f7573e4cc88abca2eddfb2178d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:08,112] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 7.5854 ms, throughput: 45.3172 GB/s; offload_time: 7.5580 ms, put_time: 0.0274 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:08,112] LMCache INFO:[0m Storing KV cache for 5327 out of 24015 tokens (skip_leading_tokens=18688) for request chatcmpl-e2c76b2525c741d7bee19471316fc400 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:08,126] LMCache INFO:[0m Stored 5327 out of total 5327 tokens. size: 0.6503 gb, cost 13.9620 ms, throughput: 46.5742 GB/s; offload_time: 13.9332 ms, put_time: 0.0288 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207068.1296775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [estimate_with_func.py:315] Request job id: 133
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '148', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:08,598] LMCache INFO:[0m Storing KV cache for 8192 out of 19200 tokens (skip_leading_tokens=11008) for request chatcmpl-1c8657f7573e4cc88abca2eddfb2178d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:08,620] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.5575 ms, throughput: 46.3876 GB/s; offload_time: 21.4952 ms, put_time: 0.0622 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [estimate_with_func.py:328] Request job id finishing: 159, time is 1761207068.6229901
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1462] Request GPU size bytes: 236978176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1463] Token size of the request: 1740
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1469] Swap waste for job 159: 0.007356770833333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1479] Accumulated tokens for job 159: 990008
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1481] Discard waste for job 159: 791.9197150394551
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1484] Preserve waste for job 159: 3.0868327958243236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [estimate_with_func.py:328] Request job id finishing: 87, time is 1761207068.6233416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1462] Request GPU size bytes: 2237399040
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1463] Token size of the request: 17047
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1469] Swap waste for job 87: 0.0694580078125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1479] Accumulated tokens for job 87: 990008
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1481] Discard waste for job 87: 791.9197150394551
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [scheduler.py:1484] Preserve waste for job 87: 0.9483416401037649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [estimate_with_func.py:307] Request job id arriving: 148, time is 1761207068.6238666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:08 [estimate_with_func.py:315] Request job id: 148
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '87', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58718 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,196] LMCache INFO:[0m Storing KV cache for 7936 out of 27136 tokens (skip_leading_tokens=19200) for request chatcmpl-1c8657f7573e4cc88abca2eddfb2178d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,218] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.9795 ms, throughput: 46.1759 GB/s; offload_time: 20.9214 ms, put_time: 0.0582 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [estimate_with_func.py:328] Request job id finishing: 121, time is 1761207069.2210734
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1462] Request GPU size bytes: 772407296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1463] Token size of the request: 5775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1469] Swap waste for job 121: 0.023978678385416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1479] Accumulated tokens for job 121: 971221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1481] Discard waste for job 121: 762.4405918224802
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1484] Preserve waste for job 121: 0.9483416401037649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207069.2215831
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1462] Request GPU size bytes: 330694656
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1463] Token size of the request: 2457
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1469] Swap waste for job 122: 0.01026611328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1479] Accumulated tokens for job 122: 971221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1481] Discard waste for job 122: 762.4405918224802
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1484] Preserve waste for job 122: 0.9483416401037649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [estimate_with_func.py:328] Request job id finishing: 126, time is 1761207069.2219048
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1462] Request GPU size bytes: 349175808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1463] Token size of the request: 2648
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1469] Swap waste for job 126: 0.01083984375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1479] Accumulated tokens for job 126: 971221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1481] Discard waste for job 126: 762.4405918224802
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [scheduler.py:1484] Preserve waste for job 126: 3.0837831421902306
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [estimate_with_func.py:307] Request job id arriving: 87, time is 1761207069.222281
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [estimate_with_func.py:315] Request job id: 87
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,225] LMCache INFO:[0m Reqid: chatcmpl-1b95f80001ab47bfb21f74d7ccd0a69a, Total tokens 10587, LMCache hit tokens: 5632, need to load: 5616 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,227] LMCache INFO:[0m Reqid: chatcmpl-a79e48760c274ea68ecc4793766502d2, Total tokens 4252, LMCache hit tokens: 2560, need to load: 2544 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,229] LMCache INFO:[0m Reqid: chatcmpl-acc83d0d32a34310b3bba3b5253a2547, Total tokens 24040, LMCache hit tokens: 13056, need to load: 13040 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,249] LMCache INFO:[0m Retrieved 5632 out of 5632 required tokens (from 5632 total tokens). size: 0.6875 gb, cost 14.8623 ms, throughput: 46.2579 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,256] LMCache INFO:[0m Retrieved 2560 out of 2560 required tokens (from 2560 total tokens). size: 0.3125 gb, cost 6.7862 ms, throughput: 46.0494 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,290] LMCache INFO:[0m Retrieved 13056 out of 13056 required tokens (from 13056 total tokens). size: 1.5938 gb, cost 34.0366 ms, throughput: 46.8246 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,659] LMCache INFO:[0m Storing KV cache for 4955 out of 10587 tokens (skip_leading_tokens=5632) for request chatcmpl-1b95f80001ab47bfb21f74d7ccd0a69a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,673] LMCache INFO:[0m Stored 4955 out of total 4955 tokens. size: 0.6049 gb, cost 13.1697 ms, throughput: 45.9280 GB/s; offload_time: 13.1179 ms, put_time: 0.0518 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,673] LMCache INFO:[0m Storing KV cache for 1692 out of 4252 tokens (skip_leading_tokens=2560) for request chatcmpl-a79e48760c274ea68ecc4793766502d2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,678] LMCache INFO:[0m Stored 1692 out of total 1692 tokens. size: 0.2065 gb, cost 4.5080 ms, throughput: 45.8170 GB/s; offload_time: 4.4926 ms, put_time: 0.0154 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,678] LMCache INFO:[0m Storing KV cache for 1280 out of 14336 tokens (skip_leading_tokens=13056) for request chatcmpl-acc83d0d32a34310b3bba3b5253a2547 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:09,681] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.4890 ms, throughput: 44.7833 GB/s; offload_time: 3.4766 ms, put_time: 0.0124 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207069.685409
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:09 [estimate_with_func.py:315] Request job id: 122
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '121', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,203] LMCache INFO:[0m Storing KV cache for 8192 out of 22528 tokens (skip_leading_tokens=14336) for request chatcmpl-acc83d0d32a34310b3bba3b5253a2547 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,224] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3180 ms, throughput: 46.9087 GB/s; offload_time: 21.2568 ms, put_time: 0.0612 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:10 [estimate_with_func.py:307] Request job id arriving: 121, time is 1761207070.2276568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:10 [estimate_with_func.py:315] Request job id: 121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,231] LMCache INFO:[0m Reqid: chatcmpl-ca29f61594344548a079e390d8cd4bbd, Total tokens 16409, LMCache hit tokens: 8704, need to load: 8688 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,257] LMCache INFO:[0m Retrieved 8704 out of 8704 required tokens (from 8704 total tokens). size: 1.0625 gb, cost 22.8051 ms, throughput: 46.5904 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:11:10 [loggers.py:123] Engine 000: Avg prompt throughput: 28583.6 tokens/s, Avg generation throughput: 100.0 tokens/s, Running: 62 reqs, Waiting: 31 reqs, GPU KV cache usage: 87.1%, Prefix cache hit rate: 37.7%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,706] LMCache INFO:[0m Storing KV cache for 6656 out of 15360 tokens (skip_leading_tokens=8704) for request chatcmpl-ca29f61594344548a079e390d8cd4bbd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,723] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 17.2624 ms, throughput: 47.0676 GB/s; offload_time: 17.2094 ms, put_time: 0.0530 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,723] LMCache INFO:[0m Storing KV cache for 1512 out of 24040 tokens (skip_leading_tokens=22528) for request chatcmpl-acc83d0d32a34310b3bba3b5253a2547 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,728] LMCache INFO:[0m Stored 1512 out of total 1512 tokens. size: 0.1846 gb, cost 4.3689 ms, throughput: 42.2467 GB/s; offload_time: 4.3529 ms, put_time: 0.0160 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,733] LMCache INFO:[0m Reqid: chatcmpl-7c4e4117cbe64cab9aad2cf7eed340d4, Total tokens 7169, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,736] LMCache INFO:[0m Reqid: chatcmpl-ee5a378367364f4e8217275c5155b812, Total tokens 6514, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,738] LMCache INFO:[0m Reqid: chatcmpl-93f5b49c9f4849eb8d0741affecc6a90, Total tokens 4032, LMCache hit tokens: 2304, need to load: 2288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,751] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.8336 ms, throughput: 46.1528 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,762] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.7595 ms, throughput: 46.4704 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:10,768] LMCache INFO:[0m Retrieved 2304 out of 2304 required tokens (from 2304 total tokens). size: 0.2812 gb, cost 6.0855 ms, throughput: 46.2164 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,123] LMCache INFO:[0m Storing KV cache for 3073 out of 7169 tokens (skip_leading_tokens=4096) for request chatcmpl-7c4e4117cbe64cab9aad2cf7eed340d4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,132] LMCache INFO:[0m Stored 3073 out of total 3073 tokens. size: 0.3751 gb, cost 8.1792 ms, throughput: 45.8630 GB/s; offload_time: 8.1537 ms, put_time: 0.0254 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,132] LMCache INFO:[0m Storing KV cache for 2418 out of 6514 tokens (skip_leading_tokens=4096) for request chatcmpl-ee5a378367364f4e8217275c5155b812 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,138] LMCache INFO:[0m Stored 2418 out of total 2418 tokens. size: 0.2952 gb, cost 6.3344 ms, throughput: 46.5974 GB/s; offload_time: 6.3151 ms, put_time: 0.0193 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,138] LMCache INFO:[0m Storing KV cache for 1536 out of 3840 tokens (skip_leading_tokens=2304) for request chatcmpl-93f5b49c9f4849eb8d0741affecc6a90 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,143] LMCache INFO:[0m Stored 1536 out of total 1536 tokens. size: 0.1875 gb, cost 4.0407 ms, throughput: 46.4030 GB/s; offload_time: 4.0274 ms, put_time: 0.0132 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '159', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58878 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,143] LMCache INFO:[0m Storing KV cache for 1049 out of 16409 tokens (skip_leading_tokens=15360) for request chatcmpl-ca29f61594344548a079e390d8cd4bbd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,146] LMCache INFO:[0m Stored 1049 out of total 1049 tokens. size: 0.1281 gb, cost 3.5162 ms, throughput: 36.4177 GB/s; offload_time: 3.5007 ms, put_time: 0.0155 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:11 [estimate_with_func.py:307] Request job id arriving: 159, time is 1761207071.1495862
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:11 [estimate_with_func.py:315] Request job id: 159
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,152] LMCache INFO:[0m Reqid: chatcmpl-b398d0de406041de9a7dee2aa37c62ed, Total tokens 22037, LMCache hit tokens: 8960, need to load: 8944 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,179] LMCache INFO:[0m Retrieved 8960 out of 8960 required tokens (from 8960 total tokens). size: 1.0938 gb, cost 23.4706 ms, throughput: 46.6009 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,624] LMCache INFO:[0m Storing KV cache for 7936 out of 16896 tokens (skip_leading_tokens=8960) for request chatcmpl-b398d0de406041de9a7dee2aa37c62ed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,646] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.9973 ms, throughput: 46.1370 GB/s; offload_time: 20.4594 ms, put_time: 0.5378 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,651] LMCache INFO:[0m Reqid: chatcmpl-bc75b8b0a40249519b1bbabdf0c28c66, Total tokens 5655, LMCache hit tokens: 3072, need to load: 3056 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,653] LMCache INFO:[0m Reqid: chatcmpl-b8ce290dcf3947418ea1fda97ea0510c, Total tokens 3003, LMCache hit tokens: 1536, need to load: 1520 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,664] LMCache INFO:[0m Retrieved 3072 out of 3072 required tokens (from 3072 total tokens). size: 0.3750 gb, cost 8.1555 ms, throughput: 45.9815 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:11,668] LMCache INFO:[0m Retrieved 1536 out of 1536 required tokens (from 1536 total tokens). size: 0.1875 gb, cost 4.1054 ms, throughput: 45.6720 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,119] LMCache INFO:[0m Storing KV cache for 2583 out of 5655 tokens (skip_leading_tokens=3072) for request chatcmpl-bc75b8b0a40249519b1bbabdf0c28c66 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,126] LMCache INFO:[0m Stored 2583 out of total 2583 tokens. size: 0.3153 gb, cost 6.9065 ms, throughput: 45.6537 GB/s; offload_time: 6.8819 ms, put_time: 0.0246 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,126] LMCache INFO:[0m Storing KV cache for 512 out of 2048 tokens (skip_leading_tokens=1536) for request chatcmpl-b8ce290dcf3947418ea1fda97ea0510c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,127] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.3888 ms, throughput: 45.0035 GB/s; offload_time: 1.3806 ms, put_time: 0.0082 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,127] LMCache INFO:[0m Storing KV cache for 5141 out of 22037 tokens (skip_leading_tokens=16896) for request chatcmpl-b398d0de406041de9a7dee2aa37c62ed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,141] LMCache INFO:[0m Stored 5141 out of total 5141 tokens. size: 0.6276 gb, cost 13.7660 ms, throughput: 45.5880 GB/s; offload_time: 13.7391 ms, put_time: 0.0269 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,146] LMCache INFO:[0m Reqid: chatcmpl-d9ff99b98aae46ae968f13e2a4e1e50b, Total tokens 2831, LMCache hit tokens: 1536, need to load: 1520 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,148] LMCache INFO:[0m Reqid: chatcmpl-de09ab0cf8c443ca89fd503ff124254a, Total tokens 15969, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,155] LMCache INFO:[0m Retrieved 1536 out of 1536 required tokens (from 1536 total tokens). size: 0.1875 gb, cost 4.1454 ms, throughput: 45.2312 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,169] LMCache INFO:[0m Retrieved 5120 out of 5120 required tokens (from 5120 total tokens). size: 0.6250 gb, cost 13.4144 ms, throughput: 46.5917 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '126', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58786 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,533] LMCache INFO:[0m Storing KV cache for 1295 out of 2831 tokens (skip_leading_tokens=1536) for request chatcmpl-d9ff99b98aae46ae968f13e2a4e1e50b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,536] LMCache INFO:[0m Stored 1295 out of total 1295 tokens. size: 0.1581 gb, cost 3.5725 ms, throughput: 44.2490 GB/s; offload_time: 3.5528 ms, put_time: 0.0197 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,537] LMCache INFO:[0m Storing KV cache for 5888 out of 11008 tokens (skip_leading_tokens=5120) for request chatcmpl-de09ab0cf8c443ca89fd503ff124254a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,552] LMCache INFO:[0m Stored 5888 out of total 5888 tokens. size: 0.7188 gb, cost 15.1434 ms, throughput: 47.4630 GB/s; offload_time: 15.1132 ms, put_time: 0.0302 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,552] LMCache INFO:[0m Storing KV cache for 955 out of 3003 tokens (skip_leading_tokens=2048) for request chatcmpl-b8ce290dcf3947418ea1fda97ea0510c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,555] LMCache INFO:[0m Stored 955 out of total 955 tokens. size: 0.1166 gb, cost 2.5900 ms, throughput: 45.0097 GB/s; offload_time: 2.5784 ms, put_time: 0.0117 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:12 [estimate_with_func.py:307] Request job id arriving: 126, time is 1761207072.55826
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:12 [estimate_with_func.py:315] Request job id: 126
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,562] LMCache INFO:[0m Reqid: chatcmpl-b5effb999dfa45968bd5d94ea60f1794, Total tokens 45376, LMCache hit tokens: 30976, need to load: 30960 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:12,656] LMCache INFO:[0m Retrieved 30976 out of 30976 required tokens (from 30976 total tokens). size: 3.7812 gb, cost 81.3925 ms, throughput: 46.4570 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:13,202] LMCache INFO:[0m Storing KV cache for 3072 out of 34048 tokens (skip_leading_tokens=30976) for request chatcmpl-b5effb999dfa45968bd5d94ea60f1794 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:13,212] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 8.8905 ms, throughput: 42.1796 GB/s; offload_time: 8.8580 ms, put_time: 0.0325 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:13,212] LMCache INFO:[0m Storing KV cache for 4961 out of 15969 tokens (skip_leading_tokens=11008) for request chatcmpl-de09ab0cf8c443ca89fd503ff124254a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:13,225] LMCache INFO:[0m Stored 4961 out of total 4961 tokens. size: 0.6056 gb, cost 12.9216 ms, throughput: 46.8664 GB/s; offload_time: 12.8929 ms, put_time: 0.0287 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [estimate_with_func.py:328] Request job id finishing: 66, time is 1761207073.228273
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1462] Request GPU size bytes: 506855424
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1463] Token size of the request: 3824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1469] Swap waste for job 66: 0.01573486328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1479] Accumulated tokens for job 66: 1128215
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1481] Discard waste for job 66: 1025.9677892432808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1484] Preserve waste for job 66: 0.9419848430352132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207073.2286339
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1462] Request GPU size bytes: 3942121472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1463] Token size of the request: 30062
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1469] Swap waste for job 79: 0.12237955729166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1479] Accumulated tokens for job 79: 1128215
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1481] Discard waste for job 79: 1025.9677892432808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:13 [scheduler.py:1484] Preserve waste for job 79: 0.9419848430352132
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '66', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,003] LMCache INFO:[0m Storing KV cache for 8192 out of 42240 tokens (skip_leading_tokens=34048) for request chatcmpl-b5effb999dfa45968bd5d94ea60f1794 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,026] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.9888 ms, throughput: 45.4777 GB/s; offload_time: 21.9510 ms, put_time: 0.0378 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:328] Request job id finishing: 93, time is 1761207074.0287712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1462] Request GPU size bytes: 1101398016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1463] Token size of the request: 8262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1469] Swap waste for job 93: 0.03419189453125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1479] Accumulated tokens for job 93: 1094329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1481] Discard waste for job 93: 965.7835090507403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1484] Preserve waste for job 93: 0.9419848430352132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:328] Request job id finishing: 78, time is 1761207074.029343
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1462] Request GPU size bytes: 6269829120
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1463] Token size of the request: 47815
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1469] Swap waste for job 78: 0.19464111328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1479] Accumulated tokens for job 78: 1094329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1481] Discard waste for job 78: 965.7835090507403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1484] Preserve waste for job 78: 0.9419848430352132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:328] Request job id finishing: 111, time is 1761207074.0299115
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1462] Request GPU size bytes: 3931111424
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1463] Token size of the request: 29975
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1469] Swap waste for job 111: 0.12203776041666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1479] Accumulated tokens for job 111: 1094329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1481] Discard waste for job 111: 965.7835090507403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1484] Preserve waste for job 111: 0.9419848430352132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207074.0304804
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:315] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:307] Request job id arriving: 66, time is 1761207074.0306222
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:315] Request job id: 66
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,034] LMCache INFO:[0m Reqid: chatcmpl-2ff1b29341bb4ac2809a24b77d1d7cb6, Total tokens 10084, LMCache hit tokens: 5888, need to load: 5872 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,036] LMCache INFO:[0m Reqid: chatcmpl-f89deb0a9c27416fba1a716a788edaa7, Total tokens 28278, LMCache hit tokens: 15104, need to load: 15088 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,058] LMCache INFO:[0m Retrieved 5888 out of 5888 required tokens (from 5888 total tokens). size: 0.7188 gb, cost 15.6597 ms, throughput: 45.8981 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,098] LMCache INFO:[0m Retrieved 15104 out of 15104 required tokens (from 15104 total tokens). size: 1.8438 gb, cost 39.3852 ms, throughput: 46.8133 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,654] LMCache INFO:[0m Storing KV cache for 4196 out of 10084 tokens (skip_leading_tokens=5888) for request chatcmpl-2ff1b29341bb4ac2809a24b77d1d7cb6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,665] LMCache INFO:[0m Stored 4196 out of total 4196 tokens. size: 0.5122 gb, cost 11.1650 ms, throughput: 45.8762 GB/s; offload_time: 11.1207 ms, put_time: 0.0442 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,665] LMCache INFO:[0m Storing KV cache for 768 out of 15872 tokens (skip_leading_tokens=15104) for request chatcmpl-f89deb0a9c27416fba1a716a788edaa7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,668] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.2041 ms, throughput: 42.5343 GB/s; offload_time: 2.1922 ms, put_time: 0.0119 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,668] LMCache INFO:[0m Storing KV cache for 3136 out of 45376 tokens (skip_leading_tokens=42240) for request chatcmpl-b5effb999dfa45968bd5d94ea60f1794 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:14,678] LMCache INFO:[0m Stored 3136 out of total 3136 tokens. size: 0.3828 gb, cost 9.4193 ms, throughput: 40.6414 GB/s; offload_time: 9.3996 ms, put_time: 0.0197 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:328] Request job id finishing: 157, time is 1761207074.6809325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1462] Request GPU size bytes: 1311244288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1463] Token size of the request: 9905
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1469] Swap waste for job 157: 0.04070638020833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1479] Accumulated tokens for job 157: 1046639
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1481] Discard waste for job 157: 884.1633121217884
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1484] Preserve waste for job 157: 0.9397286868864491
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207074.6815517
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1462] Request GPU size bytes: 683409408
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1463] Token size of the request: 5196
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1469] Swap waste for job 68: 0.0212158203125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1479] Accumulated tokens for job 68: 1046639
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1481] Discard waste for job 68: 884.1633121217884
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:14 [scheduler.py:1484] Preserve waste for job 68: 3.0821994493405023
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '78', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,218] LMCache INFO:[0m Storing KV cache for 7936 out of 23808 tokens (skip_leading_tokens=15872) for request chatcmpl-f89deb0a9c27416fba1a716a788edaa7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,239] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.5902 ms, throughput: 47.0490 GB/s; offload_time: 20.5493 ms, put_time: 0.0409 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:15 [estimate_with_func.py:307] Request job id arriving: 78, time is 1761207075.2424247
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:15 [estimate_with_func.py:315] Request job id: 78
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,245] LMCache INFO:[0m Reqid: chatcmpl-cf5a2031c63b4f8c97097490847e11f1, Total tokens 4407, LMCache hit tokens: 2560, need to load: 2544 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,248] LMCache INFO:[0m Reqid: chatcmpl-6d9823e122054620b29134d258a42c53, Total tokens 45172, LMCache hit tokens: 30720, need to load: 30704 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,263] LMCache INFO:[0m Retrieved 2560 out of 2560 required tokens (from 2560 total tokens). size: 0.3125 gb, cost 6.9348 ms, throughput: 45.0625 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '157', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '111', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,344] LMCache INFO:[0m Retrieved 30720 out of 30720 required tokens (from 30720 total tokens). size: 3.7500 gb, cost 79.9471 ms, throughput: 46.9060 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,900] LMCache INFO:[0m Storing KV cache for 1847 out of 4407 tokens (skip_leading_tokens=2560) for request chatcmpl-cf5a2031c63b4f8c97097490847e11f1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,905] LMCache INFO:[0m Stored 1847 out of total 1847 tokens. size: 0.2255 gb, cost 5.0208 ms, throughput: 44.9059 GB/s; offload_time: 5.0003 ms, put_time: 0.0205 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,906] LMCache INFO:[0m Storing KV cache for 2048 out of 32768 tokens (skip_leading_tokens=30720) for request chatcmpl-6d9823e122054620b29134d258a42c53 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,911] LMCache INFO:[0m Stored 2048 out of total 2048 tokens. size: 0.2500 gb, cost 5.6562 ms, throughput: 44.1990 GB/s; offload_time: 5.6418 ms, put_time: 0.0145 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,912] LMCache INFO:[0m Storing KV cache for 4470 out of 28278 tokens (skip_leading_tokens=23808) for request chatcmpl-f89deb0a9c27416fba1a716a788edaa7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:15,924] LMCache INFO:[0m Stored 4470 out of total 4470 tokens. size: 0.5457 gb, cost 11.7926 ms, throughput: 46.2709 GB/s; offload_time: 11.7680 ms, put_time: 0.0246 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:15 [estimate_with_func.py:307] Request job id arriving: 157, time is 1761207075.9270513
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:15 [estimate_with_func.py:315] Request job id: 157
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:15 [estimate_with_func.py:307] Request job id arriving: 111, time is 1761207075.92721
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:15 [estimate_with_func.py:315] Request job id: 111
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:16,673] LMCache INFO:[0m Storing KV cache for 7936 out of 40704 tokens (skip_leading_tokens=32768) for request chatcmpl-6d9823e122054620b29134d258a42c53 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:16,695] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3370 ms, throughput: 45.4024 GB/s; offload_time: 21.2855 ms, put_time: 0.0515 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [estimate_with_func.py:328] Request job id finishing: 109, time is 1761207076.698899
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [scheduler.py:1462] Request GPU size bytes: 559022080
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [scheduler.py:1463] Token size of the request: 4252
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [scheduler.py:1469] Swap waste for job 109: 0.017354329427083332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [scheduler.py:1479] Accumulated tokens for job 109: 1081117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [scheduler.py:1481] Discard waste for job 109: 942.8107465323624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [scheduler.py:1484] Preserve waste for job 109: 0.95183442521283
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207076.6994097
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:16 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:16,703] LMCache INFO:[0m Reqid: chatcmpl-f19e83bb63844139a109df9ef78e931d, Total tokens 8440, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:16,707] LMCache INFO:[0m Reqid: chatcmpl-5263736a35d24c87a07e2fe2803f84fe, Total tokens 44649, LMCache hit tokens: 32000, need to load: 31984 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:16,728] LMCache INFO:[0m Retrieved 5120 out of 5120 required tokens (from 5120 total tokens). size: 0.6250 gb, cost 13.6484 ms, throughput: 45.7929 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:16,817] LMCache INFO:[0m Retrieved 32000 out of 32000 required tokens (from 32000 total tokens). size: 3.9062 gb, cost 88.9776 ms, throughput: 43.9015 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '109', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:17,441] LMCache INFO:[0m Storing KV cache for 3320 out of 8440 tokens (skip_leading_tokens=5120) for request chatcmpl-f19e83bb63844139a109df9ef78e931d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:17,450] LMCache INFO:[0m Stored 3320 out of total 3320 tokens. size: 0.4053 gb, cost 8.8728 ms, throughput: 45.6757 GB/s; offload_time: 8.8366 ms, put_time: 0.0363 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:17,450] LMCache INFO:[0m Storing KV cache for 512 out of 32512 tokens (skip_leading_tokens=32000) for request chatcmpl-5263736a35d24c87a07e2fe2803f84fe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:17,452] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.7209 ms, throughput: 36.3177 GB/s; offload_time: 1.7089 ms, put_time: 0.0120 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:17,453] LMCache INFO:[0m Storing KV cache for 4468 out of 45172 tokens (skip_leading_tokens=40704) for request chatcmpl-6d9823e122054620b29134d258a42c53 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:17,466] LMCache INFO:[0m Stored 4468 out of total 4468 tokens. size: 0.5454 gb, cost 12.6439 ms, throughput: 43.1361 GB/s; offload_time: 12.6087 ms, put_time: 0.0353 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:17 [estimate_with_func.py:307] Request job id arriving: 109, time is 1761207077.4701037
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:17 [estimate_with_func.py:315] Request job id: 109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:18,221] LMCache INFO:[0m Storing KV cache for 7936 out of 40448 tokens (skip_leading_tokens=32512) for request chatcmpl-5263736a35d24c87a07e2fe2803f84fe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:18,243] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.4855 ms, throughput: 45.0885 GB/s; offload_time: 21.4441 ms, put_time: 0.0414 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207078.2463238
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1462] Request GPU size bytes: 2750676992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1463] Token size of the request: 20915
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1469] Swap waste for job 16: 0.08539225260416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1479] Accumulated tokens for job 16: 1129954
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1481] Discard waste for job 16: 1029.1054590099877
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1484] Preserve waste for job 16: 3.076684978959474
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [estimate_with_func.py:328] Request job id finishing: 128, time is 1761207078.2467897
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1462] Request GPU size bytes: 1618083840
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1463] Token size of the request: 12275
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1469] Swap waste for job 128: 0.05023193359375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1479] Accumulated tokens for job 128: 1129954
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1481] Discard waste for job 128: 1029.1054590099877
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1484] Preserve waste for job 128: 3.076684978959474
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [estimate_with_func.py:328] Request job id finishing: 127, time is 1761207078.2470963
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1462] Request GPU size bytes: 1164967936
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1463] Token size of the request: 8869
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1469] Swap waste for job 127: 0.03616536458333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1479] Accumulated tokens for job 127: 1129954
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1481] Discard waste for job 127: 1029.1054590099877
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:18 [scheduler.py:1484] Preserve waste for job 127: 3.076684978959474
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:18,251] LMCache INFO:[0m Reqid: chatcmpl-4e0c09f310b043f98df374a0617ce750, Total tokens 33160, LMCache hit tokens: 18944, need to load: 18928 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:18,307] LMCache INFO:[0m Retrieved 18944 out of 18944 required tokens (from 18944 total tokens). size: 2.3125 gb, cost 49.8339 ms, throughput: 46.4041 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '93', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58840 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:18,991] LMCache INFO:[0m Storing KV cache for 4096 out of 23040 tokens (skip_leading_tokens=18944) for request chatcmpl-4e0c09f310b043f98df374a0617ce750 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,002] LMCache INFO:[0m Stored 4096 out of total 4096 tokens. size: 0.5000 gb, cost 10.9059 ms, throughput: 45.8466 GB/s; offload_time: 10.8616 ms, put_time: 0.0443 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,003] LMCache INFO:[0m Storing KV cache for 4201 out of 44649 tokens (skip_leading_tokens=40448) for request chatcmpl-5263736a35d24c87a07e2fe2803f84fe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,016] LMCache INFO:[0m Stored 4201 out of total 4201 tokens. size: 0.5128 gb, cost 12.1529 ms, throughput: 42.1973 GB/s; offload_time: 12.1265 ms, put_time: 0.0264 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:19 [estimate_with_func.py:307] Request job id arriving: 93, time is 1761207079.0197752
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:19 [estimate_with_func.py:315] Request job id: 93
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,660] LMCache INFO:[0m Storing KV cache for 7936 out of 30976 tokens (skip_leading_tokens=23040) for request chatcmpl-4e0c09f310b043f98df374a0617ce750 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,682] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.8610 ms, throughput: 44.3140 GB/s; offload_time: 21.8003 ms, put_time: 0.0607 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,688] LMCache INFO:[0m Reqid: chatcmpl-9cc1f3000fca4afea5c04b72e1fc6744, Total tokens 6357, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,691] LMCache INFO:[0m Reqid: chatcmpl-eda19e4c66584c73ab3f3d6a5e6885b0, Total tokens 36875, LMCache hit tokens: 16128, need to load: 16112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:19,705] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.9958 ms, throughput: 45.4721 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,052] LMCache INFO:[0m Storing KV cache for 2261 out of 6357 tokens (skip_leading_tokens=4096) for request chatcmpl-9cc1f3000fca4afea5c04b72e1fc6744 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,058] LMCache INFO:[0m Stored 2261 out of total 2261 tokens. size: 0.2760 gb, cost 6.2041 ms, throughput: 44.4871 GB/s; offload_time: 6.1768 ms, put_time: 0.0272 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,059] LMCache INFO:[0m Storing KV cache for 2184 out of 33160 tokens (skip_leading_tokens=30976) for request chatcmpl-4e0c09f310b043f98df374a0617ce750 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,066] LMCache INFO:[0m Stored 2184 out of total 2184 tokens. size: 0.2666 gb, cost 6.9183 ms, throughput: 38.5355 GB/s; offload_time: 6.8933 ms, put_time: 0.0250 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:328] Request job id finishing: 83, time is 1761207080.0696783
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1462] Request GPU size bytes: 941621248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1463] Token size of the request: 7169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1469] Swap waste for job 83: 0.029231770833333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1479] Accumulated tokens for job 83: 1127412
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1481] Discard waste for job 83: 1024.5205566263166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1484] Preserve waste for job 83: 0.9817496584367382
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,073] LMCache INFO:[0m Reqid: chatcmpl-eda19e4c66584c73ab3f3d6a5e6885b0, Total tokens 36875, LMCache hit tokens: 16128, need to load: 16112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,121] LMCache INFO:[0m Retrieved 16128 out of 16128 required tokens (from 16128 total tokens). size: 1.9688 gb, cost 42.1553 ms, throughput: 46.7023 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '128', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '83', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:11:20 [loggers.py:123] Engine 000: Avg prompt throughput: 33359.3 tokens/s, Avg generation throughput: 108.2 tokens/s, Running: 68 reqs, Waiting: 24 reqs, GPU KV cache usage: 97.8%, Prefix cache hit rate: 32.8%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,666] LMCache INFO:[0m Storing KV cache for 7936 out of 24064 tokens (skip_leading_tokens=16128) for request chatcmpl-eda19e4c66584c73ab3f3d6a5e6885b0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,687] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 20.6585 ms, throughput: 46.8935 GB/s; offload_time: 20.6118 ms, put_time: 0.0467 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:307] Request job id arriving: 128, time is 1761207080.690483
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:315] Request job id: 128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:307] Request job id arriving: 83, time is 1761207080.6906714
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:315] Request job id: 83
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207080.6907504
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:315] Request job id: 16
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [estimate_with_func.py:328] Request job id finishing: 169, time is 1761207080.7690883
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1462] Request GPU size bytes: 2486435840
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1463] Token size of the request: 18897
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1469] Swap waste for job 169: 0.07718912760416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1479] Accumulated tokens for job 169: 1120243
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1481] Discard waste for job 169: 1011.6452583718286
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:20 [scheduler.py:1484] Preserve waste for job 169: 0.9789742213029128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:20,773] LMCache INFO:[0m Reqid: chatcmpl-eda19e4c66584c73ab3f3d6a5e6885b0, Total tokens 36875, LMCache hit tokens: 24064, need to load: -176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '127', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:43098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '169', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:21,419] LMCache INFO:[0m Storing KV cache for 8192 out of 32256 tokens (skip_leading_tokens=24064) for request chatcmpl-eda19e4c66584c73ab3f3d6a5e6885b0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:21,441] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.4626 ms, throughput: 46.5926 GB/s; offload_time: 21.4066 ms, put_time: 0.0561 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [estimate_with_func.py:328] Request job id finishing: 17, time is 1761207081.444325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1462] Request GPU size bytes: 2860122112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1463] Token size of the request: 21780
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1469] Swap waste for job 17: 0.08878987630208333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1479] Accumulated tokens for job 17: 1138221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1481] Discard waste for job 17: 1044.087082055226
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1484] Preserve waste for job 17: 0.9789742213029128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207081.4449592
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1462] Request GPU size bytes: 2890530816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1463] Token size of the request: 22037
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1469] Swap waste for job 44: 0.08973388671875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1479] Accumulated tokens for job 44: 1138221
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1481] Discard waste for job 44: 1044.087082055226
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [scheduler.py:1484] Preserve waste for job 44: 3.07019670070746
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [estimate_with_func.py:307] Request job id arriving: 127, time is 1761207081.4455738
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [estimate_with_func.py:315] Request job id: 127
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [estimate_with_func.py:307] Request job id arriving: 169, time is 1761207081.4457314
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:21 [estimate_with_func.py:315] Request job id: 169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:21,448] LMCache INFO:[0m Reqid: chatcmpl-0d58eccba0124503ab9fbab7c8732379, Total tokens 4220, LMCache hit tokens: 2560, need to load: 2544 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:21,450] LMCache INFO:[0m Reqid: chatcmpl-91652ee0b66c4b6d9a27cd06e5db77c3, Total tokens 7869, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:21,464] LMCache INFO:[0m Retrieved 2560 out of 2560 required tokens (from 2560 total tokens). size: 0.3125 gb, cost 6.9756 ms, throughput: 44.7991 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:21,475] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.7677 ms, throughput: 46.4353 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '17', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,023] LMCache INFO:[0m Storing KV cache for 1660 out of 4220 tokens (skip_leading_tokens=2560) for request chatcmpl-0d58eccba0124503ab9fbab7c8732379 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,028] LMCache INFO:[0m Stored 1660 out of total 1660 tokens. size: 0.2026 gb, cost 4.5361 ms, throughput: 44.6718 GB/s; offload_time: 4.5134 ms, put_time: 0.0227 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,028] LMCache INFO:[0m Storing KV cache for 1792 out of 5888 tokens (skip_leading_tokens=4096) for request chatcmpl-91652ee0b66c4b6d9a27cd06e5db77c3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,033] LMCache INFO:[0m Stored 1792 out of total 1792 tokens. size: 0.2188 gb, cost 4.6919 ms, throughput: 46.6234 GB/s; offload_time: 4.6768 ms, put_time: 0.0151 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,034] LMCache INFO:[0m Storing KV cache for 4619 out of 36875 tokens (skip_leading_tokens=32256) for request chatcmpl-eda19e4c66584c73ab3f3d6a5e6885b0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,047] LMCache INFO:[0m Stored 4619 out of total 4619 tokens. size: 0.5638 gb, cost 12.9343 ms, throughput: 43.5928 GB/s; offload_time: 12.8959 ms, put_time: 0.0384 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:328] Request job id finishing: 15, time is 1761207082.0501177
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1462] Request GPU size bytes: 1120403456
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1463] Token size of the request: 8503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1469] Swap waste for job 15: 0.03478190104166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1479] Accumulated tokens for job 15: 1106493
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1481] Discard waste for job 15: 987.1784948564147
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1484] Preserve waste for job 15: 3.0708514464144803
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:328] Request job id finishing: 1, time is 1761207082.050519
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1462] Request GPU size bytes: 2153250816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1463] Token size of the request: 16409
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1469] Swap waste for job 1: 0.066845703125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1479] Accumulated tokens for job 1: 1106493
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1481] Discard waste for job 1: 987.1784948564147
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1484] Preserve waste for job 1: 3.0708514464144803
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207082.0508068
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1462] Request GPU size bytes: 530841600
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1463] Token size of the request: 4032
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1469] Swap waste for job 102: 0.0164794921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1479] Accumulated tokens for job 102: 1106493
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1481] Discard waste for job 102: 987.1784948564147
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1484] Preserve waste for job 102: 0.9766655769056947
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:307] Request job id arriving: 17, time is 1761207082.0514581
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:315] Request job id: 17
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,053] LMCache INFO:[0m Reqid: chatcmpl-a757e999f6f845638cda56c78dd9dcc5, Total tokens 5192, LMCache hit tokens: 3584, need to load: 3568 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,056] LMCache INFO:[0m Reqid: chatcmpl-e1c7b31d0d0e4eb7a3dd93dab45d3530, Total tokens 16743, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,070] LMCache INFO:[0m Retrieved 3584 out of 3584 required tokens (from 3584 total tokens). size: 0.4375 gb, cost 9.5087 ms, throughput: 46.0104 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,099] LMCache INFO:[0m Retrieved 10752 out of 10752 required tokens (from 10752 total tokens). size: 1.3125 gb, cost 28.0623 ms, throughput: 46.7709 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,505] LMCache INFO:[0m Storing KV cache for 1608 out of 5192 tokens (skip_leading_tokens=3584) for request chatcmpl-a757e999f6f845638cda56c78dd9dcc5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,509] LMCache INFO:[0m Stored 1608 out of total 1608 tokens. size: 0.1963 gb, cost 4.3835 ms, throughput: 44.7789 GB/s; offload_time: 4.3678 ms, put_time: 0.0157 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,509] LMCache INFO:[0m Storing KV cache for 4608 out of 15360 tokens (skip_leading_tokens=10752) for request chatcmpl-e1c7b31d0d0e4eb7a3dd93dab45d3530 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,522] LMCache INFO:[0m Stored 4608 out of total 4608 tokens. size: 0.5625 gb, cost 11.9878 ms, throughput: 46.9228 GB/s; offload_time: 11.9624 ms, put_time: 0.0254 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,522] LMCache INFO:[0m Storing KV cache for 1981 out of 7869 tokens (skip_leading_tokens=5888) for request chatcmpl-91652ee0b66c4b6d9a27cd06e5db77c3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,527] LMCache INFO:[0m Stored 1981 out of total 1981 tokens. size: 0.2418 gb, cost 5.2649 ms, throughput: 45.9308 GB/s; offload_time: 5.2479 ms, put_time: 0.0170 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:328] Request job id finishing: 107, time is 1761207082.5301883
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1462] Request GPU size bytes: 856424448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1463] Token size of the request: 6514
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1469] Swap waste for job 107: 0.0265869140625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1479] Accumulated tokens for job 107: 1099484
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1481] Discard waste for job 107: 974.8219070069983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1484] Preserve waste for job 107: 0.9738660292191939
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207082.5304763
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1462] Request GPU size bytes: 1323565056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1463] Token size of the request: 10084
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1469] Swap waste for job 7: 0.0410888671875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1479] Accumulated tokens for job 7: 1099484
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1481] Discard waste for job 7: 974.8219070069983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [scheduler.py:1484] Preserve waste for job 7: 0.9738660292191939
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207082.5309176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:22 [estimate_with_func.py:315] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,533] LMCache INFO:[0m Reqid: chatcmpl-e556d0a3462d45189a9be8c1e926541f, Total tokens 19809, LMCache hit tokens: 13568, need to load: 13552 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,537] LMCache INFO:[0m Reqid: chatcmpl-dc69223ecc874eb9b9ea01305a73d963, Total tokens 4133, LMCache hit tokens: 2560, need to load: 2544 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,575] LMCache INFO:[0m Retrieved 13568 out of 13568 required tokens (from 13568 total tokens). size: 1.6562 gb, cost 35.4558 ms, throughput: 46.7131 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:22,582] LMCache INFO:[0m Retrieved 2560 out of 2560 required tokens (from 2560 total tokens). size: 0.3125 gb, cost 6.8281 ms, throughput: 45.7665 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:39140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,065] LMCache INFO:[0m Storing KV cache for 6241 out of 19809 tokens (skip_leading_tokens=13568) for request chatcmpl-e556d0a3462d45189a9be8c1e926541f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,082] LMCache INFO:[0m Stored 6241 out of total 6241 tokens. size: 0.7618 gb, cost 16.9884 ms, throughput: 44.8447 GB/s; offload_time: 16.9499 ms, put_time: 0.0385 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,082] LMCache INFO:[0m Storing KV cache for 512 out of 3072 tokens (skip_leading_tokens=2560) for request chatcmpl-dc69223ecc874eb9b9ea01305a73d963 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,084] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.4004 ms, throughput: 44.6287 GB/s; offload_time: 1.3925 ms, put_time: 0.0080 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,084] LMCache INFO:[0m Storing KV cache for 1383 out of 16743 tokens (skip_leading_tokens=15360) for request chatcmpl-e1c7b31d0d0e4eb7a3dd93dab45d3530 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,088] LMCache INFO:[0m Stored 1383 out of total 1383 tokens. size: 0.1688 gb, cost 3.9177 ms, throughput: 43.0924 GB/s; offload_time: 3.9042 ms, put_time: 0.0135 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:328] Request job id finishing: 36, time is 1761207083.090931
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1462] Request GPU size bytes: 1725300736
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1463] Token size of the request: 13043
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1469] Swap waste for job 36: 0.05356038411458333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1479] Accumulated tokens for job 36: 1106828
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1481] Discard waste for job 36: 987.7710349866579
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1484] Preserve waste for job 36: 3.0708514464144803
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:328] Request job id finishing: 117, time is 1761207083.0916471
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1462] Request GPU size bytes: 743702528
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1463] Token size of the request: 5655
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1469] Swap waste for job 117: 0.023087565104166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1479] Accumulated tokens for job 117: 1106828
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1481] Discard waste for job 117: 987.7710349866579
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1484] Preserve waste for job 117: 0.970153978892735
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:328] Request job id finishing: 119, time is 1761207083.0918155
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1462] Request GPU size bytes: 395968512
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1463] Token size of the request: 3003
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1469] Swap waste for job 119: 0.01229248046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1479] Accumulated tokens for job 119: 1106828
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1481] Discard waste for job 119: 987.7710349866579
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1484] Preserve waste for job 119: 0.970153978892735
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207083.092494
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:315] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,095] LMCache INFO:[0m Reqid: chatcmpl-4fd2c3fe58584d92b9b60567e5fe0b28, Total tokens 15001, LMCache hit tokens: 7680, need to load: 7664 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,119] LMCache INFO:[0m Retrieved 7680 out of 7680 required tokens (from 7680 total tokens). size: 0.9375 gb, cost 20.1254 ms, throughput: 46.5829 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '117', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,539] LMCache INFO:[0m Storing KV cache for 6912 out of 14592 tokens (skip_leading_tokens=7680) for request chatcmpl-4fd2c3fe58584d92b9b60567e5fe0b28 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,557] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 17.9768 ms, throughput: 46.9356 GB/s; offload_time: 17.9377 ms, put_time: 0.0391 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,557] LMCache INFO:[0m Storing KV cache for 1061 out of 4133 tokens (skip_leading_tokens=3072) for request chatcmpl-dc69223ecc874eb9b9ea01305a73d963 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,560] LMCache INFO:[0m Stored 1061 out of total 1061 tokens. size: 0.1295 gb, cost 2.8662 ms, throughput: 45.1874 GB/s; offload_time: 2.8538 ms, put_time: 0.0125 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:328] Request job id finishing: 144, time is 1761207083.5633976
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1462] Request GPU size bytes: 2156003328
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1463] Token size of the request: 16407
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1469] Swap waste for job 144: 0.06693115234375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1479] Accumulated tokens for job 144: 1100128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1481] Discard waste for job 144: 975.9540069653174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1484] Preserve waste for job 144: 3.0708514464144803
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:328] Request job id finishing: 123, time is 1761207083.5639405
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1462] Request GPU size bytes: 1746141184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1463] Token size of the request: 13283
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1469] Swap waste for job 123: 0.05420735677083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1479] Accumulated tokens for job 123: 1100128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1481] Discard waste for job 123: 975.9540069653174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1484] Preserve waste for job 123: 0.9671085147715327
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207083.5641978
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1462] Request GPU size bytes: 579469312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1463] Token size of the request: 4407
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1469] Swap waste for job 173: 0.017989095052083334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1479] Accumulated tokens for job 173: 1100128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1481] Discard waste for job 173: 975.9540069653174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [scheduler.py:1484] Preserve waste for job 173: 0.9671085147715327
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:307] Request job id arriving: 117, time is 1761207083.564551
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:23 [estimate_with_func.py:315] Request job id: 117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,566] LMCache INFO:[0m Reqid: chatcmpl-0c0737ed312d4c609d136ee26ed94df4, Total tokens 8764, LMCache hit tokens: 4864, need to load: 4848 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,568] LMCache INFO:[0m Reqid: chatcmpl-84d3313081f24c8ebe6703bf3c518c20, Total tokens 12071, LMCache hit tokens: 6144, need to load: 6128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,585] LMCache INFO:[0m Retrieved 4864 out of 4864 required tokens (from 4864 total tokens). size: 0.5938 gb, cost 12.8261 ms, throughput: 46.2923 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,601] LMCache INFO:[0m Retrieved 6144 out of 6144 required tokens (from 6144 total tokens). size: 0.7500 gb, cost 16.0971 ms, throughput: 46.5922 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '107', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,988] LMCache INFO:[0m Storing KV cache for 3900 out of 8764 tokens (skip_leading_tokens=4864) for request chatcmpl-0c0737ed312d4c609d136ee26ed94df4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,998] LMCache INFO:[0m Stored 3900 out of total 3900 tokens. size: 0.4761 gb, cost 10.3170 ms, throughput: 46.1446 GB/s; offload_time: 10.2837 ms, put_time: 0.0333 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:23,998] LMCache INFO:[0m Storing KV cache for 3840 out of 9984 tokens (skip_leading_tokens=6144) for request chatcmpl-84d3313081f24c8ebe6703bf3c518c20 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,018] LMCache INFO:[0m Stored 3840 out of total 3840 tokens. size: 0.4688 gb, cost 19.8321 ms, throughput: 23.6359 GB/s; offload_time: 19.8044 ms, put_time: 0.0278 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,019] LMCache INFO:[0m Storing KV cache for 409 out of 15001 tokens (skip_leading_tokens=14592) for request chatcmpl-4fd2c3fe58584d92b9b60567e5fe0b28 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,020] LMCache INFO:[0m Stored 409 out of total 409 tokens. size: 0.0499 gb, cost 1.3092 ms, throughput: 38.1344 GB/s; offload_time: 1.2996 ms, put_time: 0.0097 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:307] Request job id arriving: 107, time is 1761207084.0235248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:315] Request job id: 107
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,026] LMCache INFO:[0m Reqid: chatcmpl-a263e30e2f64499595c8b2f5d7bc1004, Total tokens 6334, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,029] LMCache INFO:[0m Reqid: chatcmpl-4366a1a99bb04fef99a1e3b3cb1ef69d, Total tokens 33954, LMCache hit tokens: 16896, need to load: 16880 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,044] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.8025 ms, throughput: 46.2858 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,089] LMCache INFO:[0m Retrieved 16896 out of 16896 required tokens (from 16896 total tokens). size: 2.0625 gb, cost 44.4340 ms, throughput: 46.4172 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '123', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,536] LMCache INFO:[0m Storing KV cache for 2238 out of 6334 tokens (skip_leading_tokens=4096) for request chatcmpl-a263e30e2f64499595c8b2f5d7bc1004 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,543] LMCache INFO:[0m Stored 2238 out of total 2238 tokens. size: 0.2732 gb, cost 6.0525 ms, throughput: 45.1375 GB/s; offload_time: 6.0295 ms, put_time: 0.0230 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,543] LMCache INFO:[0m Storing KV cache for 3840 out of 20736 tokens (skip_leading_tokens=16896) for request chatcmpl-4366a1a99bb04fef99a1e3b3cb1ef69d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,553] LMCache INFO:[0m Stored 3840 out of total 3840 tokens. size: 0.4688 gb, cost 10.0945 ms, throughput: 46.4361 GB/s; offload_time: 10.0742 ms, put_time: 0.0203 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,553] LMCache INFO:[0m Storing KV cache for 2087 out of 12071 tokens (skip_leading_tokens=9984) for request chatcmpl-84d3313081f24c8ebe6703bf3c518c20 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:24,559] LMCache INFO:[0m Stored 2087 out of total 2087 tokens. size: 0.2548 gb, cost 5.5851 ms, throughput: 45.6141 GB/s; offload_time: 5.5691 ms, put_time: 0.0160 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:328] Request job id finishing: 32, time is 1761207084.562091
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [scheduler.py:1462] Request GPU size bytes: 373817344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [scheduler.py:1463] Token size of the request: 2831
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [scheduler.py:1469] Swap waste for job 32: 0.011604817708333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [scheduler.py:1479] Accumulated tokens for job 32: 1127154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [scheduler.py:1481] Discard waste for job 32: 1024.0557846116942
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [scheduler.py:1484] Preserve waste for job 32: 0.9673444716369405
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207084.562649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:315] Request job id: 173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:307] Request job id arriving: 123, time is 1761207084.5627835
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:315] Request job id: 123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207084.5628757
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:24 [estimate_with_func.py:315] Request job id: 44
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '1', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '32', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,176] LMCache INFO:[0m Storing KV cache for 8192 out of 28928 tokens (skip_leading_tokens=20736) for request chatcmpl-4366a1a99bb04fef99a1e3b3cb1ef69d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,198] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.3978 ms, throughput: 46.7338 GB/s; offload_time: 21.3396 ms, put_time: 0.0582 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [estimate_with_func.py:307] Request job id arriving: 1, time is 1761207085.2021098
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [estimate_with_func.py:315] Request job id: 1
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [estimate_with_func.py:307] Request job id arriving: 32, time is 1761207085.2023
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [estimate_with_func.py:315] Request job id: 32
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,206] LMCache INFO:[0m Reqid: chatcmpl-3fe329b87f1b468286e58573fad2e1a2, Total tokens 3653, LMCache hit tokens: 2304, need to load: 2288 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,208] LMCache INFO:[0m Reqid: chatcmpl-60968d1c25d44261a9cae64ef9507c09, Total tokens 11466, LMCache hit tokens: 5632, need to load: 5616 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,219] LMCache INFO:[0m Retrieved 2304 out of 2304 required tokens (from 2304 total tokens). size: 0.2812 gb, cost 6.2838 ms, throughput: 44.7576 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '36', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58492 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,234] LMCache INFO:[0m Retrieved 5632 out of 5632 required tokens (from 5632 total tokens). size: 0.6875 gb, cost 14.7577 ms, throughput: 46.5860 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,787] LMCache INFO:[0m Storing KV cache for 1349 out of 3653 tokens (skip_leading_tokens=2304) for request chatcmpl-3fe329b87f1b468286e58573fad2e1a2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,791] LMCache INFO:[0m Stored 1349 out of total 1349 tokens. size: 0.1647 gb, cost 3.7883 ms, throughput: 43.4692 GB/s; offload_time: 3.7643 ms, put_time: 0.0239 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,792] LMCache INFO:[0m Storing KV cache for 1792 out of 7424 tokens (skip_leading_tokens=5632) for request chatcmpl-60968d1c25d44261a9cae64ef9507c09 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,796] LMCache INFO:[0m Stored 1792 out of total 1792 tokens. size: 0.2188 gb, cost 4.7310 ms, throughput: 46.2377 GB/s; offload_time: 4.7115 ms, put_time: 0.0195 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,797] LMCache INFO:[0m Storing KV cache for 5026 out of 33954 tokens (skip_leading_tokens=28928) for request chatcmpl-4366a1a99bb04fef99a1e3b3cb1ef69d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,811] LMCache INFO:[0m Stored 5026 out of total 5026 tokens. size: 0.6135 gb, cost 14.0948 ms, throughput: 43.5285 GB/s; offload_time: 14.0606 ms, put_time: 0.0342 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [estimate_with_func.py:328] Request job id finishing: 91, time is 1761207085.8147597
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [scheduler.py:1462] Request GPU size bytes: 5854068736
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [scheduler.py:1463] Token size of the request: 44649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [scheduler.py:1469] Swap waste for job 91: 0.18173421223958333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [scheduler.py:1479] Accumulated tokens for job 91: 1139442
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [scheduler.py:1481] Discard waste for job 91: 1046.3089777426762
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [scheduler.py:1484] Preserve waste for job 91: 0.9654416900744541
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [estimate_with_func.py:307] Request job id arriving: 36, time is 1761207085.8161132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:25 [estimate_with_func.py:315] Request job id: 36
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,819] LMCache INFO:[0m Reqid: chatcmpl-0f07f2981f7e49e38e99a41c76cefc39, Total tokens 3069, LMCache hit tokens: 1536, need to load: 1520 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,821] LMCache INFO:[0m Reqid: chatcmpl-50a26d6ef75142fdb69f99fe1d4925f6, Total tokens 4205, LMCache hit tokens: 2560, need to load: 2544 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,824] LMCache INFO:[0m Reqid: chatcmpl-ca7e0dcd7413429ca1cd91f94b487bc3, Total tokens 40978, LMCache hit tokens: 29952, need to load: 29936 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,835] LMCache INFO:[0m Retrieved 1536 out of 1536 required tokens (from 1536 total tokens). size: 0.1875 gb, cost 4.1699 ms, throughput: 44.9649 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,842] LMCache INFO:[0m Retrieved 2560 out of 2560 required tokens (from 2560 total tokens). size: 0.3125 gb, cost 6.7792 ms, throughput: 46.0966 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:25,921] LMCache INFO:[0m Retrieved 29952 out of 29952 required tokens (from 29952 total tokens). size: 3.6562 gb, cost 78.5684 ms, throughput: 46.5359 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '15', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '144', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,331] LMCache INFO:[0m Storing KV cache for 1533 out of 3069 tokens (skip_leading_tokens=1536) for request chatcmpl-0f07f2981f7e49e38e99a41c76cefc39 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,335] LMCache INFO:[0m Stored 1533 out of total 1533 tokens. size: 0.1871 gb, cost 4.3779 ms, throughput: 42.7452 GB/s; offload_time: 4.3493 ms, put_time: 0.0286 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,335] LMCache INFO:[0m Storing KV cache for 1645 out of 4205 tokens (skip_leading_tokens=2560) for request chatcmpl-50a26d6ef75142fdb69f99fe1d4925f6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,340] LMCache INFO:[0m Stored 1645 out of total 1645 tokens. size: 0.2008 gb, cost 4.3645 ms, throughput: 46.0091 GB/s; offload_time: 4.3509 ms, put_time: 0.0136 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,340] LMCache INFO:[0m Storing KV cache for 768 out of 30720 tokens (skip_leading_tokens=29952) for request chatcmpl-ca7e0dcd7413429ca1cd91f94b487bc3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,343] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.4354 ms, throughput: 38.4944 GB/s; offload_time: 2.4228 ms, put_time: 0.0126 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,343] LMCache INFO:[0m Storing KV cache for 4042 out of 11466 tokens (skip_leading_tokens=7424) for request chatcmpl-60968d1c25d44261a9cae64ef9507c09 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:26,354] LMCache INFO:[0m Stored 4042 out of total 4042 tokens. size: 0.4934 gb, cost 10.5548 ms, throughput: 46.7474 GB/s; offload_time: 10.5307 ms, put_time: 0.0241 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:26 [estimate_with_func.py:307] Request job id arriving: 15, time is 1761207086.3575072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:26 [estimate_with_func.py:315] Request job id: 15
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:26 [estimate_with_func.py:307] Request job id arriving: 144, time is 1761207086.3577106
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:26 [estimate_with_func.py:315] Request job id: 144
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '91', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58950 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,097] LMCache INFO:[0m Storing KV cache for 8192 out of 38912 tokens (skip_leading_tokens=30720) for request chatcmpl-ca7e0dcd7413429ca1cd91f94b487bc3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,124] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 25.6841 ms, throughput: 38.9345 GB/s; offload_time: 25.6221 ms, put_time: 0.0620 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207087.1270216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1462] Request GPU size bytes: 4353818624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1463] Token size of the request: 33165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1469] Swap waste for job 150: 0.13516031901041667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1479] Accumulated tokens for job 150: 1143045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1481] Discard waste for job 150: 1052.879246126458
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1484] Preserve waste for job 150: 0.9654416900744541
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:307] Request job id arriving: 91, time is 1761207087.1280885
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:315] Request job id: 91
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,131] LMCache INFO:[0m Reqid: chatcmpl-cebb9e8cdb764afe8ca2c9229f49701e, Total tokens 7305, LMCache hit tokens: 3584, need to load: 3568 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,135] LMCache INFO:[0m Reqid: chatcmpl-dca592c95d0247709ea0d4a061299b3d, Total tokens 71742, LMCache hit tokens: 47616, need to load: 47600 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,148] LMCache INFO:[0m Retrieved 3584 out of 3584 required tokens (from 3584 total tokens). size: 0.4375 gb, cost 9.6678 ms, throughput: 45.2531 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,548] LMCache INFO:[0m Storing KV cache for 3721 out of 7305 tokens (skip_leading_tokens=3584) for request chatcmpl-cebb9e8cdb764afe8ca2c9229f49701e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,558] LMCache INFO:[0m Stored 3721 out of total 3721 tokens. size: 0.4542 gb, cost 9.9339 ms, throughput: 45.7244 GB/s; offload_time: 9.8958 ms, put_time: 0.0382 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,558] LMCache INFO:[0m Storing KV cache for 2066 out of 40978 tokens (skip_leading_tokens=38912) for request chatcmpl-ca7e0dcd7413429ca1cd91f94b487bc3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,565] LMCache INFO:[0m Stored 2066 out of total 2066 tokens. size: 0.2522 gb, cost 6.3327 ms, throughput: 39.8245 GB/s; offload_time: 6.3130 ms, put_time: 0.0198 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,572] LMCache INFO:[0m Reqid: chatcmpl-dca592c95d0247709ea0d4a061299b3d, Total tokens 71742, LMCache hit tokens: 47616, need to load: 47600 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:328] Request job id finishing: 105, time is 1761207087.6492825
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:328] Request job id finishing: 131, time is 1761207087.6495588
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1462] Request GPU size bytes: 1772617728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1463] Token size of the request: 13401
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1469] Swap waste for job 131: 0.055029296875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1479] Accumulated tokens for job 131: 1117185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1481] Discard waste for job 131: 1006.1779553265395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1484] Preserve waste for job 131: 3.0745442269453362
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207087.6499653
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1462] Request GPU size bytes: 1108869120
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1463] Token size of the request: 8440
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1469] Swap waste for job 5: 0.034423828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1479] Accumulated tokens for job 5: 1117185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1481] Discard waste for job 5: 1006.1779553265395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1484] Preserve waste for job 5: 0.9679267389433724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:328] Request job id finishing: 98, time is 1761207087.6501884
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1462] Request GPU size bytes: 4348444672
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1463] Token size of the request: 33160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1469] Swap waste for job 98: 0.13499348958333332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1479] Accumulated tokens for job 98: 1117185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1481] Discard waste for job 98: 1006.1779553265395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1484] Preserve waste for job 98: 0.9679267389433724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [estimate_with_func.py:328] Request job id finishing: 160, time is 1761207087.6506033
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1462] Request GPU size bytes: 835321856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1463] Token size of the request: 6357
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1469] Swap waste for job 160: 0.025931803385416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1479] Accumulated tokens for job 160: 1117185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1481] Discard waste for job 160: 1006.1779553265395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:27 [scheduler.py:1484] Preserve waste for job 160: 0.9679267389433724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,653] LMCache INFO:[0m Reqid: chatcmpl-dca592c95d0247709ea0d4a061299b3d, Total tokens 71742, LMCache hit tokens: 47616, need to load: 47600 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:27,797] LMCache INFO:[0m Retrieved 47616 out of 47616 required tokens (from 47616 total tokens). size: 5.8125 gb, cost 126.0458 ms, throughput: 46.1142 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '160', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '98', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:28,728] LMCache INFO:[0m Storing KV cache for 7936 out of 55552 tokens (skip_leading_tokens=47616) for request chatcmpl-dca592c95d0247709ea0d4a061299b3d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:28,750] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.7026 ms, throughput: 44.6376 GB/s; offload_time: 21.6462 ms, put_time: 0.0564 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [estimate_with_func.py:328] Request job id finishing: 25, time is 1761207088.7537606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [scheduler.py:1462] Request GPU size bytes: 609878016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [scheduler.py:1463] Token size of the request: 4587
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [scheduler.py:1469] Swap waste for job 25: 0.01893310546875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [scheduler.py:1479] Accumulated tokens for job 25: 1117480
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [scheduler.py:1481] Discard waste for job 25: 1006.7047311122789
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [scheduler.py:1484] Preserve waste for job 25: 0.9679267389433724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [estimate_with_func.py:307] Request job id arriving: 160, time is 1761207088.7545736
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [estimate_with_func.py:315] Request job id: 160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [estimate_with_func.py:307] Request job id arriving: 98, time is 1761207088.7547455
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:28 [estimate_with_func.py:315] Request job id: 98
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '119', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:53286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '25', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:29,803] LMCache INFO:[0m Storing KV cache for 8192 out of 63744 tokens (skip_leading_tokens=55552) for request chatcmpl-dca592c95d0247709ea0d4a061299b3d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:29,827] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.4858 ms, throughput: 44.4726 GB/s; offload_time: 22.4282 ms, put_time: 0.0576 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:328] Request job id finishing: 3, time is 1761207089.8300774
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [scheduler.py:1462] Request GPU size bytes: 6592135168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [scheduler.py:1463] Token size of the request: 50255
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [scheduler.py:1469] Swap waste for job 3: 0.20464680989583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [scheduler.py:1479] Accumulated tokens for job 3: 1112893
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [scheduler.py:1481] Discard waste for job 3: 998.5294061869375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [scheduler.py:1484] Preserve waste for job 3: 0.9698475901509674
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:307] Request job id arriving: 119, time is 1761207089.8314364
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:315] Request job id: 119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207089.831614
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:315] Request job id: 5
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:307] Request job id arriving: 25, time is 1761207089.831692
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:315] Request job id: 25
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207089.8317623
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:29 [estimate_with_func.py:315] Request job id: 150
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:29,838] LMCache INFO:[0m Reqid: chatcmpl-b159fe8ad0d4426f8bba491530d1ad48, Total tokens 17473, LMCache hit tokens: 9728, need to load: 9712 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:29,869] LMCache INFO:[0m Retrieved 9728 out of 9728 required tokens (from 9728 total tokens). size: 1.1875 gb, cost 25.7254 ms, throughput: 46.1606 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '131', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '3', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:11:30 [loggers.py:123] Engine 000: Avg prompt throughput: 24163.5 tokens/s, Avg generation throughput: 112.5 tokens/s, Running: 63 reqs, Waiting: 26 reqs, GPU KV cache usage: 92.1%, Prefix cache hit rate: 28.4%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:30,975] LMCache INFO:[0m Storing KV cache for 256 out of 9984 tokens (skip_leading_tokens=9728) for request chatcmpl-b159fe8ad0d4426f8bba491530d1ad48 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:30,977] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 1.0867 ms, throughput: 28.7575 GB/s; offload_time: 1.0659 ms, put_time: 0.0208 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:30,977] LMCache INFO:[0m Storing KV cache for 7998 out of 71742 tokens (skip_leading_tokens=63744) for request chatcmpl-dca592c95d0247709ea0d4a061299b3d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:31,004] LMCache INFO:[0m Stored 7998 out of total 7998 tokens. size: 0.9763 gb, cost 25.9752 ms, throughput: 37.5865 GB/s; offload_time: 25.9256 ms, put_time: 0.0497 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:328] Request job id finishing: 168, time is 1761207091.006908
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1462] Request GPU size bytes: 970457088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1463] Token size of the request: 7338
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1469] Swap waste for job 168: 0.030126953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1479] Accumulated tokens for job 168: 1080111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1481] Discard waste for job 168: 941.0728617652557
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1484] Preserve waste for job 168: 1.030289649963379
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:328] Request job id finishing: 94, time is 1761207091.0074751
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1462] Request GPU size bytes: 682360832
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1463] Token size of the request: 5192
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1469] Swap waste for job 94: 0.021183268229166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1479] Accumulated tokens for job 94: 1080111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1481] Discard waste for job 94: 941.0728617652557
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [scheduler.py:1484] Preserve waste for job 94: 1.030289649963379
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:307] Request job id arriving: 131, time is 1761207091.0083878
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:315] Request job id: 131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:307] Request job id arriving: 3, time is 1761207091.0085728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:315] Request job id: 3
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:31,013] LMCache INFO:[0m Reqid: chatcmpl-3c4ff5f130bd4857b08527fd76461838, Total tokens 55388, LMCache hit tokens: 29952, need to load: 29936 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:31,098] LMCache INFO:[0m Retrieved 29952 out of 29952 required tokens (from 29952 total tokens). size: 3.6562 gb, cost 78.1121 ms, throughput: 46.8077 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '168', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:31,568] LMCache INFO:[0m Storing KV cache for 512 out of 30464 tokens (skip_leading_tokens=29952) for request chatcmpl-3c4ff5f130bd4857b08527fd76461838 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:31,570] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.9049 ms, throughput: 32.8100 GB/s; offload_time: 1.8863 ms, put_time: 0.0186 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:31,571] LMCache INFO:[0m Storing KV cache for 7489 out of 17473 tokens (skip_leading_tokens=9984) for request chatcmpl-b159fe8ad0d4426f8bba491530d1ad48 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:31,590] LMCache INFO:[0m Stored 7489 out of total 7489 tokens. size: 0.9142 gb, cost 19.3595 ms, throughput: 47.2215 GB/s; offload_time: 19.3207 ms, put_time: 0.0388 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:307] Request job id arriving: 168, time is 1761207091.5934901
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:31 [estimate_with_func.py:315] Request job id: 168
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '94', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:32,329] LMCache INFO:[0m Storing KV cache for 8192 out of 38656 tokens (skip_leading_tokens=30464) for request chatcmpl-3c4ff5f130bd4857b08527fd76461838 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:32,354] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.7371 ms, throughput: 42.1281 GB/s; offload_time: 23.6808 ms, put_time: 0.0563 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:32 [estimate_with_func.py:307] Request job id arriving: 94, time is 1761207092.3572085
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:32 [estimate_with_func.py:315] Request job id: 94
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:33,192] LMCache INFO:[0m Storing KV cache for 8192 out of 46848 tokens (skip_leading_tokens=38656) for request chatcmpl-3c4ff5f130bd4857b08527fd76461838 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:33,215] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.2235 ms, throughput: 44.9975 GB/s; offload_time: 22.1709 ms, put_time: 0.0526 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:33 [estimate_with_func.py:328] Request job id finishing: 29, time is 1761207093.2182176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,156] LMCache INFO:[0m Storing KV cache for 7936 out of 54784 tokens (skip_leading_tokens=46848) for request chatcmpl-3c4ff5f130bd4857b08527fd76461838 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,179] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.6990 ms, throughput: 44.6449 GB/s; offload_time: 21.6348 ms, put_time: 0.0642 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,185] LMCache INFO:[0m Reqid: chatcmpl-0eb276971d3a4668bb5c2d9c3826fa39, Total tokens 8564, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,188] LMCache INFO:[0m Reqid: chatcmpl-d6ffa3f3552f463b8214aa95fa872da1, Total tokens 11395, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,206] LMCache INFO:[0m Retrieved 5120 out of 5120 required tokens (from 5120 total tokens). size: 0.6250 gb, cost 13.6570 ms, throughput: 45.7641 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,217] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.7700 ms, throughput: 46.4252 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,615] LMCache INFO:[0m Storing KV cache for 3444 out of 8564 tokens (skip_leading_tokens=5120) for request chatcmpl-0eb276971d3a4668bb5c2d9c3826fa39 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,624] LMCache INFO:[0m Stored 3444 out of total 3444 tokens. size: 0.4204 gb, cost 9.1534 ms, throughput: 45.9295 GB/s; offload_time: 9.1192 ms, put_time: 0.0342 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,624] LMCache INFO:[0m Storing KV cache for 4096 out of 8192 tokens (skip_leading_tokens=4096) for request chatcmpl-d6ffa3f3552f463b8214aa95fa872da1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,635] LMCache INFO:[0m Stored 4096 out of total 4096 tokens. size: 0.5000 gb, cost 10.6223 ms, throughput: 47.0708 GB/s; offload_time: 10.5995 ms, put_time: 0.0228 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,636] LMCache INFO:[0m Storing KV cache for 604 out of 55388 tokens (skip_leading_tokens=54784) for request chatcmpl-3c4ff5f130bd4857b08527fd76461838 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,639] LMCache INFO:[0m Stored 604 out of total 604 tokens. size: 0.0737 gb, cost 3.1551 ms, throughput: 23.3690 GB/s; offload_time: 3.1404 ms, put_time: 0.0147 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:34 [estimate_with_func.py:328] Request job id finishing: 81, time is 1761207094.6425292
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:34 [scheduler.py:1462] Request GPU size bytes: 832045056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:34 [scheduler.py:1463] Token size of the request: 6272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:34 [scheduler.py:1469] Swap waste for job 81: 0.025830078125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:34 [scheduler.py:1479] Accumulated tokens for job 81: 1136647
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:34 [scheduler.py:1481] Discard waste for job 81: 1041.2263043309479
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:34 [scheduler.py:1484] Preserve waste for job 81: 1.030450678511754
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,646] LMCache INFO:[0m Reqid: chatcmpl-3ee1fbb09a514a1c8e0d73093755a188, Total tokens 16134, LMCache hit tokens: 8192, need to load: 8176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:34,671] LMCache INFO:[0m Retrieved 8192 out of 8192 required tokens (from 8192 total tokens). size: 1.0000 gb, cost 21.4520 ms, throughput: 46.6157 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,093] LMCache INFO:[0m Storing KV cache for 5120 out of 13312 tokens (skip_leading_tokens=8192) for request chatcmpl-3ee1fbb09a514a1c8e0d73093755a188 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,107] LMCache INFO:[0m Stored 5120 out of total 5120 tokens. size: 0.6250 gb, cost 13.3117 ms, throughput: 46.9513 GB/s; offload_time: 13.2816 ms, put_time: 0.0300 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,107] LMCache INFO:[0m Storing KV cache for 3203 out of 11395 tokens (skip_leading_tokens=8192) for request chatcmpl-d6ffa3f3552f463b8214aa95fa872da1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,115] LMCache INFO:[0m Stored 3203 out of total 3203 tokens. size: 0.3910 gb, cost 8.4096 ms, throughput: 46.4933 GB/s; offload_time: 8.3864 ms, put_time: 0.0232 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [estimate_with_func.py:328] Request job id finishing: 152, time is 1761207095.1982403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1462] Request GPU size bytes: 1756102656
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1463] Token size of the request: 13250
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1469] Swap waste for job 152: 0.0545166015625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1479] Accumulated tokens for job 152: 1130375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1481] Discard waste for job 152: 1029.8657875885983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1484] Preserve waste for job 152: 3.075951859502509
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207095.1987593
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1462] Request GPU size bytes: 480772096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1463] Token size of the request: 3653
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1469] Swap waste for job 122: 0.014925130208333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1479] Accumulated tokens for job 122: 1130375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1481] Discard waste for job 122: 1029.8657875885983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1484] Preserve waste for job 122: 1.030450678511754
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,201] LMCache INFO:[0m Reqid: chatcmpl-3ee1fbb09a514a1c8e0d73093755a188, Total tokens 16134, LMCache hit tokens: 13312, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,204] LMCache INFO:[0m Reqid: chatcmpl-e5b194a371c044cc87c08aef067d6c0f, Total tokens 23007, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,485] LMCache INFO:[0m Storing KV cache for 2822 out of 16134 tokens (skip_leading_tokens=13312) for request chatcmpl-3ee1fbb09a514a1c8e0d73093755a188 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,493] LMCache INFO:[0m Stored 2822 out of total 2822 tokens. size: 0.3445 gb, cost 7.5932 ms, throughput: 45.3673 GB/s; offload_time: 7.5677 ms, put_time: 0.0255 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [estimate_with_func.py:328] Request job id finishing: 52, time is 1761207095.4955792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1462] Request GPU size bytes: 1760165888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1463] Token size of the request: 13307
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1469] Swap waste for job 52: 0.054642740885416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1479] Accumulated tokens for job 52: 1129606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1481] Discard waste for job 52: 1028.477180823109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:35 [scheduler.py:1484] Preserve waste for job 52: 3.075951859502509
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,498] LMCache INFO:[0m Reqid: chatcmpl-e5b194a371c044cc87c08aef067d6c0f, Total tokens 23007, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:35,542] LMCache INFO:[0m Retrieved 12032 out of 12032 required tokens (from 12032 total tokens). size: 1.4688 gb, cost 31.4554 ms, throughput: 46.6931 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '81', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59026 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,041] LMCache INFO:[0m Storing KV cache for 7936 out of 19968 tokens (skip_leading_tokens=12032) for request chatcmpl-e5b194a371c044cc87c08aef067d6c0f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,065] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 23.1376 ms, throughput: 41.8692 GB/s; offload_time: 23.0812 ms, put_time: 0.0564 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [estimate_with_func.py:307] Request job id arriving: 81, time is 1761207096.068551
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [estimate_with_func.py:315] Request job id: 81
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,071] LMCache INFO:[0m Reqid: chatcmpl-cde70f395a4c439e8151c714cfa5f87f, Total tokens 12594, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,385] LMCache INFO:[0m Storing KV cache for 3039 out of 23007 tokens (skip_leading_tokens=19968) for request chatcmpl-e5b194a371c044cc87c08aef067d6c0f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,395] LMCache INFO:[0m Stored 3039 out of total 3039 tokens. size: 0.3710 gb, cost 8.9183 ms, throughput: 41.5969 GB/s; offload_time: 8.8906 ms, put_time: 0.0277 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,400] LMCache INFO:[0m Reqid: chatcmpl-cde70f395a4c439e8151c714cfa5f87f, Total tokens 12594, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,480] LMCache INFO:[0m Reqid: chatcmpl-cde70f395a4c439e8151c714cfa5f87f, Total tokens 12594, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,558] LMCache INFO:[0m Reqid: chatcmpl-cde70f395a4c439e8151c714cfa5f87f, Total tokens 12594, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207096.633353
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [scheduler.py:1462] Request GPU size bytes: 3157131264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [scheduler.py:1463] Token size of the request: 24040
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [scheduler.py:1469] Swap waste for job 136: 0.09801025390625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [scheduler.py:1479] Accumulated tokens for job 136: 1139306
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [scheduler.py:1481] Discard waste for job 136: 1046.0613770006787
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:36 [scheduler.py:1484] Preserve waste for job 136: 1.033088116645813
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,636] LMCache INFO:[0m Reqid: chatcmpl-cde70f395a4c439e8151c714cfa5f87f, Total tokens 12594, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,640] LMCache INFO:[0m Reqid: chatcmpl-cda65f281e4f429c975b40bd63cda462, Total tokens 32981, LMCache hit tokens: 20736, need to load: 20720 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,661] LMCache INFO:[0m Retrieved 7168 out of 7168 required tokens (from 7168 total tokens). size: 0.8750 gb, cost 18.8906 ms, throughput: 46.3194 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:36,993] LMCache INFO:[0m Storing KV cache for 5426 out of 12594 tokens (skip_leading_tokens=7168) for request chatcmpl-cde70f395a4c439e8151c714cfa5f87f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:37,008] LMCache INFO:[0m Stored 5426 out of total 5426 tokens. size: 0.6624 gb, cost 14.7150 ms, throughput: 45.0120 GB/s; offload_time: 14.6779 ms, put_time: 0.0371 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:328] Request job id finishing: 19, time is 1761207097.0113237
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:328] Request job id finishing: 171, time is 1761207097.011866
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1462] Request GPU size bytes: 545128448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1463] Token size of the request: 4133
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1469] Swap waste for job 171: 0.016923014322916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1479] Accumulated tokens for job 171: 1127860
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1481] Discard waste for job 171: 1025.327853100452
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1484] Preserve waste for job 171: 3.075951859502509
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:37,015] LMCache INFO:[0m Reqid: chatcmpl-cda65f281e4f429c975b40bd63cda462, Total tokens 32981, LMCache hit tokens: 20736, need to load: 20720 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:37,075] LMCache INFO:[0m Retrieved 20736 out of 20736 required tokens (from 20736 total tokens). size: 2.5312 gb, cost 54.1966 ms, throughput: 46.7049 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '152', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:37,689] LMCache INFO:[0m Storing KV cache for 7936 out of 28672 tokens (skip_leading_tokens=20736) for request chatcmpl-cda65f281e4f429c975b40bd63cda462 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:37,711] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3902 ms, throughput: 45.2893 GB/s; offload_time: 21.3401 ms, put_time: 0.0501 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:328] Request job id finishing: 129, time is 1761207097.713799
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1462] Request GPU size bytes: 690749440
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1463] Token size of the request: 5124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1469] Swap waste for job 129: 0.021443684895833332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1479] Accumulated tokens for job 129: 1137461
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1481] Discard waste for job 129: 1042.705276301016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1484] Preserve waste for job 129: 3.075951859502509
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207097.7143893
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1462] Request GPU size bytes: 1819803648
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1463] Token size of the request: 13815
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1469] Swap waste for job 10: 0.056494140625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1479] Accumulated tokens for job 10: 1137461
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1481] Discard waste for job 10: 1042.705276301016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1484] Preserve waste for job 10: 1.033088116645813
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207097.7147658
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1462] Request GPU size bytes: 5953028096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1463] Token size of the request: 45376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1469] Swap waste for job 164: 0.18480631510416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1479] Accumulated tokens for job 164: 1137461
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1481] Discard waste for job 164: 1042.705276301016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [scheduler.py:1484] Preserve waste for job 164: 1.033088116645813
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207097.7158012
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:315] Request job id: 122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:307] Request job id arriving: 152, time is 1761207097.7159762
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:37 [estimate_with_func.py:315] Request job id: 152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:37,718] LMCache INFO:[0m Reqid: chatcmpl-fbb4ec18da304632bf5dd5d53e66a582, Total tokens 13490, LMCache hit tokens: 8704, need to load: 8688 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:37,748] LMCache INFO:[0m Retrieved 8704 out of 8704 required tokens (from 8704 total tokens). size: 1.0625 gb, cost 23.0658 ms, throughput: 46.0638 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '52', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,300] LMCache INFO:[0m Storing KV cache for 3840 out of 12544 tokens (skip_leading_tokens=8704) for request chatcmpl-fbb4ec18da304632bf5dd5d53e66a582 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,310] LMCache INFO:[0m Stored 3840 out of total 3840 tokens. size: 0.4688 gb, cost 10.4712 ms, throughput: 44.7655 GB/s; offload_time: 10.4419 ms, put_time: 0.0294 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,311] LMCache INFO:[0m Storing KV cache for 4309 out of 32981 tokens (skip_leading_tokens=28672) for request chatcmpl-cda65f281e4f429c975b40bd63cda462 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,324] LMCache INFO:[0m Stored 4309 out of total 4309 tokens. size: 0.5260 gb, cost 12.3559 ms, throughput: 42.5708 GB/s; offload_time: 12.3287 ms, put_time: 0.0273 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207098.3270087
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [estimate_with_func.py:315] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [estimate_with_func.py:307] Request job id arriving: 52, time is 1761207098.3271875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [estimate_with_func.py:315] Request job id: 52
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207098.3272705
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,330] LMCache INFO:[0m Reqid: chatcmpl-6da0d66553234e5696a8250ac2c76066, Total tokens 27639, LMCache hit tokens: 18688, need to load: 18672 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,385] LMCache INFO:[0m Retrieved 18688 out of 18688 required tokens (from 18688 total tokens). size: 2.2812 gb, cost 48.8251 ms, throughput: 46.7229 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,942] LMCache INFO:[0m Storing KV cache for 7168 out of 25856 tokens (skip_leading_tokens=18688) for request chatcmpl-6da0d66553234e5696a8250ac2c76066 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,962] LMCache INFO:[0m Stored 7168 out of total 7168 tokens. size: 0.8750 gb, cost 19.1256 ms, throughput: 45.7502 GB/s; offload_time: 19.0812 ms, put_time: 0.0445 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,962] LMCache INFO:[0m Storing KV cache for 946 out of 13490 tokens (skip_leading_tokens=12544) for request chatcmpl-fbb4ec18da304632bf5dd5d53e66a582 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,965] LMCache INFO:[0m Stored 946 out of total 946 tokens. size: 0.1155 gb, cost 2.8282 ms, throughput: 40.8309 GB/s; offload_time: 2.8174 ms, put_time: 0.0108 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [estimate_with_func.py:328] Request job id finishing: 24, time is 1761207098.9676757
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [scheduler.py:1462] Request GPU size bytes: 8816951296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [scheduler.py:1463] Token size of the request: 67172
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [scheduler.py:1469] Swap waste for job 24: 0.27371419270833336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [scheduler.py:1479] Accumulated tokens for job 24: 1114275
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [scheduler.py:1481] Discard waste for job 24: 1000.989011179233
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:38 [scheduler.py:1484] Preserve waste for job 24: 1.0443563445720798
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:38,972] LMCache INFO:[0m Reqid: chatcmpl-37efa5796fc543b29779ee394f908f07, Total tokens 55853, LMCache hit tokens: 21760, need to load: 21744 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:39,036] LMCache INFO:[0m Retrieved 21760 out of 21760 required tokens (from 21760 total tokens). size: 2.6562 gb, cost 56.7630 ms, throughput: 46.7954 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '24', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:39,637] LMCache INFO:[0m Storing KV cache for 6400 out of 28160 tokens (skip_leading_tokens=21760) for request chatcmpl-37efa5796fc543b29779ee394f908f07 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:39,655] LMCache INFO:[0m Stored 6400 out of total 6400 tokens. size: 0.7812 gb, cost 17.2918 ms, throughput: 45.1803 GB/s; offload_time: 17.2586 ms, put_time: 0.0332 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:39,655] LMCache INFO:[0m Storing KV cache for 1783 out of 27639 tokens (skip_leading_tokens=25856) for request chatcmpl-6da0d66553234e5696a8250ac2c76066 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:39,660] LMCache INFO:[0m Stored 1783 out of total 1783 tokens. size: 0.2177 gb, cost 5.2547 ms, throughput: 41.4200 GB/s; offload_time: 5.2397 ms, put_time: 0.0151 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:39 [estimate_with_func.py:307] Request job id arriving: 24, time is 1761207099.663835
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:39 [estimate_with_func.py:315] Request job id: 24
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:40,364] LMCache INFO:[0m Storing KV cache for 8192 out of 36352 tokens (skip_leading_tokens=28160) for request chatcmpl-37efa5796fc543b29779ee394f908f07 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '171', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51398 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:40,389] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.0379 ms, throughput: 41.6010 GB/s; offload_time: 23.9818 ms, put_time: 0.0561 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:40 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207100.392006
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:40 [estimate_with_func.py:315] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:40 [estimate_with_func.py:307] Request job id arriving: 171, time is 1761207100.392212
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:40 [estimate_with_func.py:315] Request job id: 171
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '129', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:11:40 [loggers.py:123] Engine 000: Avg prompt throughput: 29039.5 tokens/s, Avg generation throughput: 122.7 tokens/s, Running: 60 reqs, Waiting: 30 reqs, GPU KV cache usage: 94.7%, Prefix cache hit rate: 25.5%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:41,191] LMCache INFO:[0m Storing KV cache for 8192 out of 44544 tokens (skip_leading_tokens=36352) for request chatcmpl-37efa5796fc543b29779ee394f908f07 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:41,215] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.0435 ms, throughput: 43.3962 GB/s; offload_time: 22.9936 ms, put_time: 0.0499 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:41 [estimate_with_func.py:307] Request job id arriving: 129, time is 1761207101.2180724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:41 [estimate_with_func.py:315] Request job id: 129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,123] LMCache INFO:[0m Storing KV cache for 7936 out of 52480 tokens (skip_leading_tokens=44544) for request chatcmpl-37efa5796fc543b29779ee394f908f07 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,147] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.5108 ms, throughput: 43.0348 GB/s; offload_time: 22.4604 ms, put_time: 0.0504 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [estimate_with_func.py:328] Request job id finishing: 93, time is 1761207102.149718
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1462] Request GPU size bytes: 2116550656
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1463] Token size of the request: 16134
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1469] Swap waste for job 93: 0.06570638020833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1479] Accumulated tokens for job 93: 1102956
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1481] Discard waste for job 93: 980.9331787865016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1484] Preserve waste for job 93: 1.0526479690305648
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,152] LMCache INFO:[0m Reqid: chatcmpl-81b1a170cb2443298b417b577abb38e0, Total tokens 5923, LMCache hit tokens: 3840, need to load: 3824 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,155] LMCache INFO:[0m Reqid: chatcmpl-aba60e3dbe2b4d75a474a9e913494290, Total tokens 17955, LMCache hit tokens: 9984, need to load: 9968 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,174] LMCache INFO:[0m Retrieved 3840 out of 3840 required tokens (from 3840 total tokens). size: 0.4688 gb, cost 10.2916 ms, throughput: 45.5469 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,200] LMCache INFO:[0m Retrieved 9984 out of 9984 required tokens (from 9984 total tokens). size: 1.2188 gb, cost 26.0628 ms, throughput: 46.7620 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,817] LMCache INFO:[0m Storing KV cache for 2083 out of 5923 tokens (skip_leading_tokens=3840) for request chatcmpl-81b1a170cb2443298b417b577abb38e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,823] LMCache INFO:[0m Stored 2083 out of total 2083 tokens. size: 0.2543 gb, cost 5.8080 ms, throughput: 43.7799 GB/s; offload_time: 5.7925 ms, put_time: 0.0155 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,823] LMCache INFO:[0m Storing KV cache for 2816 out of 12800 tokens (skip_leading_tokens=9984) for request chatcmpl-aba60e3dbe2b4d75a474a9e913494290 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,831] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 7.6001 ms, throughput: 45.2297 GB/s; offload_time: 7.5826 ms, put_time: 0.0175 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,832] LMCache INFO:[0m Storing KV cache for 3373 out of 55853 tokens (skip_leading_tokens=52480) for request chatcmpl-37efa5796fc543b29779ee394f908f07 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,842] LMCache INFO:[0m Stored 3373 out of total 3373 tokens. size: 0.4117 gb, cost 10.6322 ms, throughput: 38.7262 GB/s; offload_time: 10.6104 ms, put_time: 0.0218 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '93', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58840 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207102.8480365
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1462] Request GPU size bytes: 1124859904
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1463] Token size of the request: 8564
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1469] Swap waste for job 68: 0.03492024739583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1479] Accumulated tokens for job 68: 1110700
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1481] Discard waste for job 68: 994.632638664303
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [scheduler.py:1484] Preserve waste for job 68: 3.0756125056627885
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [estimate_with_func.py:307] Request job id arriving: 93, time is 1761207102.848979
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:42 [estimate_with_func.py:315] Request job id: 93
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,851] LMCache INFO:[0m Reqid: chatcmpl-0f1f692149d946b9877bed040d32434b, Total tokens 8023, LMCache hit tokens: 5632, need to load: 5616 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,854] LMCache INFO:[0m Reqid: chatcmpl-9d82e619a2a645b289cc7a03cee7093d, Total tokens 9652, LMCache hit tokens: 6400, need to load: 6384 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,871] LMCache INFO:[0m Retrieved 5632 out of 5632 required tokens (from 5632 total tokens). size: 0.6875 gb, cost 14.7909 ms, throughput: 46.4813 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:42,888] LMCache INFO:[0m Retrieved 6400 out of 6400 required tokens (from 6400 total tokens). size: 0.7812 gb, cost 16.7396 ms, throughput: 46.6707 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,327] LMCache INFO:[0m Storing KV cache for 2391 out of 8023 tokens (skip_leading_tokens=5632) for request chatcmpl-0f1f692149d946b9877bed040d32434b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,333] LMCache INFO:[0m Stored 2391 out of total 2391 tokens. size: 0.2919 gb, cost 6.6342 ms, throughput: 43.9950 GB/s; offload_time: 6.6114 ms, put_time: 0.0228 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,334] LMCache INFO:[0m Storing KV cache for 512 out of 6912 tokens (skip_leading_tokens=6400) for request chatcmpl-9d82e619a2a645b289cc7a03cee7093d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,335] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.4846 ms, throughput: 42.1000 GB/s; offload_time: 1.4765 ms, put_time: 0.0080 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,335] LMCache INFO:[0m Storing KV cache for 5155 out of 17955 tokens (skip_leading_tokens=12800) for request chatcmpl-aba60e3dbe2b4d75a474a9e913494290 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,349] LMCache INFO:[0m Stored 5155 out of total 5155 tokens. size: 0.6293 gb, cost 13.9034 ms, throughput: 45.2603 GB/s; offload_time: 13.8751 ms, put_time: 0.0283 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [estimate_with_func.py:328] Request job id finishing: 140, time is 1761207103.3521152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1462] Request GPU size bytes: 173801472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1463] Token size of the request: 1103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1469] Swap waste for job 140: 0.0053955078125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1479] Accumulated tokens for job 140: 1119811
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1481] Discard waste for job 140: 1010.8720005614335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1484] Preserve waste for job 140: 3.0756125056627885
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [estimate_with_func.py:328] Request job id finishing: 111, time is 1761207103.3525
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1462] Request GPU size bytes: 7262306304
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1463] Token size of the request: 55388
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1469] Swap waste for job 111: 0.22545166015625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1479] Accumulated tokens for job 111: 1119811
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1481] Discard waste for job 111: 1010.8720005614335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1484] Preserve waste for job 111: 1.050382675268711
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,355] LMCache INFO:[0m Reqid: chatcmpl-28cb602466fe4aa0bd19b483345222ca, Total tokens 12151, LMCache hit tokens: 4352, need to load: 4336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,370] LMCache INFO:[0m Retrieved 4352 out of 4352 required tokens (from 4352 total tokens). size: 0.5312 gb, cost 11.4785 ms, throughput: 46.2820 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,749] LMCache INFO:[0m Storing KV cache for 5376 out of 9728 tokens (skip_leading_tokens=4352) for request chatcmpl-28cb602466fe4aa0bd19b483345222ca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,764] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 14.3466 ms, throughput: 45.7427 GB/s; offload_time: 14.3084 ms, put_time: 0.0381 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,764] LMCache INFO:[0m Storing KV cache for 2740 out of 9652 tokens (skip_leading_tokens=6912) for request chatcmpl-9d82e619a2a645b289cc7a03cee7093d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,771] LMCache INFO:[0m Stored 2740 out of total 2740 tokens. size: 0.3345 gb, cost 7.4463 ms, throughput: 44.9177 GB/s; offload_time: 7.4289 ms, put_time: 0.0174 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [estimate_with_func.py:328] Request job id finishing: 11, time is 1761207103.774288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1462] Request GPU size bytes: 978452480
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1463] Token size of the request: 7339
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1469] Swap waste for job 11: 0.030375162760416668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1479] Accumulated tokens for job 11: 1075471
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1481] Discard waste for job 11: 933.0779185645729
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:43 [scheduler.py:1484] Preserve waste for job 11: 3.0756125056627885
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,777] LMCache INFO:[0m Reqid: chatcmpl-d02ea8e7b947448b940b9a7e4b3ddfa2, Total tokens 19949, LMCache hit tokens: 13056, need to load: 13040 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:43,817] LMCache INFO:[0m Retrieved 13056 out of 13056 required tokens (from 13056 total tokens). size: 1.5938 gb, cost 34.1430 ms, throughput: 46.6787 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:44,290] LMCache INFO:[0m Storing KV cache for 5888 out of 18944 tokens (skip_leading_tokens=13056) for request chatcmpl-d02ea8e7b947448b940b9a7e4b3ddfa2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:44,306] LMCache INFO:[0m Stored 5888 out of total 5888 tokens. size: 0.7188 gb, cost 15.9078 ms, throughput: 45.1822 GB/s; offload_time: 15.8741 ms, put_time: 0.0338 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:44,306] LMCache INFO:[0m Storing KV cache for 2423 out of 12151 tokens (skip_leading_tokens=9728) for request chatcmpl-28cb602466fe4aa0bd19b483345222ca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:44,313] LMCache INFO:[0m Stored 2423 out of total 2423 tokens. size: 0.2958 gb, cost 6.6330 ms, throughput: 44.5914 GB/s; offload_time: 6.6159 ms, put_time: 0.0171 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:44,319] LMCache INFO:[0m Reqid: chatcmpl-803f4140c62346268cf8dfba363706c9, Total tokens 35368, LMCache hit tokens: 22016, need to load: 22000 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:44,394] LMCache INFO:[0m Retrieved 22016 out of 22016 required tokens (from 22016 total tokens). size: 2.6875 gb, cost 57.4524 ms, throughput: 46.7778 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '111', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:44,988] LMCache INFO:[0m Storing KV cache for 6912 out of 28928 tokens (skip_leading_tokens=22016) for request chatcmpl-803f4140c62346268cf8dfba363706c9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,007] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 18.7109 ms, throughput: 45.0941 GB/s; offload_time: 18.6730 ms, put_time: 0.0379 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,008] LMCache INFO:[0m Storing KV cache for 1005 out of 19949 tokens (skip_leading_tokens=18944) for request chatcmpl-d02ea8e7b947448b940b9a7e4b3ddfa2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,011] LMCache INFO:[0m Stored 1005 out of total 1005 tokens. size: 0.1227 gb, cost 3.1010 ms, throughput: 39.5612 GB/s; offload_time: 3.0903 ms, put_time: 0.0108 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:45 [estimate_with_func.py:328] Request job id finishing: 30, time is 1761207105.0135787
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:45 [estimate_with_func.py:307] Request job id arriving: 111, time is 1761207105.0145252
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:45 [estimate_with_func.py:315] Request job id: 111
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,018] LMCache INFO:[0m Reqid: chatcmpl-cced64e962c6440ea9e926ca03f684f5, Total tokens 24186, LMCache hit tokens: 16384, need to load: 16368 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,068] LMCache INFO:[0m Retrieved 16384 out of 16384 required tokens (from 16384 total tokens). size: 2.0000 gb, cost 43.1640 ms, throughput: 46.3349 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '140', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59118 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,720] LMCache INFO:[0m Storing KV cache for 1792 out of 18176 tokens (skip_leading_tokens=16384) for request chatcmpl-cced64e962c6440ea9e926ca03f684f5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,726] LMCache INFO:[0m Stored 1792 out of total 1792 tokens. size: 0.2188 gb, cost 5.3230 ms, throughput: 41.0954 GB/s; offload_time: 5.2947 ms, put_time: 0.0282 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,726] LMCache INFO:[0m Storing KV cache for 6440 out of 35368 tokens (skip_leading_tokens=28928) for request chatcmpl-803f4140c62346268cf8dfba363706c9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,745] LMCache INFO:[0m Stored 6440 out of total 6440 tokens. size: 0.7861 gb, cost 18.3131 ms, throughput: 42.9273 GB/s; offload_time: 18.2744 ms, put_time: 0.0387 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:45 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207105.74858
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:45 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:45 [estimate_with_func.py:307] Request job id arriving: 140, time is 1761207105.749109
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:45 [estimate_with_func.py:315] Request job id: 140
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:45,752] LMCache INFO:[0m Reqid: chatcmpl-c87fe65dc804416d8e064f0241e75b4c, Total tokens 5274, LMCache hit tokens: 2816, need to load: 2800 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,210] LMCache INFO:[0m Storing KV cache for 6010 out of 24186 tokens (skip_leading_tokens=18176) for request chatcmpl-cced64e962c6440ea9e926ca03f684f5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,226] LMCache INFO:[0m Stored 6010 out of total 6010 tokens. size: 0.7336 gb, cost 16.5140 ms, throughput: 44.4254 GB/s; offload_time: 16.4730 ms, put_time: 0.0410 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,232] LMCache INFO:[0m Reqid: chatcmpl-c87fe65dc804416d8e064f0241e75b4c, Total tokens 5274, LMCache hit tokens: 2816, need to load: 2800 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '11', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:328] Request job id finishing: 104, time is 1761207106.313456
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1462] Request GPU size bytes: 351797248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1463] Token size of the request: 2539
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1469] Swap waste for job 104: 0.010921223958333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1479] Accumulated tokens for job 104: 1144078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1481] Discard waste for job 104: 1054.7667711660556
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1484] Preserve waste for job 104: 1.0542788915573411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:328] Request job id finishing: 127, time is 1761207106.3139148
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1462] Request GPU size bytes: 1769865216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1463] Token size of the request: 13490
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1469] Swap waste for job 127: 0.05494384765625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1479] Accumulated tokens for job 127: 1144078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1481] Discard waste for job 127: 1054.7667711660556
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1484] Preserve waste for job 127: 1.0542788915573411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:307] Request job id arriving: 11, time is 1761207106.314306
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:315] Request job id: 11
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,316] LMCache INFO:[0m Reqid: chatcmpl-c87fe65dc804416d8e064f0241e75b4c, Total tokens 5274, LMCache hit tokens: 2816, need to load: 2800 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,318] LMCache INFO:[0m Reqid: chatcmpl-7cca4c3f91194f459b45ad075e5e6ed7, Total tokens 19673, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,329] LMCache INFO:[0m Retrieved 2816 out of 2816 required tokens (from 2816 total tokens). size: 0.3438 gb, cost 7.5489 ms, throughput: 45.5365 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '127', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:43098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '104', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,659] LMCache INFO:[0m Storing KV cache for 2458 out of 5274 tokens (skip_leading_tokens=2816) for request chatcmpl-c87fe65dc804416d8e064f0241e75b4c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,666] LMCache INFO:[0m Stored 2458 out of total 2458 tokens. size: 0.3000 gb, cost 6.8714 ms, throughput: 43.6664 GB/s; offload_time: 6.8496 ms, put_time: 0.0217 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,666] LMCache INFO:[0m Storing KV cache for 5632 out of 5632 tokens (skip_leading_tokens=0) for request chatcmpl-7cca4c3f91194f459b45ad075e5e6ed7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:46,681] LMCache INFO:[0m Stored 5632 out of total 5632 tokens. size: 0.6875 gb, cost 14.8712 ms, throughput: 46.2304 GB/s; offload_time: 14.8410 ms, put_time: 0.0302 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207106.684455
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1462] Request GPU size bytes: 2100822016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1463] Token size of the request: 15969
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1469] Swap waste for job 156: 0.06521809895833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1479] Accumulated tokens for job 156: 1152996
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1481] Discard waste for job 156: 1071.1322607675388
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1484] Preserve waste for job 156: 1.0542788915573411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:328] Request job id finishing: 169, time is 1761207106.684994
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1462] Request GPU size bytes: 3624402944
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1463] Token size of the request: 27639
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1469] Swap waste for job 169: 0.11251627604166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1479] Accumulated tokens for job 169: 1152996
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1481] Discard waste for job 169: 1071.1322607675388
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [scheduler.py:1484] Preserve waste for job 169: 1.0542788915573411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:307] Request job id arriving: 127, time is 1761207106.6855874
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:315] Request job id: 127
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:307] Request job id arriving: 104, time is 1761207106.6857092
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:46 [estimate_with_func.py:315] Request job id: 104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,104] LMCache INFO:[0m Storing KV cache for 7936 out of 13568 tokens (skip_leading_tokens=5632) for request chatcmpl-7cca4c3f91194f459b45ad075e5e6ed7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,126] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.4543 ms, throughput: 45.1542 GB/s; offload_time: 21.3913 ms, put_time: 0.0630 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [estimate_with_func.py:328] Request job id finishing: 39, time is 1761207107.1290598
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207107.1301253
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [scheduler.py:1462] Request GPU size bytes: 1587544064
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [scheduler.py:1463] Token size of the request: 12071
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [scheduler.py:1469] Swap waste for job 133: 0.04928385416666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [scheduler.py:1479] Accumulated tokens for job 133: 1109388
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [scheduler.py:1481] Discard waste for job 133: 992.3049724046296
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:47 [scheduler.py:1484] Preserve waste for job 133: 1.0456961940669414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,133] LMCache INFO:[0m Reqid: chatcmpl-34432191db944a91934d8ef347b58aa5, Total tokens 11714, LMCache hit tokens: 8448, need to load: 8432 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,160] LMCache INFO:[0m Retrieved 8448 out of 8448 required tokens (from 8448 total tokens). size: 1.0312 gb, cost 22.1584 ms, throughput: 46.5399 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,617] LMCache INFO:[0m Storing KV cache for 2048 out of 10496 tokens (skip_leading_tokens=8448) for request chatcmpl-34432191db944a91934d8ef347b58aa5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,623] LMCache INFO:[0m Stored 2048 out of total 2048 tokens. size: 0.2500 gb, cost 5.8321 ms, throughput: 42.8659 GB/s; offload_time: 5.8095 ms, put_time: 0.0226 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,623] LMCache INFO:[0m Storing KV cache for 6105 out of 19673 tokens (skip_leading_tokens=13568) for request chatcmpl-7cca4c3f91194f459b45ad075e5e6ed7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,640] LMCache INFO:[0m Stored 6105 out of total 6105 tokens. size: 0.7452 gb, cost 16.4645 ms, throughput: 45.2633 GB/s; offload_time: 16.4287 ms, put_time: 0.0359 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,645] LMCache INFO:[0m Reqid: chatcmpl-68229ffc7cbb493790bd4e96be48932d, Total tokens 27780, LMCache hit tokens: 16384, need to load: 16368 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:47,695] LMCache INFO:[0m Retrieved 16384 out of 16384 required tokens (from 16384 total tokens). size: 2.0000 gb, cost 42.7896 ms, throughput: 46.7404 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:48,212] LMCache INFO:[0m Storing KV cache for 6912 out of 23296 tokens (skip_leading_tokens=16384) for request chatcmpl-68229ffc7cbb493790bd4e96be48932d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '169', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:48,235] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 22.7639 ms, throughput: 37.0652 GB/s; offload_time: 22.7122 ms, put_time: 0.0517 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:48,236] LMCache INFO:[0m Storing KV cache for 1218 out of 11714 tokens (skip_leading_tokens=10496) for request chatcmpl-34432191db944a91934d8ef347b58aa5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:48,239] LMCache INFO:[0m Stored 1218 out of total 1218 tokens. size: 0.1487 gb, cost 3.5450 ms, throughput: 41.9412 GB/s; offload_time: 3.5342 ms, put_time: 0.0108 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207108.2426164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [scheduler.py:1462] Request GPU size bytes: 4325244928
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [scheduler.py:1463] Token size of the request: 32981
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [scheduler.py:1469] Swap waste for job 16: 0.13427327473958334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [scheduler.py:1479] Accumulated tokens for job 16: 1059875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [scheduler.py:1481] Discard waste for job 16: 906.4552112317609
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [scheduler.py:1484] Preserve waste for job 16: 3.0689670606092974
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [estimate_with_func.py:307] Request job id arriving: 169, time is 1761207108.2434947
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:48 [estimate_with_func.py:315] Request job id: 169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:48,247] LMCache INFO:[0m Reqid: chatcmpl-0d15cb4d1c534d9ca4b6dc71dfc7a5c1, Total tokens 62320, LMCache hit tokens: 44544, need to load: 44528 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:48,376] LMCache INFO:[0m Retrieved 44544 out of 44544 required tokens (from 44544 total tokens). size: 5.4375 gb, cost 116.9721 ms, throughput: 46.4854 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:49,097] LMCache INFO:[0m Storing KV cache for 3840 out of 48384 tokens (skip_leading_tokens=44544) for request chatcmpl-0d15cb4d1c534d9ca4b6dc71dfc7a5c1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:49,110] LMCache INFO:[0m Stored 3840 out of total 3840 tokens. size: 0.4688 gb, cost 11.4491 ms, throughput: 40.9421 GB/s; offload_time: 11.4211 ms, put_time: 0.0280 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:49,110] LMCache INFO:[0m Storing KV cache for 4484 out of 27780 tokens (skip_leading_tokens=23296) for request chatcmpl-68229ffc7cbb493790bd4e96be48932d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:49,122] LMCache INFO:[0m Stored 4484 out of total 4484 tokens. size: 0.5474 gb, cost 12.3239 ms, throughput: 44.4146 GB/s; offload_time: 12.2977 ms, put_time: 0.0262 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [estimate_with_func.py:328] Request job id finishing: 77, time is 1761207109.1253166
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [scheduler.py:1462] Request GPU size bytes: 1131020288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [scheduler.py:1463] Token size of the request: 8510
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [scheduler.py:1469] Swap waste for job 77: 0.035111490885416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [scheduler.py:1479] Accumulated tokens for job 77: 1089214
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [scheduler.py:1481] Discard waste for job 77: 956.8568479411839
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [scheduler.py:1484] Preserve waste for job 77: 3.0689670606092974
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207109.126423
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:49 [estimate_with_func.py:315] Request job id: 133
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '77', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,069] LMCache INFO:[0m Storing KV cache for 7936 out of 56320 tokens (skip_leading_tokens=48384) for request chatcmpl-0d15cb4d1c534d9ca4b6dc71dfc7a5c1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,093] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.7145 ms, throughput: 42.6490 GB/s; offload_time: 22.6653 ms, put_time: 0.0492 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207110.0957882
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1462] Request GPU size bytes: 575143936
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1463] Token size of the request: 4213
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1469] Swap waste for job 97: 0.017854817708333335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1479] Accumulated tokens for job 97: 1080704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1481] Discard waste for job 97: 942.0970869530572
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1484] Preserve waste for job 97: 3.0689670606092974
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [estimate_with_func.py:307] Request job id arriving: 77, time is 1761207110.0967293
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [estimate_with_func.py:315] Request job id: 77
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,099] LMCache INFO:[0m Reqid: chatcmpl-d91da283c04342ae9723f3001e07779c, Total tokens 15392, LMCache hit tokens: 6144, need to load: 6128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,120] LMCache INFO:[0m Retrieved 6144 out of 6144 required tokens (from 6144 total tokens). size: 0.7500 gb, cost 16.3204 ms, throughput: 45.9547 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:11:50 [loggers.py:123] Engine 000: Avg prompt throughput: 25347.5 tokens/s, Avg generation throughput: 95.9 tokens/s, Running: 58 reqs, Waiting: 29 reqs, GPU KV cache usage: 93.5%, Prefix cache hit rate: 23.7%
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,952] LMCache INFO:[0m Storing KV cache for 2304 out of 8448 tokens (skip_leading_tokens=6144) for request chatcmpl-d91da283c04342ae9723f3001e07779c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,958] LMCache INFO:[0m Stored 2304 out of total 2304 tokens. size: 0.2812 gb, cost 6.3877 ms, throughput: 44.0297 GB/s; offload_time: 6.3677 ms, put_time: 0.0200 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,959] LMCache INFO:[0m Storing KV cache for 6000 out of 62320 tokens (skip_leading_tokens=56320) for request chatcmpl-0d15cb4d1c534d9ca4b6dc71dfc7a5c1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,977] LMCache INFO:[0m Stored 6000 out of total 6000 tokens. size: 0.7324 gb, cost 17.2602 ms, throughput: 42.4341 GB/s; offload_time: 17.2299 ms, put_time: 0.0303 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [estimate_with_func.py:328] Request job id finishing: 103, time is 1761207110.9793901
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1462] Request GPU size bytes: 1206255616
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1463] Token size of the request: 9082
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1469] Swap waste for job 103: 0.03744710286458333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1479] Accumulated tokens for job 103: 1091883
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1481] Discard waste for job 103: 961.5095971194769
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1484] Preserve waste for job 103: 3.0589787233443486
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [estimate_with_func.py:328] Request job id finishing: 126, time is 1761207110.9797974
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1462] Request GPU size bytes: 556793856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1463] Token size of the request: 4205
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1469] Swap waste for job 126: 0.01728515625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1479] Accumulated tokens for job 126: 1091883
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1481] Discard waste for job 126: 961.5095971194769
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [scheduler.py:1484] Preserve waste for job 126: 3.0589787233443486
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207110.9805725
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:50 [estimate_with_func.py:315] Request job id: 16
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:50,984] LMCache INFO:[0m Reqid: chatcmpl-ff04b9ab19e4414db1e60b8dd1e0ca80, Total tokens 62925, LMCache hit tokens: 33024, need to load: 33008 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:51,082] LMCache INFO:[0m Retrieved 33024 out of 33024 required tokens (from 33024 total tokens). size: 4.0312 gb, cost 86.7681 ms, throughput: 46.4601 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:51,560] LMCache INFO:[0m Storing KV cache for 1024 out of 34048 tokens (skip_leading_tokens=33024) for request chatcmpl-ff04b9ab19e4414db1e60b8dd1e0ca80 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:51,564] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 3.6741 ms, throughput: 34.0217 GB/s; offload_time: 3.6568 ms, put_time: 0.0173 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:51,565] LMCache INFO:[0m Storing KV cache for 6944 out of 15392 tokens (skip_leading_tokens=8448) for request chatcmpl-d91da283c04342ae9723f3001e07779c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:51,584] LMCache INFO:[0m Stored 6944 out of total 6944 tokens. size: 0.8477 gb, cost 19.0242 ms, throughput: 44.5567 GB/s; offload_time: 18.9854 ms, put_time: 0.0388 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:51 [estimate_with_func.py:328] Request job id finishing: 166, time is 1761207111.5865624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:52,374] LMCache INFO:[0m Storing KV cache for 8192 out of 42240 tokens (skip_leading_tokens=34048) for request chatcmpl-ff04b9ab19e4414db1e60b8dd1e0ca80 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:52,397] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.0114 ms, throughput: 43.4568 GB/s; offload_time: 22.9639 ms, put_time: 0.0475 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:53,279] LMCache INFO:[0m Storing KV cache for 8192 out of 50432 tokens (skip_leading_tokens=42240) for request chatcmpl-ff04b9ab19e4414db1e60b8dd1e0ca80 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:53,304] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.1664 ms, throughput: 43.1660 GB/s; offload_time: 23.1245 ms, put_time: 0.0419 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:53 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207113.3069532
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:53 [estimate_with_func.py:315] Request job id: 97
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '103', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:54,292] LMCache INFO:[0m Storing KV cache for 8192 out of 58624 tokens (skip_leading_tokens=50432) for request chatcmpl-ff04b9ab19e4414db1e60b8dd1e0ca80 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:54,316] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.3699 ms, throughput: 42.7901 GB/s; offload_time: 23.3257 ms, put_time: 0.0442 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:54 [estimate_with_func.py:307] Request job id arriving: 103, time is 1761207114.319732
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:54 [estimate_with_func.py:315] Request job id: 103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:54,322] LMCache INFO:[0m Reqid: chatcmpl-3063fb534066493ab349e7c37faee117, Total tokens 5689, LMCache hit tokens: 2816, need to load: 2800 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:54,324] LMCache INFO:[0m Reqid: chatcmpl-74cfb4cc6e794c608d6c5c9020210104, Total tokens 12012, LMCache hit tokens: 8192, need to load: 8176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:54,335] LMCache INFO:[0m Retrieved 2816 out of 2816 required tokens (from 2816 total tokens). size: 0.3438 gb, cost 7.6290 ms, throughput: 45.0583 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,021] LMCache INFO:[0m Storing KV cache for 2873 out of 5689 tokens (skip_leading_tokens=2816) for request chatcmpl-3063fb534066493ab349e7c37faee117 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,029] LMCache INFO:[0m Stored 2873 out of total 2873 tokens. size: 0.3507 gb, cost 8.2452 ms, throughput: 42.5347 GB/s; offload_time: 8.2102 ms, put_time: 0.0350 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,030] LMCache INFO:[0m Storing KV cache for 4301 out of 62925 tokens (skip_leading_tokens=58624) for request chatcmpl-ff04b9ab19e4414db1e60b8dd1e0ca80 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,044] LMCache INFO:[0m Stored 4301 out of total 4301 tokens. size: 0.5250 gb, cost 13.6421 ms, throughput: 38.4856 GB/s; offload_time: 13.6113 ms, put_time: 0.0308 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207115.0475922
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1462] Request GPU size bytes: 4637720576
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1463] Token size of the request: 35368
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1469] Swap waste for job 44: 0.14397379557291667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1479] Accumulated tokens for job 44: 1145017
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1481] Discard waste for job 44: 1056.4840034331346
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1484] Preserve waste for job 44: 1.0547861342104325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,051] LMCache INFO:[0m Reqid: chatcmpl-74cfb4cc6e794c608d6c5c9020210104, Total tokens 12012, LMCache hit tokens: 8192, need to load: 8176 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,056] LMCache INFO:[0m Reqid: chatcmpl-389e2b4c73734e37af0332a1ac13edcd, Total tokens 8764, LMCache hit tokens: 4352, need to load: 4336 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,082] LMCache INFO:[0m Retrieved 8192 out of 8192 required tokens (from 8192 total tokens). size: 1.0000 gb, cost 21.5364 ms, throughput: 46.4330 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,093] LMCache INFO:[0m Retrieved 4352 out of 4352 required tokens (from 4352 total tokens). size: 0.5312 gb, cost 11.4411 ms, throughput: 46.4336 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,481] LMCache INFO:[0m Storing KV cache for 3820 out of 12012 tokens (skip_leading_tokens=8192) for request chatcmpl-74cfb4cc6e794c608d6c5c9020210104 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,491] LMCache INFO:[0m Stored 3820 out of total 3820 tokens. size: 0.4663 gb, cost 10.5172 ms, throughput: 44.3379 GB/s; offload_time: 10.4907 ms, put_time: 0.0265 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,491] LMCache INFO:[0m Storing KV cache for 4096 out of 8448 tokens (skip_leading_tokens=4352) for request chatcmpl-389e2b4c73734e37af0332a1ac13edcd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,503] LMCache INFO:[0m Stored 4096 out of total 4096 tokens. size: 0.5000 gb, cost 10.9820 ms, throughput: 45.5291 GB/s; offload_time: 10.9541 ms, put_time: 0.0278 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [estimate_with_func.py:328] Request job id finishing: 117, time is 1761207115.5057216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1462] Request GPU size bytes: 1054212096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1463] Token size of the request: 8023
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1469] Swap waste for job 117: 0.03272705078125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1479] Accumulated tokens for job 117: 1130425
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1481] Discard waste for job 117: 1029.9561065460864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1484] Preserve waste for job 117: 3.059507233436119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207115.5060854
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1462] Request GPU size bytes: 1595015168
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1463] Token size of the request: 12151
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1469] Swap waste for job 173: 0.049515787760416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1479] Accumulated tokens for job 173: 1130425
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1481] Discard waste for job 173: 1029.9561065460864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1484] Preserve waste for job 173: 1.0547861342104325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,509] LMCache INFO:[0m Reqid: chatcmpl-b3221c4e0e3849df8acad80db2c51ab1, Total tokens 49286, LMCache hit tokens: 33024, need to load: 33008 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,683] LMCache INFO:[0m Storing KV cache for 316 out of 8764 tokens (skip_leading_tokens=8448) for request chatcmpl-389e2b4c73734e37af0332a1ac13edcd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,684] LMCache INFO:[0m Stored 316 out of total 316 tokens. size: 0.0386 gb, cost 1.3270 ms, throughput: 29.0691 GB/s; offload_time: 1.3111 ms, put_time: 0.0159 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [estimate_with_func.py:328] Request job id finishing: 89, time is 1761207115.687049
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,690] LMCache INFO:[0m Reqid: chatcmpl-b3221c4e0e3849df8acad80db2c51ab1, Total tokens 49286, LMCache hit tokens: 33024, need to load: 33008 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,768] LMCache INFO:[0m Reqid: chatcmpl-b3221c4e0e3849df8acad80db2c51ab1, Total tokens 49286, LMCache hit tokens: 33024, need to load: 33008 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207115.8399475
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1462] Request GPU size bytes: 3715629056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1463] Token size of the request: 28278
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1469] Swap waste for job 138: 0.11534830729166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1479] Accumulated tokens for job 138: 1106154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1481] Discard waste for job 138: 986.579060577555
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1484] Preserve waste for job 138: 3.059507233436119
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [estimate_with_func.py:328] Request job id finishing: 15, time is 1761207115.8405707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1462] Request GPU size bytes: 1537081344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1463] Token size of the request: 11714
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1469] Swap waste for job 15: 0.04771728515625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1479] Accumulated tokens for job 15: 1106154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1481] Discard waste for job 15: 986.579060577555
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:55 [scheduler.py:1484] Preserve waste for job 15: 1.0547861342104325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:55,843] LMCache INFO:[0m Reqid: chatcmpl-b3221c4e0e3849df8acad80db2c51ab1, Total tokens 49286, LMCache hit tokens: 33024, need to load: 33008 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:56,096] LMCache INFO:[0m Retrieved 33024 out of 33024 required tokens (from 33024 total tokens). size: 4.0312 gb, cost 88.0601 ms, throughput: 45.7784 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '126', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34128 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '15', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:56,852] LMCache INFO:[0m Storing KV cache for 7936 out of 40960 tokens (skip_leading_tokens=33024) for request chatcmpl-b3221c4e0e3849df8acad80db2c51ab1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:56,875] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.4392 ms, throughput: 43.1722 GB/s; offload_time: 22.3917 ms, put_time: 0.0475 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207116.878439
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:315] Request job id: 173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207116.8786278
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:315] Request job id: 44
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:307] Request job id arriving: 126, time is 1761207116.8787131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:315] Request job id: 126
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:307] Request job id arriving: 15, time is 1761207116.8788009
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:56 [estimate_with_func.py:315] Request job id: 15
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:56,882] LMCache INFO:[0m Reqid: chatcmpl-a7679b5cd3d947e887a885ae083517ba, Total tokens 20548, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:57,741] LMCache INFO:[0m Storing KV cache for 8326 out of 49286 tokens (skip_leading_tokens=40960) for request chatcmpl-b3221c4e0e3849df8acad80db2c51ab1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:57,766] LMCache INFO:[0m Stored 8326 out of total 8326 tokens. size: 1.0164 gb, cost 24.2658 ms, throughput: 41.8844 GB/s; offload_time: 24.2151 ms, put_time: 0.0507 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,117] LMCache INFO:[0m Storing KV cache for 7936 out of 7936 tokens (skip_leading_tokens=0) for request chatcmpl-a7679b5cd3d947e887a885ae083517ba [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,138] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.0389 ms, throughput: 46.0456 GB/s; offload_time: 20.9908 ms, put_time: 0.0482 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '117', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,595] LMCache INFO:[0m Storing KV cache for 8192 out of 16128 tokens (skip_leading_tokens=7936) for request chatcmpl-a7679b5cd3d947e887a885ae083517ba [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,618] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.8798 ms, throughput: 45.7043 GB/s; offload_time: 21.8367 ms, put_time: 0.0431 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [estimate_with_func.py:328] Request job id finishing: 144, time is 1761207118.6206963
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [scheduler.py:1462] Request GPU size bytes: 3643277312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [scheduler.py:1463] Token size of the request: 27780
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [scheduler.py:1469] Swap waste for job 144: 0.11310221354166666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [scheduler.py:1479] Accumulated tokens for job 144: 1135996
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [scheduler.py:1481] Discard waste for job 144: 1040.044245466358
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [scheduler.py:1484] Preserve waste for job 144: 3.072775603454804
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [estimate_with_func.py:307] Request job id arriving: 117, time is 1761207118.6213984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [estimate_with_func.py:315] Request job id: 117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207118.6215348
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:58 [estimate_with_func.py:315] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,626] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,979] LMCache INFO:[0m Storing KV cache for 4420 out of 20548 tokens (skip_leading_tokens=16128) for request chatcmpl-a7679b5cd3d947e887a885ae083517ba [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,991] LMCache INFO:[0m Stored 4420 out of total 4420 tokens. size: 0.5396 gb, cost 12.0048 ms, throughput: 44.9446 GB/s; offload_time: 11.9798 ms, put_time: 0.0250 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:58,997] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,073] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,146] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,218] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [estimate_with_func.py:328] Request job id finishing: 106, time is 1761207119.2879858
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [estimate_with_func.py:328] Request job id finishing: 32, time is 1761207119.2883582
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1462] Request GPU size bytes: 694550528
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1463] Token size of the request: 5274
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1469] Swap waste for job 32: 0.021561686197916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1479] Accumulated tokens for job 32: 1108216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1481] Discard waste for job 32: 990.2279908304414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1484] Preserve waste for job 32: 1.061355132882188
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,291] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [estimate_with_func.py:328] Request job id finishing: 110, time is 1761207119.3589723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1462] Request GPU size bytes: 562298880
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1463] Token size of the request: 4220
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1469] Swap waste for job 110: 0.0174560546875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1479] Accumulated tokens for job 110: 1093077
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1481] Discard waste for job 110: 963.5946972654308
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1484] Preserve waste for job 110: 3.071625819912663
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,362] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,434] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,505] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,577] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,648] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [estimate_with_func.py:328] Request job id finishing: 119, time is 1761207119.7180905
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1462] Request GPU size bytes: 748290048
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1463] Token size of the request: 5689
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1469] Swap waste for job 119: 0.02322998046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1479] Accumulated tokens for job 119: 1088857
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1481] Discard waste for job 119: 956.2353612612213
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:11:59 [scheduler.py:1484] Preserve waste for job 119: 1.061355132882188
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,721] LMCache INFO:[0m Reqid: chatcmpl-e57568ebd5094644b4b7c9c06588b7ca, Total tokens 70021, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '32', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:11:59,865] LMCache INFO:[0m Retrieved 50176 out of 50176 required tokens (from 50176 total tokens). size: 6.1250 gb, cost 131.7736 ms, throughput: 46.4812 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '119', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:53286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:12:00 [loggers.py:123] Engine 000: Avg prompt throughput: 23691.5 tokens/s, Avg generation throughput: 137.5 tokens/s, Running: 51 reqs, Waiting: 32 reqs, GPU KV cache usage: 94.6%, Prefix cache hit rate: 18.4%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:00,837] LMCache INFO:[0m Storing KV cache for 7936 out of 58112 tokens (skip_leading_tokens=50176) for request chatcmpl-e57568ebd5094644b4b7c9c06588b7ca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:00,861] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 23.0892 ms, throughput: 41.9568 GB/s; offload_time: 23.0320 ms, put_time: 0.0572 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207120.8644242
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [scheduler.py:1462] Request GPU size bytes: 2358509568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [scheduler.py:1463] Token size of the request: 17955
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [scheduler.py:1469] Swap waste for job 7: 0.0732177734375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [scheduler.py:1479] Accumulated tokens for job 7: 1153189
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [scheduler.py:1481] Discard waste for job 7: 1071.4878291789853
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [scheduler.py:1484] Preserve waste for job 7: 1.061355132882188
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [estimate_with_func.py:307] Request job id arriving: 32, time is 1761207120.8651845
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [estimate_with_func.py:315] Request job id: 32
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [estimate_with_func.py:307] Request job id arriving: 119, time is 1761207120.8653784
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:00 [estimate_with_func.py:315] Request job id: 119
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '7', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:39140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:01,946] LMCache INFO:[0m Storing KV cache for 8192 out of 66304 tokens (skip_leading_tokens=58112) for request chatcmpl-e57568ebd5094644b4b7c9c06588b7ca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:01,971] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.6276 ms, throughput: 42.3233 GB/s; offload_time: 23.5775 ms, put_time: 0.0502 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:01 [estimate_with_func.py:307] Request job id arriving: 7, time is 1761207121.9742866
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:01 [estimate_with_func.py:315] Request job id: 7
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:01,977] LMCache INFO:[0m Reqid: chatcmpl-6074758ff1bb48b7aa189926ce35c4e0, Total tokens 13146, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '110', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '144', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:02,589] LMCache INFO:[0m Storing KV cache for 3717 out of 70021 tokens (skip_leading_tokens=66304) for request chatcmpl-e57568ebd5094644b4b7c9c06588b7ca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:02,601] LMCache INFO:[0m Stored 3717 out of total 3717 tokens. size: 0.4537 gb, cost 11.6464 ms, throughput: 38.9594 GB/s; offload_time: 11.6180 ms, put_time: 0.0284 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [estimate_with_func.py:328] Request job id finishing: 66, time is 1761207122.603534
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [scheduler.py:1462] Request GPU size bytes: 966393856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [scheduler.py:1463] Token size of the request: 7305
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [scheduler.py:1469] Swap waste for job 66: 0.030000813802083335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [scheduler.py:1479] Accumulated tokens for job 66: 1135234
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [scheduler.py:1481] Discard waste for job 66: 1038.6614901291202
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [scheduler.py:1484] Preserve waste for job 66: 3.071625819912663
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [estimate_with_func.py:307] Request job id arriving: 110, time is 1761207122.6044836
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [estimate_with_func.py:315] Request job id: 110
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [estimate_with_func.py:307] Request job id arriving: 144, time is 1761207122.6046348
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:02 [estimate_with_func.py:315] Request job id: 144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:02,606] LMCache INFO:[0m Reqid: chatcmpl-6074758ff1bb48b7aa189926ce35c4e0, Total tokens 13146, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:02,610] LMCache INFO:[0m Reqid: chatcmpl-fe1fae000ce04b1c9733005fcb1d4add, Total tokens 9343, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:02,631] LMCache INFO:[0m Retrieved 7168 out of 7168 required tokens (from 7168 total tokens). size: 0.8750 gb, cost 18.8205 ms, throughput: 46.4919 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:02,986] LMCache INFO:[0m Storing KV cache for 5978 out of 13146 tokens (skip_leading_tokens=7168) for request chatcmpl-6074758ff1bb48b7aa189926ce35c4e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,002] LMCache INFO:[0m Stored 5978 out of total 5978 tokens. size: 0.7297 gb, cost 16.2277 ms, throughput: 44.9687 GB/s; offload_time: 16.1861 ms, put_time: 0.0416 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,007] LMCache INFO:[0m Reqid: chatcmpl-fe1fae000ce04b1c9733005fcb1d4add, Total tokens 9343, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,079] LMCache INFO:[0m Reqid: chatcmpl-fe1fae000ce04b1c9733005fcb1d4add, Total tokens 9343, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [estimate_with_func.py:328] Request job id finishing: 6, time is 1761207123.1483
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,150] LMCache INFO:[0m Reqid: chatcmpl-fe1fae000ce04b1c9733005fcb1d4add, Total tokens 9343, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,153] LMCache INFO:[0m Reqid: chatcmpl-a214ad48dc7441cdba151d86636a0a70, Total tokens 9631, LMCache hit tokens: 6144, need to load: 6128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,168] LMCache INFO:[0m Retrieved 5120 out of 5120 required tokens (from 5120 total tokens). size: 0.6250 gb, cost 13.4784 ms, throughput: 46.3705 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,446] LMCache INFO:[0m Storing KV cache for 4223 out of 9343 tokens (skip_leading_tokens=5120) for request chatcmpl-fe1fae000ce04b1c9733005fcb1d4add [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,457] LMCache INFO:[0m Stored 4223 out of total 4223 tokens. size: 0.5155 gb, cost 11.4445 ms, throughput: 45.0437 GB/s; offload_time: 11.4182 ms, put_time: 0.0263 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207123.4599507
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1462] Request GPU size bytes: 782368768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1463] Token size of the request: 5923
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1469] Swap waste for job 102: 0.024287923177083334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1479] Accumulated tokens for job 102: 1135417
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1481] Discard waste for job 102: 1038.9934852504805
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1484] Preserve waste for job 102: 1.0652470545854398
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [estimate_with_func.py:328] Request job id finishing: 123, time is 1761207123.4602392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1462] Request GPU size bytes: 2620260352
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1463] Token size of the request: 19949
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1469] Swap waste for job 123: 0.08134358723958333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1479] Accumulated tokens for job 123: 1135417
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1481] Discard waste for job 123: 1038.9934852504805
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:03 [scheduler.py:1484] Preserve waste for job 123: 3.0766079185205863
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,462] LMCache INFO:[0m Reqid: chatcmpl-a214ad48dc7441cdba151d86636a0a70, Total tokens 9631, LMCache hit tokens: 6144, need to load: 6128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,464] LMCache INFO:[0m Reqid: chatcmpl-e2ff7986d53744b5b853d6f073bf8f5e, Total tokens 5200, LMCache hit tokens: 3584, need to load: 3568 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,467] LMCache INFO:[0m Reqid: chatcmpl-593101a08c9f468bb589ea435ad3d6cd, Total tokens 25510, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,486] LMCache INFO:[0m Retrieved 6144 out of 6144 required tokens (from 6144 total tokens). size: 0.7500 gb, cost 16.1377 ms, throughput: 46.4749 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,496] LMCache INFO:[0m Retrieved 3584 out of 3584 required tokens (from 3584 total tokens). size: 0.4375 gb, cost 9.4644 ms, throughput: 46.2259 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,847] LMCache INFO:[0m Storing KV cache for 3487 out of 9631 tokens (skip_leading_tokens=6144) for request chatcmpl-a214ad48dc7441cdba151d86636a0a70 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,856] LMCache INFO:[0m Stored 3487 out of total 3487 tokens. size: 0.4257 gb, cost 9.5391 ms, throughput: 44.6225 GB/s; offload_time: 9.5163 ms, put_time: 0.0228 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,856] LMCache INFO:[0m Storing KV cache for 1616 out of 5200 tokens (skip_leading_tokens=3584) for request chatcmpl-e2ff7986d53744b5b853d6f073bf8f5e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,861] LMCache INFO:[0m Stored 1616 out of total 1616 tokens. size: 0.1973 gb, cost 4.4532 ms, throughput: 44.2978 GB/s; offload_time: 4.4399 ms, put_time: 0.0132 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,861] LMCache INFO:[0m Storing KV cache for 2816 out of 2816 tokens (skip_leading_tokens=0) for request chatcmpl-593101a08c9f468bb589ea435ad3d6cd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:03,869] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 7.5080 ms, throughput: 45.7844 GB/s; offload_time: 7.4911 ms, put_time: 0.0169 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:04,259] LMCache INFO:[0m Storing KV cache for 8192 out of 11008 tokens (skip_leading_tokens=2816) for request chatcmpl-593101a08c9f468bb589ea435ad3d6cd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:04,282] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0386 ms, throughput: 45.3749 GB/s; offload_time: 21.9898 ms, put_time: 0.0488 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:04 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207124.2853527
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:04 [estimate_with_func.py:315] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:04,777] LMCache INFO:[0m Storing KV cache for 8192 out of 19200 tokens (skip_leading_tokens=11008) for request chatcmpl-593101a08c9f468bb589ea435ad3d6cd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:04,800] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1237 ms, throughput: 45.2003 GB/s; offload_time: 22.0704 ms, put_time: 0.0534 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:04,883] LMCache INFO:[0m Reqid: chatcmpl-593101a08c9f468bb589ea435ad3d6cd, Total tokens 25510, LMCache hit tokens: 19200, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:04,958] LMCache INFO:[0m Reqid: chatcmpl-593101a08c9f468bb589ea435ad3d6cd, Total tokens 25510, LMCache hit tokens: 19200, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [estimate_with_func.py:328] Request job id finishing: 35, time is 1761207125.0291138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,032] LMCache INFO:[0m Reqid: chatcmpl-593101a08c9f468bb589ea435ad3d6cd, Total tokens 25510, LMCache hit tokens: 19200, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,036] LMCache INFO:[0m Reqid: chatcmpl-4c8f1003bf434b0b9513a8a05111c66f, Total tokens 36983, LMCache hit tokens: 23808, need to load: 23792 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '66', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,516] LMCache INFO:[0m Storing KV cache for 6310 out of 25510 tokens (skip_leading_tokens=19200) for request chatcmpl-593101a08c9f468bb589ea435ad3d6cd [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,534] LMCache INFO:[0m Stored 6310 out of total 6310 tokens. size: 0.7703 gb, cost 17.2759 ms, throughput: 44.5861 GB/s; offload_time: 17.2364 ms, put_time: 0.0395 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [estimate_with_func.py:307] Request job id arriving: 66, time is 1761207125.5370653
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [estimate_with_func.py:315] Request job id: 66
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,539] LMCache INFO:[0m Reqid: chatcmpl-4c8f1003bf434b0b9513a8a05111c66f, Total tokens 36983, LMCache hit tokens: 23808, need to load: 23792 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,615] LMCache INFO:[0m Reqid: chatcmpl-4c8f1003bf434b0b9513a8a05111c66f, Total tokens 36983, LMCache hit tokens: 23808, need to load: 23792 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,689] LMCache INFO:[0m Reqid: chatcmpl-4c8f1003bf434b0b9513a8a05111c66f, Total tokens 36983, LMCache hit tokens: 23808, need to load: 23792 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [estimate_with_func.py:328] Request job id finishing: 114, time is 1761207125.7596831
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [estimate_with_func.py:328] Request job id finishing: 23, time is 1761207125.7599466
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [scheduler.py:1462] Request GPU size bytes: 4845338624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [scheduler.py:1463] Token size of the request: 36875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [scheduler.py:1469] Swap waste for job 23: 0.15041910807291667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [scheduler.py:1479] Accumulated tokens for job 23: 1131329
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [scheduler.py:1481] Discard waste for job 23: 1031.5897563177466
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:05 [scheduler.py:1484] Preserve waste for job 23: 1.063821513028372
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,762] LMCache INFO:[0m Reqid: chatcmpl-4c8f1003bf434b0b9513a8a05111c66f, Total tokens 36983, LMCache hit tokens: 23808, need to load: 23792 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:05,832] LMCache INFO:[0m Retrieved 23808 out of 23808 required tokens (from 23808 total tokens). size: 2.9062 gb, cost 62.4574 ms, throughput: 46.5317 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '23', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58770 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '123', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:06,472] LMCache INFO:[0m Storing KV cache for 7936 out of 31744 tokens (skip_leading_tokens=23808) for request chatcmpl-4c8f1003bf434b0b9513a8a05111c66f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:06,494] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.5070 ms, throughput: 45.0435 GB/s; offload_time: 21.4559 ms, put_time: 0.0511 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:06 [estimate_with_func.py:307] Request job id arriving: 23, time is 1761207126.4975896
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:06 [estimate_with_func.py:315] Request job id: 23
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:06 [estimate_with_func.py:307] Request job id arriving: 123, time is 1761207126.4978263
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:06 [estimate_with_func.py:315] Request job id: 123
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:06,500] LMCache INFO:[0m Reqid: chatcmpl-3502ca874ad84fa08e4c99ff73af02db, Total tokens 21342, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:60200 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:07,070] LMCache INFO:[0m Storing KV cache for 3072 out of 3072 tokens (skip_leading_tokens=0) for request chatcmpl-3502ca874ad84fa08e4c99ff73af02db [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:07,079] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 8.4111 ms, throughput: 44.5838 GB/s; offload_time: 8.3817 ms, put_time: 0.0294 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:07,079] LMCache INFO:[0m Storing KV cache for 5239 out of 36983 tokens (skip_leading_tokens=31744) for request chatcmpl-4c8f1003bf434b0b9513a8a05111c66f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:07,094] LMCache INFO:[0m Stored 5239 out of total 5239 tokens. size: 0.6395 gb, cost 15.0357 ms, throughput: 42.5339 GB/s; offload_time: 14.9979 ms, put_time: 0.0378 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:07 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207127.0974264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:07 [estimate_with_func.py:315] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:07,481] LMCache INFO:[0m Storing KV cache for 8192 out of 11264 tokens (skip_leading_tokens=3072) for request chatcmpl-3502ca874ad84fa08e4c99ff73af02db [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:07,503] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.9089 ms, throughput: 45.6435 GB/s; offload_time: 21.8590 ms, put_time: 0.0499 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:07,996] LMCache INFO:[0m Storing KV cache for 7936 out of 19200 tokens (skip_leading_tokens=11264) for request chatcmpl-3502ca874ad84fa08e4c99ff73af02db [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,018] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.1932 ms, throughput: 45.7105 GB/s; offload_time: 21.1506 ms, put_time: 0.0426 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,024] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,293] LMCache INFO:[0m Storing KV cache for 2142 out of 21342 tokens (skip_leading_tokens=19200) for request chatcmpl-3502ca874ad84fa08e4c99ff73af02db [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,300] LMCache INFO:[0m Stored 2142 out of total 2142 tokens. size: 0.2615 gb, cost 6.1752 ms, throughput: 42.3425 GB/s; offload_time: 6.1561 ms, put_time: 0.0191 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,305] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,384] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,458] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207128.5306182
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1462] Request GPU size bytes: 3163947008
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1463] Token size of the request: 24015
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1469] Swap waste for job 174: 0.09822184244791667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1479] Accumulated tokens for job 174: 1143467
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1481] Discard waste for job 174: 1053.6501315291325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1484] Preserve waste for job 174: 3.075780508734963
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207128.5313036
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1462] Request GPU size bytes: 683933696
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1463] Token size of the request: 5200
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1469] Swap waste for job 122: 0.021232096354166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1479] Accumulated tokens for job 122: 1143467
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1481] Discard waste for job 122: 1053.6501315291325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1484] Preserve waste for job 122: 3.075780508734963
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,534] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,610] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,684] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,758] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [estimate_with_func.py:328] Request job id finishing: 121, time is 1761207128.8306015
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1462] Request GPU size bytes: 1515454464
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1463] Token size of the request: 11466
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1469] Swap waste for job 121: 0.0470458984375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1479] Accumulated tokens for job 121: 1114252
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1481] Discard waste for job 121: 1000.9480523323997
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1484] Preserve waste for job 121: 3.075780508734963
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,833] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [estimate_with_func.py:328] Request job id finishing: 101, time is 1761207128.9046137
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1462] Request GPU size bytes: 1404174336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1463] Token size of the request: 10587
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1469] Swap waste for job 101: 0.04359130859375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1479] Accumulated tokens for job 101: 1102786
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1481] Discard waste for job 101: 980.6335071969567
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1484] Preserve waste for job 101: 1.175721988958471
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [estimate_with_func.py:328] Request job id finishing: 94, time is 1761207128.9050605
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1462] Request GPU size bytes: 1227751424
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1463] Token size of the request: 9343
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1469] Swap waste for job 94: 0.03811442057291667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1479] Accumulated tokens for job 94: 1102786
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1481] Discard waste for job 94: 980.6335071969567
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:08 [scheduler.py:1484] Preserve waste for job 94: 1.175721988958471
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:08,908] LMCache INFO:[0m Reqid: chatcmpl-134ef6466bf74bdc8818ae7f28834936, Total tokens 59780, LMCache hit tokens: 45312, need to load: 45296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:09,040] LMCache INFO:[0m Retrieved 45312 out of 45312 required tokens (from 45312 total tokens). size: 5.5312 gb, cost 120.0014 ms, throughput: 46.0932 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '101', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:09,952] LMCache INFO:[0m Storing KV cache for 7936 out of 53248 tokens (skip_leading_tokens=45312) for request chatcmpl-134ef6466bf74bdc8818ae7f28834936 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:09,976] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.8328 ms, throughput: 42.4279 GB/s; offload_time: 22.7818 ms, put_time: 0.0510 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:09 [estimate_with_func.py:328] Request job id finishing: 112, time is 1761207129.9786615
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:09 [estimate_with_func.py:307] Request job id arriving: 101, time is 1761207129.9797916
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:09 [estimate_with_func.py:315] Request job id: 101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:09,984] LMCache INFO:[0m Reqid: chatcmpl-34178782ba5f4c81a22ec36f488e6193, Total tokens 93883, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:12:10 [loggers.py:123] Engine 000: Avg prompt throughput: 19114.8 tokens/s, Avg generation throughput: 155.9 tokens/s, Running: 46 reqs, Waiting: 33 reqs, GPU KV cache usage: 96.9%, Prefix cache hit rate: 16.1%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:10,833] LMCache INFO:[0m Storing KV cache for 1792 out of 1792 tokens (skip_leading_tokens=0) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:10,839] LMCache INFO:[0m Stored 1792 out of total 1792 tokens. size: 0.2188 gb, cost 5.3808 ms, throughput: 40.6540 GB/s; offload_time: 5.3514 ms, put_time: 0.0293 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:10,840] LMCache INFO:[0m Storing KV cache for 6532 out of 59780 tokens (skip_leading_tokens=53248) for request chatcmpl-134ef6466bf74bdc8818ae7f28834936 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:10,859] LMCache INFO:[0m Stored 6532 out of total 6532 tokens. size: 0.7974 gb, cost 19.4257 ms, throughput: 41.0469 GB/s; offload_time: 19.3861 ms, put_time: 0.0395 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:10 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207130.8626401
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:10 [estimate_with_func.py:315] Request job id: 122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:11,234] LMCache INFO:[0m Storing KV cache for 8192 out of 9984 tokens (skip_leading_tokens=1792) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:11,256] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.6843 ms, throughput: 46.1163 GB/s; offload_time: 21.6374 ms, put_time: 0.0469 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '121', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:11,739] LMCache INFO:[0m Storing KV cache for 7936 out of 17920 tokens (skip_leading_tokens=9984) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:11,761] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.2673 ms, throughput: 45.5511 GB/s; offload_time: 21.2138 ms, put_time: 0.0536 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [estimate_with_func.py:328] Request job id finishing: 141, time is 1761207131.7634358
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [scheduler.py:1462] Request GPU size bytes: 461766656
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [scheduler.py:1463] Token size of the request: 3375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [scheduler.py:1469] Swap waste for job 141: 0.014335123697916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [scheduler.py:1479] Accumulated tokens for job 141: 1208585
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [scheduler.py:1481] Discard waste for job 141: 1175.984019095256
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [scheduler.py:1484] Preserve waste for job 141: 3.0724147088926843
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [estimate_with_func.py:307] Request job id arriving: 121, time is 1761207131.7639985
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:11 [estimate_with_func.py:315] Request job id: 121
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '94', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59056 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:12,347] LMCache INFO:[0m Storing KV cache for 8192 out of 26112 tokens (skip_leading_tokens=17920) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:12,370] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.4161 ms, throughput: 44.6108 GB/s; offload_time: 22.3561 ms, put_time: 0.0600 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [estimate_with_func.py:307] Request job id arriving: 94, time is 1761207132.3726826
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [estimate_with_func.py:315] Request job id: 94
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207132.4475524
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [scheduler.py:1462] Request GPU size bytes: 6466568192
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [scheduler.py:1463] Token size of the request: 49286
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [scheduler.py:1469] Swap waste for job 150: 0.20074869791666666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [scheduler.py:1479] Accumulated tokens for job 150: 1111327
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [scheduler.py:1481] Discard waste for job 150: 995.745984711724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:12 [scheduler.py:1484] Preserve waste for job 150: 3.071788462432655
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:12,464] LMCache INFO:[0m Reqid: chatcmpl-34178782ba5f4c81a22ec36f488e6193, Total tokens 93883, LMCache hit tokens: 26112, need to load: -160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:13,141] LMCache INFO:[0m Storing KV cache for 8192 out of 34304 tokens (skip_leading_tokens=26112) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:13,165] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.9690 ms, throughput: 43.5370 GB/s; offload_time: 22.9241 ms, put_time: 0.0449 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207133.1678052
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [estimate_with_func.py:315] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:13,947] LMCache INFO:[0m Storing KV cache for 8192 out of 42496 tokens (skip_leading_tokens=34304) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:13,971] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.2731 ms, throughput: 42.9681 GB/s; offload_time: 23.2242 ms, put_time: 0.0489 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207133.9741712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [scheduler.py:1462] Request GPU size bytes: 4850057216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [scheduler.py:1463] Token size of the request: 36983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [scheduler.py:1469] Swap waste for job 136: 0.15056559244791667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [scheduler.py:1479] Accumulated tokens for job 136: 1155924
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [scheduler.py:1481] Discard waste for job 136: 1076.5329258874572
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:13 [scheduler.py:1484] Preserve waste for job 136: 3.0788095606816723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:14,857] LMCache INFO:[0m Storing KV cache for 8192 out of 50688 tokens (skip_leading_tokens=42496) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:14,881] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.1125 ms, throughput: 43.2666 GB/s; offload_time: 23.0461 ms, put_time: 0.0664 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '141', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:15,864] LMCache INFO:[0m Storing KV cache for 7936 out of 58624 tokens (skip_leading_tokens=50688) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:15,888] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.3160 ms, throughput: 43.4106 GB/s; offload_time: 22.2708 ms, put_time: 0.0452 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [estimate_with_func.py:328] Request job id finishing: 52, time is 1761207135.8903406
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [scheduler.py:1462] Request GPU size bytes: 2799828992
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [scheduler.py:1463] Token size of the request: 21342
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [scheduler.py:1469] Swap waste for job 52: 0.08691813151041666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [scheduler.py:1479] Accumulated tokens for job 52: 1118941
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [scheduler.py:1481] Discard waste for job 52: 1009.3156423615814
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [scheduler.py:1484] Preserve waste for job 52: 3.0788095606816723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [estimate_with_func.py:307] Request job id arriving: 141, time is 1761207135.8910334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:15 [estimate_with_func.py:315] Request job id: 141
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:16,970] LMCache INFO:[0m Storing KV cache for 8192 out of 66816 tokens (skip_leading_tokens=58624) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:16,994] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.2677 ms, throughput: 42.9781 GB/s; offload_time: 23.2013 ms, put_time: 0.0663 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:16 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207136.9978628
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:16 [estimate_with_func.py:315] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:16 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207136.9981084
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:16 [estimate_with_func.py:315] Request job id: 150
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '52', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:18,191] LMCache INFO:[0m Storing KV cache for 8192 out of 75008 tokens (skip_leading_tokens=66816) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:18,216] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.3986 ms, throughput: 42.7376 GB/s; offload_time: 23.3447 ms, put_time: 0.0539 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:18 [estimate_with_func.py:307] Request job id arriving: 52, time is 1761207138.219202
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:18 [estimate_with_func.py:315] Request job id: 52
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:19,514] LMCache INFO:[0m Storing KV cache for 8192 out of 83200 tokens (skip_leading_tokens=75008) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:19,539] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.8464 ms, throughput: 41.9350 GB/s; offload_time: 23.7927 ms, put_time: 0.0537 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:19 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207139.5427563
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:19 [scheduler.py:1462] Request GPU size bytes: 7837057024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:19 [scheduler.py:1463] Token size of the request: 59780
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:19 [scheduler.py:1469] Swap waste for job 164: 0.24329427083333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:19 [scheduler.py:1479] Accumulated tokens for job 164: 1097599
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:19 [scheduler.py:1481] Discard waste for job 164: 971.5120048557106
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:19 [scheduler.py:1484] Preserve waste for job 164: 1.1884631708610889
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:12:20 [loggers.py:123] Engine 000: Avg prompt throughput: 5978.0 tokens/s, Avg generation throughput: 52.8 tokens/s, Running: 42 reqs, Waiting: 41 reqs, GPU KV cache usage: 89.8%, Prefix cache hit rate: 16.0%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:20,941] LMCache INFO:[0m Storing KV cache for 8192 out of 91392 tokens (skip_leading_tokens=83200) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:20,967] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.1794 ms, throughput: 41.3576 GB/s; offload_time: 24.1282 ms, put_time: 0.0512 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:20 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207140.9702888
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:20 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:20,973] LMCache INFO:[0m Reqid: chatcmpl-35b7d82b7b9d42149c6777e7134455b6, Total tokens 18975, LMCache hit tokens: 13568, need to load: 13552 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:20,979] LMCache INFO:[0m Reqid: chatcmpl-174bd0f9afec4dd792328f7d0994ddf9, Total tokens 6142, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,020] LMCache INFO:[0m Retrieved 13568 out of 13568 required tokens (from 13568 total tokens). size: 1.6562 gb, cost 35.8649 ms, throughput: 46.1803 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,031] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.7751 ms, throughput: 46.4033 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,804] LMCache INFO:[0m Storing KV cache for 5407 out of 18975 tokens (skip_leading_tokens=13568) for request chatcmpl-35b7d82b7b9d42149c6777e7134455b6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,819] LMCache INFO:[0m Stored 5407 out of total 5407 tokens. size: 0.6600 gb, cost 14.9594 ms, throughput: 44.1218 GB/s; offload_time: 14.9206 ms, put_time: 0.0388 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,819] LMCache INFO:[0m Storing KV cache for 256 out of 4352 tokens (skip_leading_tokens=4096) for request chatcmpl-174bd0f9afec4dd792328f7d0994ddf9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,820] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.8117 ms, throughput: 38.4988 GB/s; offload_time: 0.8053 ms, put_time: 0.0064 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,821] LMCache INFO:[0m Storing KV cache for 2491 out of 93883 tokens (skip_leading_tokens=91392) for request chatcmpl-34178782ba5f4c81a22ec36f488e6193 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,830] LMCache INFO:[0m Stored 2491 out of total 2491 tokens. size: 0.3041 gb, cost 9.3707 ms, throughput: 32.4498 GB/s; offload_time: 9.3505 ms, put_time: 0.0202 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:21 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207141.8331866
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:21 [scheduler.py:1462] Request GPU size bytes: 1582825472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:21 [scheduler.py:1463] Token size of the request: 12012
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:21 [scheduler.py:1469] Swap waste for job 5: 0.04913736979166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:21 [scheduler.py:1479] Accumulated tokens for job 5: 1062936
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:21 [scheduler.py:1481] Discard waste for job 5: 911.6500158830886
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:21 [scheduler.py:1484] Preserve waste for job 5: 1.1898452560336603
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:21,836] LMCache INFO:[0m Reqid: chatcmpl-e25689e0a6244f39a86f279c80023ce1, Total tokens 9323, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,175] LMCache INFO:[0m Storing KV cache for 6400 out of 6400 tokens (skip_leading_tokens=0) for request chatcmpl-e25689e0a6244f39a86f279c80023ce1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,192] LMCache INFO:[0m Stored 6400 out of total 6400 tokens. size: 0.7812 gb, cost 17.1441 ms, throughput: 45.5696 GB/s; offload_time: 17.1044 ms, put_time: 0.0397 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,193] LMCache INFO:[0m Storing KV cache for 1790 out of 6142 tokens (skip_leading_tokens=4352) for request chatcmpl-174bd0f9afec4dd792328f7d0994ddf9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,198] LMCache INFO:[0m Stored 1790 out of total 1790 tokens. size: 0.2185 gb, cost 4.9079 ms, throughput: 44.5210 GB/s; offload_time: 4.8935 ms, put_time: 0.0144 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,203] LMCache INFO:[0m Reqid: chatcmpl-63da394eb1464e4690f872d7f1969a08, Total tokens 25125, LMCache hit tokens: 16128, need to load: 16112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,250] LMCache INFO:[0m Retrieved 16128 out of 16128 required tokens (from 16128 total tokens). size: 1.9688 gb, cost 42.4371 ms, throughput: 46.3921 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '5', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,724] LMCache INFO:[0m Storing KV cache for 5120 out of 21248 tokens (skip_leading_tokens=16128) for request chatcmpl-63da394eb1464e4690f872d7f1969a08 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,738] LMCache INFO:[0m Stored 5120 out of total 5120 tokens. size: 0.6250 gb, cost 13.9462 ms, throughput: 44.8152 GB/s; offload_time: 13.9151 ms, put_time: 0.0310 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,738] LMCache INFO:[0m Storing KV cache for 2923 out of 9323 tokens (skip_leading_tokens=6400) for request chatcmpl-e25689e0a6244f39a86f279c80023ce1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,746] LMCache INFO:[0m Stored 2923 out of total 2923 tokens. size: 0.3568 gb, cost 7.9071 ms, throughput: 45.1254 GB/s; offload_time: 7.8876 ms, put_time: 0.0196 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:22 [estimate_with_func.py:307] Request job id arriving: 5, time is 1761207142.7492342
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:22 [estimate_with_func.py:315] Request job id: 5
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:22,754] LMCache INFO:[0m Reqid: chatcmpl-1132bdb4e63443f48f6f26e6524158b0, Total tokens 83619, LMCache hit tokens: 55296, need to load: 55280 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:23,120] LMCache INFO:[0m Storing KV cache for 3877 out of 25125 tokens (skip_leading_tokens=21248) for request chatcmpl-63da394eb1464e4690f872d7f1969a08 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:23,131] LMCache INFO:[0m Stored 3877 out of total 3877 tokens. size: 0.4733 gb, cost 10.7719 ms, throughput: 43.9355 GB/s; offload_time: 10.7468 ms, put_time: 0.0251 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:23,137] LMCache INFO:[0m Reqid: chatcmpl-1132bdb4e63443f48f6f26e6524158b0, Total tokens 83619, LMCache hit tokens: 55296, need to load: 55280 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:23,230] LMCache INFO:[0m Reqid: chatcmpl-1132bdb4e63443f48f6f26e6524158b0, Total tokens 83619, LMCache hit tokens: 55296, need to load: 55280 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:23 [estimate_with_func.py:328] Request job id finishing: 2, time is 1761207143.313035
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:23,317] LMCache INFO:[0m Reqid: chatcmpl-1132bdb4e63443f48f6f26e6524158b0, Total tokens 83619, LMCache hit tokens: 55296, need to load: 55280 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:23,477] LMCache INFO:[0m Retrieved 55296 out of 55296 required tokens (from 55296 total tokens). size: 6.7500 gb, cost 146.2354 ms, throughput: 46.1584 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:24,504] LMCache INFO:[0m Storing KV cache for 7936 out of 63232 tokens (skip_leading_tokens=55296) for request chatcmpl-1132bdb4e63443f48f6f26e6524158b0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:24,528] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.9467 ms, throughput: 42.2174 GB/s; offload_time: 22.8873 ms, put_time: 0.0594 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:24 [estimate_with_func.py:328] Request job id finishing: 100, time is 1761207144.5303476
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:24 [scheduler.py:1462] Request GPU size bytes: 129892352
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:24 [scheduler.py:1463] Token size of the request: 381
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:24 [scheduler.py:1469] Swap waste for job 100: 0.0040323893229166664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:24 [scheduler.py:1479] Accumulated tokens for job 100: 1108266
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:24 [scheduler.py:1481] Discard waste for job 100: 990.3165548290327
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:24 [scheduler.py:1484] Preserve waste for job 100: 3.0863669160179104
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:25,674] LMCache INFO:[0m Storing KV cache for 8192 out of 71424 tokens (skip_leading_tokens=63232) for request chatcmpl-1132bdb4e63443f48f6f26e6524158b0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:25,699] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.8223 ms, throughput: 41.9775 GB/s; offload_time: 23.7742 ms, put_time: 0.0480 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:25 [estimate_with_func.py:328] Request job id finishing: 92, time is 1761207145.7019308
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:26,947] LMCache INFO:[0m Storing KV cache for 8192 out of 79616 tokens (skip_leading_tokens=71424) for request chatcmpl-1132bdb4e63443f48f6f26e6524158b0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:26,972] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.9452 ms, throughput: 41.7620 GB/s; offload_time: 23.8927 ms, put_time: 0.0526 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:26,977] LMCache INFO:[0m Reqid: chatcmpl-20d89afaf9d5452e9513fe62df5ebd7b, Total tokens 12122, LMCache hit tokens: 8448, need to load: 8432 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:26,980] LMCache INFO:[0m Reqid: chatcmpl-b095c27b6a36429d8aa63f4936b0f05a, Total tokens 2457, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,006] LMCache INFO:[0m Retrieved 8448 out of 8448 required tokens (from 8448 total tokens). size: 1.0312 gb, cost 22.3930 ms, throughput: 46.0523 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,841] LMCache INFO:[0m Storing KV cache for 3674 out of 12122 tokens (skip_leading_tokens=8448) for request chatcmpl-20d89afaf9d5452e9513fe62df5ebd7b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,851] LMCache INFO:[0m Stored 3674 out of total 3674 tokens. size: 0.4485 gb, cost 10.1606 ms, throughput: 44.1399 GB/s; offload_time: 10.1324 ms, put_time: 0.0281 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,851] LMCache INFO:[0m Storing KV cache for 512 out of 512 tokens (skip_leading_tokens=0) for request chatcmpl-b095c27b6a36429d8aa63f4936b0f05a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,853] LMCache INFO:[0m Stored 512 out of total 512 tokens. size: 0.0625 gb, cost 1.4519 ms, throughput: 43.0460 GB/s; offload_time: 1.4437 ms, put_time: 0.0082 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,853] LMCache INFO:[0m Storing KV cache for 4003 out of 83619 tokens (skip_leading_tokens=79616) for request chatcmpl-1132bdb4e63443f48f6f26e6524158b0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,866] LMCache INFO:[0m Stored 4003 out of total 4003 tokens. size: 0.4886 gb, cost 12.3521 ms, throughput: 39.5600 GB/s; offload_time: 12.3275 ms, put_time: 0.0246 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:27,871] LMCache INFO:[0m Reqid: chatcmpl-313be15d318741d6afdb6f530478f364, Total tokens 13601, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,198] LMCache INFO:[0m Storing KV cache for 6144 out of 6144 tokens (skip_leading_tokens=0) for request chatcmpl-313be15d318741d6afdb6f530478f364 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,214] LMCache INFO:[0m Stored 6144 out of total 6144 tokens. size: 0.7500 gb, cost 16.4785 ms, throughput: 45.5140 GB/s; offload_time: 16.4358 ms, put_time: 0.0426 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,215] LMCache INFO:[0m Storing KV cache for 1945 out of 2457 tokens (skip_leading_tokens=512) for request chatcmpl-b095c27b6a36429d8aa63f4936b0f05a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,220] LMCache INFO:[0m Stored 1945 out of total 1945 tokens. size: 0.2374 gb, cost 5.3049 ms, throughput: 44.7561 GB/s; offload_time: 5.2897 ms, put_time: 0.0152 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:28 [estimate_with_func.py:328] Request job id finishing: 124, time is 1761207148.2225761
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:28 [estimate_with_func.py:328] Request job id finishing: 151, time is 1761207148.2230396
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,226] LMCache INFO:[0m Reqid: chatcmpl-b0046693a2e84512bddcea694383808e, Total tokens 21040, LMCache hit tokens: 13312, need to load: 13296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,277] LMCache INFO:[0m Retrieved 13312 out of 13312 required tokens (from 13312 total tokens). size: 1.6250 gb, cost 34.8143 ms, throughput: 46.6762 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '100', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,692] LMCache INFO:[0m Storing KV cache for 768 out of 14080 tokens (skip_leading_tokens=13312) for request chatcmpl-b0046693a2e84512bddcea694383808e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,695] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.2974 ms, throughput: 40.8063 GB/s; offload_time: 2.2865 ms, put_time: 0.0110 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,695] LMCache INFO:[0m Storing KV cache for 7457 out of 13601 tokens (skip_leading_tokens=6144) for request chatcmpl-313be15d318741d6afdb6f530478f364 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,715] LMCache INFO:[0m Stored 7457 out of total 7457 tokens. size: 0.9103 gb, cost 19.7979 ms, throughput: 45.9785 GB/s; offload_time: 19.7578 ms, put_time: 0.0401 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:28 [estimate_with_func.py:307] Request job id arriving: 100, time is 1761207148.7176526
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:28 [estimate_with_func.py:315] Request job id: 100
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:28,720] LMCache INFO:[0m Reqid: chatcmpl-ab5b07404ecf4c59b5282a4342745ded, Total tokens 10891, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,204] LMCache INFO:[0m Storing KV cache for 1280 out of 1280 tokens (skip_leading_tokens=0) for request chatcmpl-ab5b07404ecf4c59b5282a4342745ded [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,208] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.6839 ms, throughput: 42.4143 GB/s; offload_time: 3.6684 ms, put_time: 0.0155 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,208] LMCache INFO:[0m Storing KV cache for 6960 out of 21040 tokens (skip_leading_tokens=14080) for request chatcmpl-b0046693a2e84512bddcea694383808e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,227] LMCache INFO:[0m Stored 6960 out of total 6960 tokens. size: 0.8496 gb, cost 18.6492 ms, throughput: 45.5575 GB/s; offload_time: 18.6176 ms, put_time: 0.0316 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,591] LMCache INFO:[0m Storing KV cache for 7936 out of 9216 tokens (skip_leading_tokens=1280) for request chatcmpl-ab5b07404ecf4c59b5282a4342745ded [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,612] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.2610 ms, throughput: 45.5647 GB/s; offload_time: 21.2145 ms, put_time: 0.0465 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,618] LMCache INFO:[0m Reqid: chatcmpl-67ecff7d988b498e8bc3855384b3c712, Total tokens 37162, LMCache hit tokens: 27392, need to load: 27376 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:29,698] LMCache INFO:[0m Retrieved 27392 out of 27392 required tokens (from 27392 total tokens). size: 3.3438 gb, cost 72.1490 ms, throughput: 46.3450 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,334] LMCache INFO:[0m Storing KV cache for 6656 out of 34048 tokens (skip_leading_tokens=27392) for request chatcmpl-67ecff7d988b498e8bc3855384b3c712 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,354] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 18.9070 ms, throughput: 42.9736 GB/s; offload_time: 18.8547 ms, put_time: 0.0523 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,354] LMCache INFO:[0m Storing KV cache for 1675 out of 10891 tokens (skip_leading_tokens=9216) for request chatcmpl-ab5b07404ecf4c59b5282a4342745ded [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,359] LMCache INFO:[0m Stored 1675 out of total 1675 tokens. size: 0.2045 gb, cost 4.7116 ms, throughput: 43.3964 GB/s; offload_time: 4.6962 ms, put_time: 0.0154 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,364] LMCache INFO:[0m Reqid: chatcmpl-c2eacb804abd48f09a339883723dd16d, Total tokens 18384, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,401] LMCache INFO:[0m Retrieved 12032 out of 12032 required tokens (from 12032 total tokens). size: 1.4688 gb, cost 31.7763 ms, throughput: 46.2215 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:12:30 [loggers.py:123] Engine 000: Avg prompt throughput: 29717.9 tokens/s, Avg generation throughput: 70.4 tokens/s, Running: 47 reqs, Waiting: 33 reqs, GPU KV cache usage: 97.0%, Prefix cache hit rate: 14.8%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,976] LMCache INFO:[0m Storing KV cache for 4864 out of 16896 tokens (skip_leading_tokens=12032) for request chatcmpl-c2eacb804abd48f09a339883723dd16d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,990] LMCache INFO:[0m Stored 4864 out of total 4864 tokens. size: 0.5938 gb, cost 13.1674 ms, throughput: 45.0925 GB/s; offload_time: 13.1439 ms, put_time: 0.0234 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:30,991] LMCache INFO:[0m Storing KV cache for 3114 out of 37162 tokens (skip_leading_tokens=34048) for request chatcmpl-67ecff7d988b498e8bc3855384b3c712 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,000] LMCache INFO:[0m Stored 3114 out of total 3114 tokens. size: 0.3801 gb, cost 9.5259 ms, throughput: 39.9045 GB/s; offload_time: 9.5034 ms, put_time: 0.0225 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,005] LMCache INFO:[0m Reqid: chatcmpl-bc47fcf57c91497a82f057a026686058, Total tokens 12644, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,380] LMCache INFO:[0m Storing KV cache for 6656 out of 6656 tokens (skip_leading_tokens=0) for request chatcmpl-bc47fcf57c91497a82f057a026686058 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,398] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 17.7440 ms, throughput: 45.7901 GB/s; offload_time: 17.7108 ms, put_time: 0.0332 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,398] LMCache INFO:[0m Storing KV cache for 1488 out of 18384 tokens (skip_leading_tokens=16896) for request chatcmpl-c2eacb804abd48f09a339883723dd16d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,403] LMCache INFO:[0m Stored 1488 out of total 1488 tokens. size: 0.1816 gb, cost 4.2504 ms, throughput: 42.7345 GB/s; offload_time: 4.2388 ms, put_time: 0.0117 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,409] LMCache INFO:[0m Reqid: chatcmpl-37b154f56523498d9511083484349e57, Total tokens 45132, LMCache hit tokens: 32768, need to load: 32752 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,764] LMCache INFO:[0m Storing KV cache for 5988 out of 12644 tokens (skip_leading_tokens=6656) for request chatcmpl-bc47fcf57c91497a82f057a026686058 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,780] LMCache INFO:[0m Stored 5988 out of total 5988 tokens. size: 0.7310 gb, cost 16.3362 ms, throughput: 44.7447 GB/s; offload_time: 16.2934 ms, put_time: 0.0428 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,786] LMCache INFO:[0m Reqid: chatcmpl-37b154f56523498d9511083484349e57, Total tokens 45132, LMCache hit tokens: 32768, need to load: 32752 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:31 [estimate_with_func.py:328] Request job id finishing: 142, time is 1761207151.8723037
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:31 [scheduler.py:1462] Request GPU size bytes: 2847277056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:31 [scheduler.py:1463] Token size of the request: 21545
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:31 [scheduler.py:1469] Swap waste for job 142: 0.08839111328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:31 [scheduler.py:1479] Accumulated tokens for job 142: 1144196
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:31 [scheduler.py:1481] Discard waste for job 142: 1054.9824914662697
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:31 [scheduler.py:1484] Preserve waste for job 142: 3.091195687913058
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,875] LMCache INFO:[0m Reqid: chatcmpl-37b154f56523498d9511083484349e57, Total tokens 45132, LMCache hit tokens: 32768, need to load: 32752 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:31,962] LMCache INFO:[0m Reqid: chatcmpl-37b154f56523498d9511083484349e57, Total tokens 45132, LMCache hit tokens: 32768, need to load: 32752 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:32,049] LMCache INFO:[0m Reqid: chatcmpl-37b154f56523498d9511083484349e57, Total tokens 45132, LMCache hit tokens: 32768, need to load: 32752 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:32,134] LMCache INFO:[0m Reqid: chatcmpl-37b154f56523498d9511083484349e57, Total tokens 45132, LMCache hit tokens: 32768, need to load: 32752 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [estimate_with_func.py:328] Request job id finishing: 76, time is 1761207152.2188883
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [estimate_with_func.py:328] Request job id finishing: 1, time is 1761207152.2195458
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1462] Request GPU size bytes: 3183214592
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1463] Token size of the request: 24186
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1469] Swap waste for job 1: 0.09881998697916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1479] Accumulated tokens for job 1: 1122651
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1481] Discard waste for job 1: 1015.9608708469348
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1484] Preserve waste for job 1: 1.188271944550262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207152.2200415
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1462] Request GPU size bytes: 1590689792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1463] Token size of the request: 12122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1469] Swap waste for job 68: 0.04938151041666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1479] Accumulated tokens for job 68: 1122651
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1481] Discard waste for job 68: 1015.9608708469348
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1484] Preserve waste for job 68: 1.188271944550262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [estimate_with_func.py:328] Request job id finishing: 11, time is 1761207152.2202995
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1462] Request GPU size bytes: 1784283136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1463] Token size of the request: 13601
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1469] Swap waste for job 11: 0.05539143880208333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1479] Accumulated tokens for job 11: 1122651
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1481] Discard waste for job 11: 1015.9608708469348
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:32 [scheduler.py:1484] Preserve waste for job 11: 1.188271944550262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:32,222] LMCache INFO:[0m Reqid: chatcmpl-37b154f56523498d9511083484349e57, Total tokens 45132, LMCache hit tokens: 32768, need to load: 32752 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:32,318] LMCache INFO:[0m Retrieved 32768 out of 32768 required tokens (from 32768 total tokens). size: 4.0000 gb, cost 86.1519 ms, throughput: 46.4296 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '11', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '1', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,068] LMCache INFO:[0m Storing KV cache for 7936 out of 40704 tokens (skip_leading_tokens=32768) for request chatcmpl-37b154f56523498d9511083484349e57 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,092] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.7678 ms, throughput: 42.5491 GB/s; offload_time: 22.7165 ms, put_time: 0.0513 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [estimate_with_func.py:328] Request job id finishing: 90, time is 1761207153.0945606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [scheduler.py:1462] Request GPU size bytes: 1050017792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [scheduler.py:1463] Token size of the request: 7869
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [scheduler.py:1469] Swap waste for job 90: 0.03259684244791667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [scheduler.py:1479] Accumulated tokens for job 90: 1072702
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [scheduler.py:1481] Discard waste for job 90: 928.3230463444619
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [scheduler.py:1484] Preserve waste for job 90: 1.188271944550262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [estimate_with_func.py:307] Request job id arriving: 11, time is 1761207153.0952728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [estimate_with_func.py:315] Request job id: 11
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207153.0954494
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [estimate_with_func.py:307] Request job id arriving: 1, time is 1761207153.0955315
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:33 [estimate_with_func.py:315] Request job id: 1
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,098] LMCache INFO:[0m Reqid: chatcmpl-af2d0902bac24642a420f6575af4bbf3, Total tokens 6750, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,679] LMCache INFO:[0m Storing KV cache for 3840 out of 3840 tokens (skip_leading_tokens=0) for request chatcmpl-af2d0902bac24642a420f6575af4bbf3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,690] LMCache INFO:[0m Stored 3840 out of total 3840 tokens. size: 0.4688 gb, cost 10.6224 ms, throughput: 44.1283 GB/s; offload_time: 10.5939 ms, put_time: 0.0285 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,691] LMCache INFO:[0m Storing KV cache for 4428 out of 45132 tokens (skip_leading_tokens=40704) for request chatcmpl-37b154f56523498d9511083484349e57 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,704] LMCache INFO:[0m Stored 4428 out of total 4428 tokens. size: 0.5405 gb, cost 13.0865 ms, throughput: 41.3041 GB/s; offload_time: 13.0590 ms, put_time: 0.0275 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:33,709] LMCache INFO:[0m Reqid: chatcmpl-1a1a99f180574d0a884635e5970f794a, Total tokens 13545, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,066] LMCache INFO:[0m Storing KV cache for 5120 out of 5120 tokens (skip_leading_tokens=0) for request chatcmpl-1a1a99f180574d0a884635e5970f794a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,080] LMCache INFO:[0m Stored 5120 out of total 5120 tokens. size: 0.6250 gb, cost 13.8807 ms, throughput: 45.0265 GB/s; offload_time: 13.8494 ms, put_time: 0.0314 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,080] LMCache INFO:[0m Storing KV cache for 2910 out of 6750 tokens (skip_leading_tokens=3840) for request chatcmpl-af2d0902bac24642a420f6575af4bbf3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,088] LMCache INFO:[0m Stored 2910 out of total 2910 tokens. size: 0.3552 gb, cost 7.9150 ms, throughput: 44.8800 GB/s; offload_time: 7.8945 ms, put_time: 0.0205 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '90', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '142', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,507] LMCache INFO:[0m Storing KV cache for 8192 out of 13312 tokens (skip_leading_tokens=5120) for request chatcmpl-1a1a99f180574d0a884635e5970f794a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,530] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.8640 ms, throughput: 45.7374 GB/s; offload_time: 21.8162 ms, put_time: 0.0478 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:34 [estimate_with_func.py:307] Request job id arriving: 90, time is 1761207154.5322618
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:34 [estimate_with_func.py:315] Request job id: 90
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:34 [estimate_with_func.py:307] Request job id arriving: 142, time is 1761207154.5328088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:34 [estimate_with_func.py:315] Request job id: 142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,535] LMCache INFO:[0m Reqid: chatcmpl-84627f9920c74f439a85943ebbbf843c, Total tokens 22738, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:34,575] LMCache INFO:[0m Retrieved 12032 out of 12032 required tokens (from 12032 total tokens). size: 1.4688 gb, cost 31.5399 ms, throughput: 46.5680 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,069] LMCache INFO:[0m Storing KV cache for 7936 out of 19968 tokens (skip_leading_tokens=12032) for request chatcmpl-84627f9920c74f439a85943ebbbf843c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,091] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.5983 ms, throughput: 44.8530 GB/s; offload_time: 21.5489 ms, put_time: 0.0494 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,098] LMCache INFO:[0m Reqid: chatcmpl-0ad7d6116f104003aa55a368a838a3b5, Total tokens 49172, LMCache hit tokens: 35328, need to load: 35312 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,401] LMCache INFO:[0m Storing KV cache for 2770 out of 22738 tokens (skip_leading_tokens=19968) for request chatcmpl-84627f9920c74f439a85943ebbbf843c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,409] LMCache INFO:[0m Stored 2770 out of total 2770 tokens. size: 0.3381 gb, cost 7.8054 ms, throughput: 43.3205 GB/s; offload_time: 7.7845 ms, put_time: 0.0209 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,414] LMCache INFO:[0m Reqid: chatcmpl-0ad7d6116f104003aa55a368a838a3b5, Total tokens 49172, LMCache hit tokens: 35328, need to load: 35312 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:35 [estimate_with_func.py:328] Request job id finishing: 77, time is 1761207155.5062063
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:35 [scheduler.py:1462] Request GPU size bytes: 1658978304
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:35 [scheduler.py:1463] Token size of the request: 12644
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:35 [scheduler.py:1469] Swap waste for job 77: 0.05150146484375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:35 [scheduler.py:1479] Accumulated tokens for job 77: 1107866
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:35 [scheduler.py:1481] Discard waste for job 77: 989.6081537181606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:35 [scheduler.py:1484] Preserve waste for job 77: 1.184403194470352
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,508] LMCache INFO:[0m Reqid: chatcmpl-0ad7d6116f104003aa55a368a838a3b5, Total tokens 49172, LMCache hit tokens: 35328, need to load: 35312 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:35,617] LMCache INFO:[0m Retrieved 35328 out of 35328 required tokens (from 35328 total tokens). size: 4.3125 gb, cost 93.0999 ms, throughput: 46.3212 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:36,416] LMCache INFO:[0m Storing KV cache for 7936 out of 43264 tokens (skip_leading_tokens=35328) for request chatcmpl-0ad7d6116f104003aa55a368a838a3b5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:36,439] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.3379 ms, throughput: 43.3681 GB/s; offload_time: 22.2913 ms, put_time: 0.0466 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:36,445] LMCache INFO:[0m Reqid: chatcmpl-647b662721e74d988e7819fa5816a225, Total tokens 6088, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,123] LMCache INFO:[0m Storing KV cache for 5908 out of 49172 tokens (skip_leading_tokens=43264) for request chatcmpl-0ad7d6116f104003aa55a368a838a3b5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,141] LMCache INFO:[0m Stored 5908 out of total 5908 tokens. size: 0.7212 gb, cost 17.5364 ms, throughput: 41.1255 GB/s; offload_time: 17.4928 ms, put_time: 0.0435 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,146] LMCache INFO:[0m Reqid: chatcmpl-647b662721e74d988e7819fa5816a225, Total tokens 6088, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,239] LMCache INFO:[0m Reqid: chatcmpl-647b662721e74d988e7819fa5816a225, Total tokens 6088, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '77', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [estimate_with_func.py:307] Request job id arriving: 77, time is 1761207157.3283925
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [estimate_with_func.py:315] Request job id: 77
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,330] LMCache INFO:[0m Reqid: chatcmpl-647b662721e74d988e7819fa5816a225, Total tokens 6088, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207157.418721
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1462] Request GPU size bytes: 5389942784
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1463] Token size of the request: 40978
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1469] Swap waste for job 79: 0.16732584635416667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1479] Accumulated tokens for job 79: 1144394
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1481] Discard waste for job 79: 1055.3445123703752
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1484] Preserve waste for job 79: 1.187966344076828
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [estimate_with_func.py:328] Request job id finishing: 17, time is 1761207157.4193525
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,421] LMCache INFO:[0m Reqid: chatcmpl-647b662721e74d988e7819fa5816a225, Total tokens 6088, LMCache hit tokens: 4096, need to load: 4080 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,424] LMCache INFO:[0m Reqid: chatcmpl-9c8abec8f358452abe20688a3edaa2c7, Total tokens 38352, LMCache hit tokens: 11520, need to load: 11504 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,441] LMCache INFO:[0m Retrieved 4096 out of 4096 required tokens (from 4096 total tokens). size: 0.5000 gb, cost 10.8248 ms, throughput: 46.1901 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,471] LMCache INFO:[0m Retrieved 11520 out of 11520 required tokens (from 11520 total tokens). size: 1.4062 gb, cost 30.0802 ms, throughput: 46.7500 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,913] LMCache INFO:[0m Storing KV cache for 1992 out of 6088 tokens (skip_leading_tokens=4096) for request chatcmpl-647b662721e74d988e7819fa5816a225 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,919] LMCache INFO:[0m Stored 1992 out of total 1992 tokens. size: 0.2432 gb, cost 5.5745 ms, throughput: 43.6207 GB/s; offload_time: 5.5574 ms, put_time: 0.0171 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,919] LMCache INFO:[0m Storing KV cache for 6144 out of 17664 tokens (skip_leading_tokens=11520) for request chatcmpl-9c8abec8f358452abe20688a3edaa2c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:37,935] LMCache INFO:[0m Stored 6144 out of total 6144 tokens. size: 0.7500 gb, cost 16.4180 ms, throughput: 45.6815 GB/s; offload_time: 16.3817 ms, put_time: 0.0363 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207157.9380455
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1462] Request GPU size bytes: 5917114368
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1463] Token size of the request: 45132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1469] Swap waste for job 16: 0.18369140625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1479] Accumulated tokens for job 16: 1092003
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1481] Discard waste for job 16: 961.7190528521024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:37 [scheduler.py:1484] Preserve waste for job 16: 1.187966344076828
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '16', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '79', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:38,505] LMCache INFO:[0m Storing KV cache for 7936 out of 25600 tokens (skip_leading_tokens=17664) for request chatcmpl-9c8abec8f358452abe20688a3edaa2c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:38,527] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3885 ms, throughput: 45.2930 GB/s; offload_time: 21.3380 ms, put_time: 0.0505 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:38 [estimate_with_func.py:307] Request job id arriving: 16, time is 1761207158.5295167
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:38 [estimate_with_func.py:315] Request job id: 16
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:38 [estimate_with_func.py:307] Request job id arriving: 79, time is 1761207158.5296857
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:38 [estimate_with_func.py:315] Request job id: 79
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,196] LMCache INFO:[0m Storing KV cache for 8192 out of 33792 tokens (skip_leading_tokens=25600) for request chatcmpl-9c8abec8f358452abe20688a3edaa2c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,219] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.6072 ms, throughput: 44.2337 GB/s; offload_time: 22.5663 ms, put_time: 0.0409 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:39 [estimate_with_func.py:328] Request job id finishing: 130, time is 1761207159.2218814
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:39 [scheduler.py:1462] Request GPU size bytes: 862060544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:39 [scheduler.py:1463] Token size of the request: 6300
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:39 [scheduler.py:1469] Swap waste for job 130: 0.026761881510416665
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:39 [scheduler.py:1479] Accumulated tokens for job 130: 1046871
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:39 [scheduler.py:1481] Discard waste for job 130: 884.5516541445852
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:39 [scheduler.py:1484] Preserve waste for job 130: 3.0893150364988236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,225] LMCache INFO:[0m Reqid: chatcmpl-b4f686f69f3e458db8f3ee710ee5769d, Total tokens 10928, LMCache hit tokens: 7936, need to load: 7920 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,228] LMCache INFO:[0m Reqid: chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0, Total tokens 41831, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,255] LMCache INFO:[0m Retrieved 7936 out of 7936 required tokens (from 7936 total tokens). size: 0.9688 gb, cost 20.9210 ms, throughput: 46.3052 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,826] LMCache INFO:[0m Storing KV cache for 2992 out of 10928 tokens (skip_leading_tokens=7936) for request chatcmpl-b4f686f69f3e458db8f3ee710ee5769d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,834] LMCache INFO:[0m Stored 2992 out of total 2992 tokens. size: 0.3652 gb, cost 8.2758 ms, throughput: 44.1327 GB/s; offload_time: 8.2532 ms, put_time: 0.0226 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,834] LMCache INFO:[0m Storing KV cache for 768 out of 768 tokens (skip_leading_tokens=0) for request chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,837] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.1327 ms, throughput: 43.9576 GB/s; offload_time: 2.1233 ms, put_time: 0.0095 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,837] LMCache INFO:[0m Storing KV cache for 4560 out of 38352 tokens (skip_leading_tokens=33792) for request chatcmpl-9c8abec8f358452abe20688a3edaa2c7 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:39,850] LMCache INFO:[0m Stored 4560 out of total 4560 tokens. size: 0.5566 gb, cost 12.8613 ms, throughput: 43.2802 GB/s; offload_time: 12.8388 ms, put_time: 0.0226 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:40,208] LMCache INFO:[0m Storing KV cache for 7936 out of 8704 tokens (skip_leading_tokens=768) for request chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:40,229] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3315 ms, throughput: 45.4142 GB/s; offload_time: 21.2822 ms, put_time: 0.0492 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:40 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207160.2320027
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:40 [scheduler.py:1462] Request GPU size bytes: 2412773376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:40 [scheduler.py:1463] Token size of the request: 18384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:40 [scheduler.py:1469] Swap waste for job 133: 0.07490234375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:40 [scheduler.py:1479] Accumulated tokens for job 133: 1093330
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:40 [scheduler.py:1481] Discard waste for job 133: 964.0368049065199
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:40 [scheduler.py:1484] Preserve waste for job 133: 1.1842453822246573
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:12:40 [loggers.py:123] Engine 000: Avg prompt throughput: 26088.7 tokens/s, Avg generation throughput: 116.5 tokens/s, Running: 46 reqs, Waiting: 30 reqs, GPU KV cache usage: 91.1%, Prefix cache hit rate: 13.5%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:40,693] LMCache INFO:[0m Storing KV cache for 8192 out of 16896 tokens (skip_leading_tokens=8704) for request chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:40,716] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0158 ms, throughput: 45.4219 GB/s; offload_time: 21.9694 ms, put_time: 0.0465 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:41,281] LMCache INFO:[0m Storing KV cache for 8192 out of 25088 tokens (skip_leading_tokens=16896) for request chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:41,304] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.3230 ms, throughput: 44.7969 GB/s; offload_time: 22.2588 ms, put_time: 0.0642 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207161.3069732
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [scheduler.py:1462] Request GPU size bytes: 2492596224
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [scheduler.py:1463] Token size of the request: 18975
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [scheduler.py:1469] Swap waste for job 10: 0.07738037109375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [scheduler.py:1479] Accumulated tokens for job 10: 1074946
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [scheduler.py:1481] Discard waste for job 10: 932.1754658756975
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [scheduler.py:1484] Preserve waste for job 10: 1.1842453822246573
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:41,963] LMCache INFO:[0m Storing KV cache for 8192 out of 33280 tokens (skip_leading_tokens=25088) for request chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:41,986] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.0590 ms, throughput: 43.3671 GB/s; offload_time: 23.0047 ms, put_time: 0.0543 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207161.989266
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [estimate_with_func.py:315] Request job id: 133
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207161.989475
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:41 [estimate_with_func.py:315] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,755] LMCache INFO:[0m Storing KV cache for 8192 out of 41472 tokens (skip_leading_tokens=33280) for request chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,779] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.4551 ms, throughput: 42.6346 GB/s; offload_time: 23.4058 ms, put_time: 0.0493 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,784] LMCache INFO:[0m Reqid: chatcmpl-0ff01ccee7264e029d714b2db52e689b, Total tokens 8352, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,787] LMCache INFO:[0m Reqid: chatcmpl-058ed30718044f63a1600e86b59a7fbf, Total tokens 8790, LMCache hit tokens: 5632, need to load: 5616 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,792] LMCache INFO:[0m Reqid: chatcmpl-500db609046749539e0e8881596b6982, Total tokens 62558, LMCache hit tokens: 17920, need to load: 17904 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,814] LMCache INFO:[0m Retrieved 5120 out of 5120 required tokens (from 5120 total tokens). size: 0.6250 gb, cost 13.6690 ms, throughput: 45.7240 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,829] LMCache INFO:[0m Retrieved 5632 out of 5632 required tokens (from 5632 total tokens). size: 0.6875 gb, cost 14.7629 ms, throughput: 46.5694 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:42,876] LMCache INFO:[0m Retrieved 17920 out of 17920 required tokens (from 17920 total tokens). size: 2.1875 gb, cost 46.7519 ms, throughput: 46.7895 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,290] LMCache INFO:[0m Storing KV cache for 3232 out of 8352 tokens (skip_leading_tokens=5120) for request chatcmpl-0ff01ccee7264e029d714b2db52e689b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,299] LMCache INFO:[0m Stored 3232 out of total 3232 tokens. size: 0.3945 gb, cost 8.8833 ms, throughput: 44.4125 GB/s; offload_time: 8.8577 ms, put_time: 0.0257 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,300] LMCache INFO:[0m Storing KV cache for 3158 out of 8790 tokens (skip_leading_tokens=5632) for request chatcmpl-058ed30718044f63a1600e86b59a7fbf [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,308] LMCache INFO:[0m Stored 3158 out of total 3158 tokens. size: 0.3855 gb, cost 8.5838 ms, throughput: 44.9100 GB/s; offload_time: 8.5631 ms, put_time: 0.0207 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,308] LMCache INFO:[0m Storing KV cache for 1280 out of 19200 tokens (skip_leading_tokens=17920) for request chatcmpl-500db609046749539e0e8881596b6982 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,312] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.6909 ms, throughput: 42.3340 GB/s; offload_time: 3.6795 ms, put_time: 0.0114 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,313] LMCache INFO:[0m Storing KV cache for 359 out of 41831 tokens (skip_leading_tokens=41472) for request chatcmpl-c53550fe39ed4e5fa0e1d699df2f63e0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,315] LMCache INFO:[0m Stored 359 out of total 359 tokens. size: 0.0438 gb, cost 1.9411 ms, throughput: 22.5763 GB/s; offload_time: 1.9283 ms, put_time: 0.0129 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [estimate_with_func.py:328] Request job id finishing: 107, time is 1761207163.317863
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,913] LMCache INFO:[0m Storing KV cache for 8192 out of 27392 tokens (skip_leading_tokens=19200) for request chatcmpl-500db609046749539e0e8881596b6982 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:43,936] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1153 ms, throughput: 45.2175 GB/s; offload_time: 22.0738 ms, put_time: 0.0415 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [estimate_with_func.py:328] Request job id finishing: 129, time is 1761207163.9384153
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [scheduler.py:1462] Request GPU size bytes: 1227751424
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [scheduler.py:1463] Token size of the request: 9323
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [scheduler.py:1469] Swap waste for job 129: 0.03811442057291667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [scheduler.py:1479] Accumulated tokens for job 129: 1126019
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [scheduler.py:1481] Discard waste for job 129: 1022.0124002071101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:43 [scheduler.py:1484] Preserve waste for job 129: 3.0893150364988236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:44,638] LMCache INFO:[0m Storing KV cache for 8192 out of 35584 tokens (skip_leading_tokens=27392) for request chatcmpl-500db609046749539e0e8881596b6982 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:44,661] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.2320 ms, throughput: 43.0440 GB/s; offload_time: 23.1588 ms, put_time: 0.0732 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:45,465] LMCache INFO:[0m Storing KV cache for 8192 out of 43776 tokens (skip_leading_tokens=35584) for request chatcmpl-500db609046749539e0e8881596b6982 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:45,489] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.9311 ms, throughput: 43.6090 GB/s; offload_time: 22.8844 ms, put_time: 0.0466 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '130', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:41468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:46,391] LMCache INFO:[0m Storing KV cache for 7936 out of 51712 tokens (skip_leading_tokens=43776) for request chatcmpl-500db609046749539e0e8881596b6982 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:46,414] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.5353 ms, throughput: 42.9881 GB/s; offload_time: 22.4871 ms, put_time: 0.0482 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:46 [estimate_with_func.py:307] Request job id arriving: 130, time is 1761207166.4174812
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:46 [estimate_with_func.py:315] Request job id: 130
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '129', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:47,425] LMCache INFO:[0m Storing KV cache for 8192 out of 59904 tokens (skip_leading_tokens=51712) for request chatcmpl-500db609046749539e0e8881596b6982 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:47,449] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.1612 ms, throughput: 43.1757 GB/s; offload_time: 23.1069 ms, put_time: 0.0543 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:47 [estimate_with_func.py:307] Request job id arriving: 129, time is 1761207167.4523468
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:47 [estimate_with_func.py:315] Request job id: 129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:47,454] LMCache INFO:[0m Reqid: chatcmpl-f88311dec744415da941e8a8f7b0b354, Total tokens 6344, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,012] LMCache INFO:[0m Storing KV cache for 5632 out of 5632 tokens (skip_leading_tokens=0) for request chatcmpl-f88311dec744415da941e8a8f7b0b354 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,027] LMCache INFO:[0m Stored 5632 out of total 5632 tokens. size: 0.6875 gb, cost 15.2106 ms, throughput: 45.1988 GB/s; offload_time: 15.1736 ms, put_time: 0.0370 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,028] LMCache INFO:[0m Storing KV cache for 2654 out of 62558 tokens (skip_leading_tokens=59904) for request chatcmpl-500db609046749539e0e8881596b6982 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,037] LMCache INFO:[0m Stored 2654 out of total 2654 tokens. size: 0.3240 gb, cost 8.5866 ms, throughput: 37.7302 GB/s; offload_time: 8.5676 ms, put_time: 0.0190 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [estimate_with_func.py:328] Request job id finishing: 143, time is 1761207168.0393605
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1462] Request GPU size bytes: 726532096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1463] Token size of the request: 5245
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1469] Swap waste for job 143: 0.022554524739583335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1479] Accumulated tokens for job 143: 1123040
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1481] Discard waste for job 143: 1016.6588975245237
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1484] Preserve waste for job 143: 3.108929731113054
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,045] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 27648, need to load: 27632 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,237] LMCache INFO:[0m Storing KV cache for 712 out of 6344 tokens (skip_leading_tokens=5632) for request chatcmpl-f88311dec744415da941e8a8f7b0b354 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,240] LMCache INFO:[0m Stored 712 out of total 712 tokens. size: 0.0869 gb, cost 2.1595 ms, throughput: 40.2465 GB/s; offload_time: 2.1467 ms, put_time: 0.0128 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [estimate_with_func.py:328] Request job id finishing: 117, time is 1761207168.241981
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1462] Request GPU size bytes: 1434189824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1463] Token size of the request: 10928
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1469] Swap waste for job 117: 0.04452311197916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1479] Accumulated tokens for job 117: 1117795
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1481] Discard waste for job 117: 1007.2673726904711
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:48 [scheduler.py:1484] Preserve waste for job 117: 1.184634826222404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,244] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 27648, need to load: 27632 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:48,324] LMCache INFO:[0m Retrieved 27648 out of 27648 required tokens (from 27648 total tokens). size: 3.3750 gb, cost 72.7103 ms, throughput: 46.4171 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,022] LMCache INFO:[0m Storing KV cache for 7936 out of 35584 tokens (skip_leading_tokens=27648) for request chatcmpl-24a1b85353c94ff7b597400c3eb79e5d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,045] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.6259 ms, throughput: 42.8160 GB/s; offload_time: 22.5782 ms, put_time: 0.0477 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,140] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '117', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58750 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:49 [estimate_with_func.py:307] Request job id arriving: 117, time is 1761207169.223757
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:49 [estimate_with_func.py:315] Request job id: 117
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,227] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,314] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,402] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,488] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,575] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,662] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,750] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,837] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:49 [estimate_with_func.py:328] Request job id finishing: 87, time is 1761207169.920525
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,924] LMCache INFO:[0m Reqid: chatcmpl-24a1b85353c94ff7b597400c3eb79e5d, Total tokens 39390, LMCache hit tokens: 35584, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,927] LMCache INFO:[0m Reqid: chatcmpl-066a9f88568b48b7b0a5b8a5e25d1e71, Total tokens 15693, LMCache hit tokens: 5888, need to load: 5872 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:49,949] LMCache INFO:[0m Retrieved 5888 out of 5888 required tokens (from 5888 total tokens). size: 0.7188 gb, cost 15.7536 ms, throughput: 45.6246 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:50,510] LMCache INFO:[0m Storing KV cache for 4352 out of 10240 tokens (skip_leading_tokens=5888) for request chatcmpl-066a9f88568b48b7b0a5b8a5e25d1e71 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:50,522] LMCache INFO:[0m Stored 4352 out of total 4352 tokens. size: 0.5312 gb, cost 11.9811 ms, throughput: 44.3405 GB/s; offload_time: 11.9501 ms, put_time: 0.0310 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:50,523] LMCache INFO:[0m Storing KV cache for 3806 out of 39390 tokens (skip_leading_tokens=35584) for request chatcmpl-24a1b85353c94ff7b597400c3eb79e5d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:50,534] LMCache INFO:[0m Stored 3806 out of total 3806 tokens. size: 0.4646 gb, cost 11.4783 ms, throughput: 40.4762 GB/s; offload_time: 11.4535 ms, put_time: 0.0248 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:50 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207170.537183
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:50 [scheduler.py:1462] Request GPU size bytes: 889847808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:50 [scheduler.py:1463] Token size of the request: 6750
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:50 [scheduler.py:1469] Swap waste for job 97: 0.02762451171875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:50 [scheduler.py:1479] Accumulated tokens for job 97: 1127996
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:50 [scheduler.py:1481] Discard waste for job 97: 1025.5729881469788
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:50 [scheduler.py:1484] Preserve waste for job 97: 1.1835325787896696
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:50,540] LMCache INFO:[0m Reqid: chatcmpl-d5e7a6d9c6c947ebbbb4389d17499181, Total tokens 11079, LMCache hit tokens: 7168, need to load: 7152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:50,562] LMCache INFO:[0m Retrieved 7168 out of 7168 required tokens (from 7168 total tokens). size: 0.8750 gb, cost 18.8310 ms, throughput: 46.4659 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:12:50 [loggers.py:123] Engine 000: Avg prompt throughput: 16726.0 tokens/s, Avg generation throughput: 108.3 tokens/s, Running: 45 reqs, Waiting: 29 reqs, GPU KV cache usage: 97.5%, Prefix cache hit rate: 17.1%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,006] LMCache INFO:[0m Storing KV cache for 2816 out of 9984 tokens (skip_leading_tokens=7168) for request chatcmpl-d5e7a6d9c6c947ebbbb4389d17499181 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,014] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 7.7720 ms, throughput: 44.2291 GB/s; offload_time: 7.7503 ms, put_time: 0.0217 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,014] LMCache INFO:[0m Storing KV cache for 5453 out of 15693 tokens (skip_leading_tokens=10240) for request chatcmpl-066a9f88568b48b7b0a5b8a5e25d1e71 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,029] LMCache INFO:[0m Stored 5453 out of total 5453 tokens. size: 0.6656 gb, cost 14.6816 ms, throughput: 45.3389 GB/s; offload_time: 14.6509 ms, put_time: 0.0308 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,034] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,394] LMCache INFO:[0m Storing KV cache for 6912 out of 6912 tokens (skip_leading_tokens=0) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,413] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 18.5400 ms, throughput: 45.5097 GB/s; offload_time: 18.5032 ms, put_time: 0.0368 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,413] LMCache INFO:[0m Storing KV cache for 1095 out of 11079 tokens (skip_leading_tokens=9984) for request chatcmpl-d5e7a6d9c6c947ebbbb4389d17499181 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,416] LMCache INFO:[0m Stored 1095 out of total 1095 tokens. size: 0.1337 gb, cost 3.1923 ms, throughput: 41.8721 GB/s; offload_time: 3.1782 ms, put_time: 0.0140 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,507] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 6912, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [estimate_with_func.py:328] Request job id finishing: 60, time is 1761207171.5876932
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1462] Request GPU size bytes: 247201792
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1463] Token size of the request: 1578
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1469] Swap waste for job 60: 0.007674153645833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1479] Accumulated tokens for job 60: 1132325
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1481] Discard waste for job 60: 1033.3911612339439
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1484] Preserve waste for job 60: 3.108929731113054
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,590] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 6912, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [estimate_with_func.py:328] Request job id finishing: 103, time is 1761207171.6763587
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1462] Request GPU size bytes: 1780875264
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1463] Token size of the request: 13545
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1469] Swap waste for job 103: 0.05528564453125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1479] Accumulated tokens for job 103: 1130747
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1481] Discard waste for job 103: 1030.5378554994045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:51 [scheduler.py:1484] Preserve waste for job 103: 3.108929731113054
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:51,680] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 6912, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:52,122] LMCache INFO:[0m Storing KV cache for 8192 out of 15104 tokens (skip_leading_tokens=6912) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:52,144] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.2047 ms, throughput: 45.0356 GB/s; offload_time: 22.1530 ms, put_time: 0.0517 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:52 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207172.1471772
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:52 [estimate_with_func.py:315] Request job id: 97
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:52,697] LMCache INFO:[0m Storing KV cache for 8192 out of 23296 tokens (skip_leading_tokens=15104) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:52,720] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1391 ms, throughput: 45.1689 GB/s; offload_time: 22.0566 ms, put_time: 0.0826 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:52,814] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 23296, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:52,899] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 23296, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:52,984] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 23296, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:53 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207173.0645597
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:53 [scheduler.py:1462] Request GPU size bytes: 2986475520
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:53 [scheduler.py:1463] Token size of the request: 22738
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:53 [scheduler.py:1469] Swap waste for job 173: 0.09271240234375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:53 [scheduler.py:1479] Accumulated tokens for job 173: 1117202
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:53 [scheduler.py:1481] Discard waste for job 173: 1006.2083081543234
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:53 [scheduler.py:1484] Preserve waste for job 173: 1.18583793253512
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:53,068] LMCache INFO:[0m Reqid: chatcmpl-fd9608a6af1a4be39efe791de403ca74, Total tokens 81106, LMCache hit tokens: 23296, need to load: -128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:53,714] LMCache INFO:[0m Storing KV cache for 8192 out of 31488 tokens (skip_leading_tokens=23296) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:53,737] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.4420 ms, throughput: 44.5594 GB/s; offload_time: 22.3753 ms, put_time: 0.0666 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '60', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '103', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59218 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '143', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:52836 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:54,494] LMCache INFO:[0m Storing KV cache for 8192 out of 39680 tokens (skip_leading_tokens=31488) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:54,518] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.4319 ms, throughput: 42.6769 GB/s; offload_time: 23.3847 ms, put_time: 0.0472 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:328] Request job id finishing: 144, time is 1761207174.5213668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [scheduler.py:1462] Request GPU size bytes: 5164761088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [scheduler.py:1463] Token size of the request: 39390
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [scheduler.py:1469] Swap waste for job 144: 0.16033528645833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [scheduler.py:1479] Accumulated tokens for job 144: 1175570
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [scheduler.py:1481] Discard waste for job 144: 1113.121002038779
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [scheduler.py:1484] Preserve waste for job 144: 1.18583793253512
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:307] Request job id arriving: 60, time is 1761207174.5223038
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:315] Request job id: 60
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:307] Request job id arriving: 103, time is 1761207174.5225024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:315] Request job id: 103
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:307] Request job id arriving: 143, time is 1761207174.522595
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:315] Request job id: 143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207174.5226917
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:54 [estimate_with_func.py:315] Request job id: 173
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '144', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:55,373] LMCache INFO:[0m Storing KV cache for 8192 out of 47872 tokens (skip_leading_tokens=39680) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:55,398] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.8104 ms, throughput: 41.9985 GB/s; offload_time: 23.7495 ms, put_time: 0.0609 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:55 [estimate_with_func.py:307] Request job id arriving: 144, time is 1761207175.4010265
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:55 [estimate_with_func.py:315] Request job id: 144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:56,352] LMCache INFO:[0m Storing KV cache for 7936 out of 55808 tokens (skip_leading_tokens=47872) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:56,375] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.9554 ms, throughput: 42.2013 GB/s; offload_time: 22.9021 ms, put_time: 0.0533 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:56 [estimate_with_func.py:328] Request job id finishing: 160, time is 1761207176.378297
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:56 [scheduler.py:1462] Request GPU size bytes: 2036727808
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:56 [scheduler.py:1463] Token size of the request: 15392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:56 [scheduler.py:1469] Swap waste for job 160: 0.06322835286458334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:56 [scheduler.py:1479] Accumulated tokens for job 160: 1136180
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:56 [scheduler.py:1481] Discard waste for job 160: 1040.3782769996162
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:56 [scheduler.py:1484] Preserve waste for job 160: 3.1214815836686354
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:57,434] LMCache INFO:[0m Storing KV cache for 8192 out of 64000 tokens (skip_leading_tokens=55808) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:57,460] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.1117 ms, throughput: 41.4737 GB/s; offload_time: 24.0546 ms, put_time: 0.0571 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:58,622] LMCache INFO:[0m Storing KV cache for 8192 out of 72192 tokens (skip_leading_tokens=64000) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '160', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:58,652] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 27.8724 ms, throughput: 35.8777 GB/s; offload_time: 27.8041 ms, put_time: 0.0683 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:58 [estimate_with_func.py:328] Request job id finishing: 36, time is 1761207178.654627
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:58 [estimate_with_func.py:307] Request job id arriving: 160, time is 1761207178.6556628
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:12:58 [estimate_with_func.py:315] Request job id: 160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:59,924] LMCache INFO:[0m Storing KV cache for 8192 out of 80384 tokens (skip_leading_tokens=72192) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:59,950] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.3299 ms, throughput: 41.1017 GB/s; offload_time: 24.2705 ms, put_time: 0.0594 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:59,956] LMCache INFO:[0m Reqid: chatcmpl-118da710e855430da08ff3d5eaca68e3, Total tokens 27041, LMCache hit tokens: 19712, need to load: 19696 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:12:59,979] LMCache INFO:[0m Reqid: chatcmpl-d61e6beba45e4d848fd8703358acd5d0, Total tokens 26885, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:00,036] LMCache INFO:[0m Retrieved 19712 out of 19712 required tokens (from 19712 total tokens). size: 2.4062 gb, cost 51.9667 ms, throughput: 46.3037 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:13:00 [loggers.py:123] Engine 000: Avg prompt throughput: 2677.1 tokens/s, Avg generation throughput: 78.4 tokens/s, Running: 41 reqs, Waiting: 34 reqs, GPU KV cache usage: 96.2%, Prefix cache hit rate: 17.1%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:00,674] LMCache INFO:[0m Storing KV cache for 7329 out of 27041 tokens (skip_leading_tokens=19712) for request chatcmpl-118da710e855430da08ff3d5eaca68e3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:00,695] LMCache INFO:[0m Stored 7329 out of total 7329 tokens. size: 0.8947 gb, cost 20.2578 ms, throughput: 44.1633 GB/s; offload_time: 20.2075 ms, put_time: 0.0503 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:00,696] LMCache INFO:[0m Storing KV cache for 722 out of 81106 tokens (skip_leading_tokens=80384) for request chatcmpl-fd9608a6af1a4be39efe791de403ca74 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:00,700] LMCache INFO:[0m Stored 722 out of total 722 tokens. size: 0.0881 gb, cost 4.1501 ms, throughput: 21.2366 GB/s; offload_time: 4.1359 ms, put_time: 0.0142 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [estimate_with_func.py:328] Request job id finishing: 146, time is 1761207180.702748
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1462] Request GPU size bytes: 2622619648
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1463] Token size of the request: 19809
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1469] Swap waste for job 146: 0.08141682942708334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1479] Accumulated tokens for job 146: 1155041
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1481] Discard waste for job 146: 1074.902811585503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1484] Preserve waste for job 146: 3.1178896224245114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [estimate_with_func.py:328] Request job id finishing: 66, time is 1761207180.7035673
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1462] Request GPU size bytes: 1454505984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1463] Token size of the request: 11079
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1469] Swap waste for job 66: 0.04515380859375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1479] Accumulated tokens for job 66: 1155041
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1481] Discard waste for job 66: 1074.902811585503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:00 [scheduler.py:1484] Preserve waste for job 66: 1.1856566635682622
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:01,060] LMCache INFO:[0m Storing KV cache for 8192 out of 8192 tokens (skip_leading_tokens=0) for request chatcmpl-d61e6beba45e4d848fd8703358acd5d0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:01,083] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.3179 ms, throughput: 44.8071 GB/s; offload_time: 22.2617 ms, put_time: 0.0562 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '66', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:01,546] LMCache INFO:[0m Storing KV cache for 8192 out of 16384 tokens (skip_leading_tokens=8192) for request chatcmpl-d61e6beba45e4d848fd8703358acd5d0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:01,568] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.9525 ms, throughput: 45.5529 GB/s; offload_time: 21.9039 ms, put_time: 0.0486 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:01 [estimate_with_func.py:328] Request job id finishing: 78, time is 1761207181.570587
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:01 [estimate_with_func.py:307] Request job id arriving: 66, time is 1761207181.5717468
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:01 [estimate_with_func.py:315] Request job id: 66
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:02,127] LMCache INFO:[0m Storing KV cache for 8192 out of 24576 tokens (skip_leading_tokens=16384) for request chatcmpl-d61e6beba45e4d848fd8703358acd5d0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:02,150] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.2831 ms, throughput: 44.8770 GB/s; offload_time: 22.2282 ms, put_time: 0.0549 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [estimate_with_func.py:328] Request job id finishing: 99, time is 1761207182.1524827
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1462] Request GPU size bytes: 318111744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1463] Token size of the request: 2100
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1469] Swap waste for job 99: 0.00987548828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1479] Accumulated tokens for job 99: 1052411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1481] Discard waste for job 99: 893.8503190266043
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1484] Preserve waste for job 99: 3.1178896224245114
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207182.1531456
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1462] Request GPU size bytes: 5488377856
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1463] Token size of the request: 41831
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1469] Swap waste for job 138: 0.17038167317708333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1479] Accumulated tokens for job 138: 1052411
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1481] Discard waste for job 138: 893.8503190266043
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:02 [scheduler.py:1484] Preserve waste for job 138: 1.1839682941741132
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:02,156] LMCache INFO:[0m Reqid: chatcmpl-3656150617b44bac85efbc9724c610e1, Total tokens 15770, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:02,556] LMCache INFO:[0m Storing KV cache for 5888 out of 5888 tokens (skip_leading_tokens=0) for request chatcmpl-3656150617b44bac85efbc9724c610e1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:02,572] LMCache INFO:[0m Stored 5888 out of total 5888 tokens. size: 0.7188 gb, cost 15.8940 ms, throughput: 45.2215 GB/s; offload_time: 15.8517 ms, put_time: 0.0423 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:02,572] LMCache INFO:[0m Storing KV cache for 2309 out of 26885 tokens (skip_leading_tokens=24576) for request chatcmpl-d61e6beba45e4d848fd8703358acd5d0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:02,579] LMCache INFO:[0m Stored 2309 out of total 2309 tokens. size: 0.2819 gb, cost 6.6013 ms, throughput: 42.6977 GB/s; offload_time: 6.5837 ms, put_time: 0.0176 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,000] LMCache INFO:[0m Storing KV cache for 8192 out of 14080 tokens (skip_leading_tokens=5888) for request chatcmpl-3656150617b44bac85efbc9724c610e1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,022] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.5985 ms, throughput: 44.2508 GB/s; offload_time: 22.5268 ms, put_time: 0.0717 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207183.0256867
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [estimate_with_func.py:315] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,028] LMCache INFO:[0m Reqid: chatcmpl-644a0e5bc6da45989481754fca5d81dc, Total tokens 7037, LMCache hit tokens: 5120, need to load: 5104 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,030] LMCache INFO:[0m Reqid: chatcmpl-76d5feb6528a410d9c87b9d28e9c677f, Total tokens 17509, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,047] LMCache INFO:[0m Retrieved 5120 out of 5120 required tokens (from 5120 total tokens). size: 0.6250 gb, cost 13.5382 ms, throughput: 46.1656 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '146', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:39144 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,402] LMCache INFO:[0m Storing KV cache for 1917 out of 7037 tokens (skip_leading_tokens=5120) for request chatcmpl-644a0e5bc6da45989481754fca5d81dc [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,408] LMCache INFO:[0m Stored 1917 out of total 1917 tokens. size: 0.2340 gb, cost 5.6483 ms, throughput: 41.4297 GB/s; offload_time: 5.6262 ms, put_time: 0.0221 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,408] LMCache INFO:[0m Storing KV cache for 4352 out of 4352 tokens (skip_leading_tokens=0) for request chatcmpl-76d5feb6528a410d9c87b9d28e9c677f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,420] LMCache INFO:[0m Stored 4352 out of total 4352 tokens. size: 0.5312 gb, cost 11.5811 ms, throughput: 45.8723 GB/s; offload_time: 11.5531 ms, put_time: 0.0280 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,420] LMCache INFO:[0m Storing KV cache for 1690 out of 15770 tokens (skip_leading_tokens=14080) for request chatcmpl-3656150617b44bac85efbc9724c610e1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,425] LMCache INFO:[0m Stored 1690 out of total 1690 tokens. size: 0.2063 gb, cost 4.7789 ms, throughput: 43.1689 GB/s; offload_time: 4.7641 ms, put_time: 0.0148 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [estimate_with_func.py:328] Request job id finishing: 111, time is 1761207183.4274914
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [estimate_with_func.py:307] Request job id arriving: 146, time is 1761207183.4289181
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [estimate_with_func.py:315] Request job id: 146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,819] LMCache INFO:[0m Storing KV cache for 8192 out of 12544 tokens (skip_leading_tokens=4352) for request chatcmpl-76d5feb6528a410d9c87b9d28e9c677f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,842] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.5347 ms, throughput: 44.3760 GB/s; offload_time: 22.4607 ms, put_time: 0.0740 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [estimate_with_func.py:328] Request job id finishing: 152, time is 1761207183.8449607
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1462] Request GPU size bytes: 3359506432
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1463] Token size of the request: 25510
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1469] Swap waste for job 152: 0.10429280598958333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1479] Accumulated tokens for job 152: 965177
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1481] Discard waste for job 152: 753.0756693077358
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1484] Preserve waste for job 152: 1.182321031257589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [estimate_with_func.py:328] Request job id finishing: 119, time is 1761207183.8457544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1462] Request GPU size bytes: 1158152192
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1463] Token size of the request: 8790
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1469] Swap waste for job 119: 0.03595377604166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1479] Accumulated tokens for job 119: 965177
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1481] Discard waste for job 119: 753.0756693077358
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:03 [scheduler.py:1484] Preserve waste for job 119: 1.182321031257589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,849] LMCache INFO:[0m Reqid: chatcmpl-748c16928e5543e08a57d796495064ce, Total tokens 25515, LMCache hit tokens: 9216, need to load: 9200 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:03,882] LMCache INFO:[0m Retrieved 9216 out of 9216 required tokens (from 9216 total tokens). size: 1.1250 gb, cost 24.1744 ms, throughput: 46.5367 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '152', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:04,317] LMCache INFO:[0m Storing KV cache for 3328 out of 12544 tokens (skip_leading_tokens=9216) for request chatcmpl-748c16928e5543e08a57d796495064ce [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:04,327] LMCache INFO:[0m Stored 3328 out of total 3328 tokens. size: 0.4062 gb, cost 9.4458 ms, throughput: 43.0083 GB/s; offload_time: 9.4205 ms, put_time: 0.0254 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:04,327] LMCache INFO:[0m Storing KV cache for 4965 out of 17509 tokens (skip_leading_tokens=12544) for request chatcmpl-76d5feb6528a410d9c87b9d28e9c677f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:04,341] LMCache INFO:[0m Stored 4965 out of total 4965 tokens. size: 0.6061 gb, cost 13.5022 ms, throughput: 44.8876 GB/s; offload_time: 13.4695 ms, put_time: 0.0327 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [estimate_with_func.py:328] Request job id finishing: 110, time is 1761207184.3435974
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [scheduler.py:1462] Request GPU size bytes: 836763648
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [scheduler.py:1463] Token size of the request: 6344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [scheduler.py:1469] Swap waste for job 110: 0.0259765625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [scheduler.py:1479] Accumulated tokens for job 110: 956392
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [scheduler.py:1481] Discard waste for job 110: 739.5668571942058
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [scheduler.py:1484] Preserve waste for job 110: 1.182321031257589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [estimate_with_func.py:307] Request job id arriving: 152, time is 1761207184.3441567
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:04 [estimate_with_func.py:315] Request job id: 152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:04,836] LMCache INFO:[0m Storing KV cache for 8192 out of 20736 tokens (skip_leading_tokens=12544) for request chatcmpl-748c16928e5543e08a57d796495064ce [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:04,859] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.3136 ms, throughput: 44.8157 GB/s; offload_time: 22.2548 ms, put_time: 0.0589 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:04,865] LMCache INFO:[0m Reqid: chatcmpl-f15e22ab196c4c3fb6e068aa85039415, Total tokens 30949, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:05,322] LMCache INFO:[0m Storing KV cache for 3328 out of 3328 tokens (skip_leading_tokens=0) for request chatcmpl-f15e22ab196c4c3fb6e068aa85039415 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:05,331] LMCache INFO:[0m Stored 3328 out of total 3328 tokens. size: 0.4062 gb, cost 9.2143 ms, throughput: 44.0888 GB/s; offload_time: 9.1832 ms, put_time: 0.0311 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:05,332] LMCache INFO:[0m Storing KV cache for 4779 out of 25515 tokens (skip_leading_tokens=20736) for request chatcmpl-748c16928e5543e08a57d796495064ce [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:05,345] LMCache INFO:[0m Stored 4779 out of total 4779 tokens. size: 0.5834 gb, cost 13.1034 ms, throughput: 44.5207 GB/s; offload_time: 13.0712 ms, put_time: 0.0322 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [estimate_with_func.py:328] Request job id finishing: 165, time is 1761207185.3473125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [scheduler.py:1462] Request GPU size bytes: 531890176
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [scheduler.py:1463] Token size of the request: 3807
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [scheduler.py:1469] Swap waste for job 165: 0.016512044270833335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [scheduler.py:1479] Accumulated tokens for job 165: 980997
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [scheduler.py:1481] Discard waste for job 165: 777.7105760214638
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [scheduler.py:1484] Preserve waste for job 165: 3.1162298119674294
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [estimate_with_func.py:328] Request job id finishing: 162, time is 1761207185.3476746
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [estimate_with_func.py:328] Request job id finishing: 159, time is 1761207185.347852
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '110', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '99', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58526 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:05,725] LMCache INFO:[0m Storing KV cache for 8192 out of 11520 tokens (skip_leading_tokens=3328) for request chatcmpl-f15e22ab196c4c3fb6e068aa85039415 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:05,747] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1764 ms, throughput: 45.0930 GB/s; offload_time: 22.1120 ms, put_time: 0.0644 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [estimate_with_func.py:307] Request job id arriving: 110, time is 1761207185.7499478
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [estimate_with_func.py:315] Request job id: 110
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [estimate_with_func.py:307] Request job id arriving: 99, time is 1761207185.7501862
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:05 [estimate_with_func.py:315] Request job id: 99
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:06,230] LMCache INFO:[0m Storing KV cache for 8192 out of 19712 tokens (skip_leading_tokens=11520) for request chatcmpl-f15e22ab196c4c3fb6e068aa85039415 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:06,252] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0644 ms, throughput: 45.3219 GB/s; offload_time: 22.0157 ms, put_time: 0.0486 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:06,839] LMCache INFO:[0m Storing KV cache for 7936 out of 27648 tokens (skip_leading_tokens=19712) for request chatcmpl-f15e22ab196c4c3fb6e068aa85039415 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:06,862] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.2468 ms, throughput: 43.5456 GB/s; offload_time: 22.1812 ms, put_time: 0.0656 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:06,868] LMCache INFO:[0m Reqid: chatcmpl-88805e338ea54ff0b2069d2d26585252, Total tokens 4883, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:06,874] LMCache INFO:[0m Reqid: chatcmpl-10ae88a10fd64529aa421405f9525af0, Total tokens 50415, LMCache hit tokens: 36864, need to load: 36848 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '119', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:53286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:06,981] LMCache INFO:[0m Retrieved 36864 out of 36864 required tokens (from 36864 total tokens). size: 4.5000 gb, cost 96.9860 ms, throughput: 46.3985 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:07,436] LMCache INFO:[0m Storing KV cache for 4883 out of 4883 tokens (skip_leading_tokens=0) for request chatcmpl-88805e338ea54ff0b2069d2d26585252 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:07,449] LMCache INFO:[0m Stored 4883 out of total 4883 tokens. size: 0.5961 gb, cost 13.5476 ms, throughput: 43.9981 GB/s; offload_time: 13.5074 ms, put_time: 0.0402 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:07,450] LMCache INFO:[0m Storing KV cache for 3301 out of 30949 tokens (skip_leading_tokens=27648) for request chatcmpl-f15e22ab196c4c3fb6e068aa85039415 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:07,459] LMCache INFO:[0m Stored 3301 out of total 3301 tokens. size: 0.4030 gb, cost 9.2717 ms, throughput: 43.4608 GB/s; offload_time: 9.2511 ms, put_time: 0.0205 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:07 [estimate_with_func.py:307] Request job id arriving: 119, time is 1761207187.462263
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:07 [estimate_with_func.py:315] Request job id: 119
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '165', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34246 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:08,263] LMCache INFO:[0m Storing KV cache for 8192 out of 45056 tokens (skip_leading_tokens=36864) for request chatcmpl-10ae88a10fd64529aa421405f9525af0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:08,288] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.4467 ms, throughput: 42.6499 GB/s; offload_time: 23.3940 ms, put_time: 0.0527 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:08 [estimate_with_func.py:307] Request job id arriving: 165, time is 1761207188.2906227
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:08 [estimate_with_func.py:315] Request job id: 165
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:08,295] LMCache INFO:[0m Reqid: chatcmpl-177834e885ca424a85827a64219bbb3c, Total tokens 65632, LMCache hit tokens: 49152, need to load: 49136 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:08,439] LMCache INFO:[0m Retrieved 49152 out of 49152 required tokens (from 49152 total tokens). size: 6.0000 gb, cost 130.3632 ms, throughput: 46.0253 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:09,331] LMCache INFO:[0m Storing KV cache for 2816 out of 51968 tokens (skip_leading_tokens=49152) for request chatcmpl-177834e885ca424a85827a64219bbb3c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:09,342] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 9.5068 ms, throughput: 36.1584 GB/s; offload_time: 9.4803 ms, put_time: 0.0265 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:09,343] LMCache INFO:[0m Storing KV cache for 5359 out of 50415 tokens (skip_leading_tokens=45056) for request chatcmpl-10ae88a10fd64529aa421405f9525af0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:09,359] LMCache INFO:[0m Stored 5359 out of total 5359 tokens. size: 0.6542 gb, cost 16.2405 ms, throughput: 40.2804 GB/s; offload_time: 16.2022 ms, put_time: 0.0383 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:10,354] LMCache INFO:[0m Storing KV cache for 8192 out of 60160 tokens (skip_leading_tokens=51968) for request chatcmpl-177834e885ca424a85827a64219bbb3c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:10,380] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.5460 ms, throughput: 40.7399 GB/s; offload_time: 24.4831 ms, put_time: 0.0629 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:10,387] LMCache INFO:[0m Reqid: chatcmpl-056b77b318d04dd499937518d65ba6a9, Total tokens 29574, LMCache hit tokens: 21248, need to load: 21232 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:10,461] LMCache INFO:[0m Retrieved 21248 out of 21248 required tokens (from 21248 total tokens). size: 2.5938 gb, cost 55.9995 ms, throughput: 46.3174 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:13:10 [loggers.py:123] Engine 000: Avg prompt throughput: 28709.3 tokens/s, Avg generation throughput: 68.4 tokens/s, Running: 39 reqs, Waiting: 32 reqs, GPU KV cache usage: 94.4%, Prefix cache hit rate: 16.6%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,362] LMCache INFO:[0m Storing KV cache for 2560 out of 23808 tokens (skip_leading_tokens=21248) for request chatcmpl-056b77b318d04dd499937518d65ba6a9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,370] LMCache INFO:[0m Stored 2560 out of total 2560 tokens. size: 0.3125 gb, cost 7.7898 ms, throughput: 40.1168 GB/s; offload_time: 7.7600 ms, put_time: 0.0297 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,371] LMCache INFO:[0m Storing KV cache for 5472 out of 65632 tokens (skip_leading_tokens=60160) for request chatcmpl-177834e885ca424a85827a64219bbb3c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,388] LMCache INFO:[0m Stored 5472 out of total 5472 tokens. size: 0.6680 gb, cost 16.7046 ms, throughput: 39.9871 GB/s; offload_time: 16.6604 ms, put_time: 0.0442 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,397] LMCache INFO:[0m Reqid: chatcmpl-2bf1a35ab61b4382847df911281ff0b8, Total tokens 75015, LMCache hit tokens: 59648, need to load: 59632 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,887] LMCache INFO:[0m Storing KV cache for 5766 out of 29574 tokens (skip_leading_tokens=23808) for request chatcmpl-056b77b318d04dd499937518d65ba6a9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,903] LMCache INFO:[0m Stored 5766 out of total 5766 tokens. size: 0.7039 gb, cost 15.7350 ms, throughput: 44.7319 GB/s; offload_time: 15.7000 ms, put_time: 0.0350 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:11 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207191.9052136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:11 [scheduler.py:1462] Request GPU size bytes: 6454378496
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:11 [scheduler.py:1463] Token size of the request: 49172
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:11 [scheduler.py:1469] Swap waste for job 44: 0.20037027994791667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:11 [scheduler.py:1479] Accumulated tokens for job 44: 1115861
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:11 [scheduler.py:1481] Discard waste for job 44: 1003.8154118364708
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:11 [scheduler.py:1484] Preserve waste for job 44: 3.1175267736450967
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:11,909] LMCache INFO:[0m Reqid: chatcmpl-2bf1a35ab61b4382847df911281ff0b8, Total tokens 75015, LMCache hit tokens: 59648, need to load: 59632 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:12,079] LMCache INFO:[0m Retrieved 59648 out of 59648 required tokens (from 59648 total tokens). size: 7.2812 gb, cost 156.5805 ms, throughput: 46.5016 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:13,184] LMCache INFO:[0m Storing KV cache for 7936 out of 67584 tokens (skip_leading_tokens=59648) for request chatcmpl-2bf1a35ab61b4382847df911281ff0b8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:13,209] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 23.2453 ms, throughput: 41.6751 GB/s; offload_time: 23.1807 ms, put_time: 0.0646 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:13 [estimate_with_func.py:328] Request job id finishing: 101, time is 1761207193.2117326
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:13 [scheduler.py:1462] Request GPU size bytes: 2068971520
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:13 [scheduler.py:1463] Token size of the request: 15770
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:13 [scheduler.py:1469] Swap waste for job 101: 0.06422932942708333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:13 [scheduler.py:1479] Accumulated tokens for job 101: 1141704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:13 [scheduler.py:1481] Discard waste for job 101: 1050.4314566156706
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:13 [scheduler.py:1484] Preserve waste for job 101: 3.1175267736450967
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:13,216] LMCache INFO:[0m Reqid: chatcmpl-8bc68e76a9cf443ab2b60dd45ba13315, Total tokens 37270, LMCache hit tokens: 11776, need to load: 11760 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:13,253] LMCache INFO:[0m Retrieved 11776 out of 11776 required tokens (from 11776 total tokens). size: 1.4375 gb, cost 31.1280 ms, throughput: 46.1803 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:14,361] LMCache INFO:[0m Storing KV cache for 768 out of 12544 tokens (skip_leading_tokens=11776) for request chatcmpl-8bc68e76a9cf443ab2b60dd45ba13315 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:14,364] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.7056 ms, throughput: 34.6501 GB/s; offload_time: 2.6877 ms, put_time: 0.0179 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:14,365] LMCache INFO:[0m Storing KV cache for 7431 out of 75015 tokens (skip_leading_tokens=67584) for request chatcmpl-2bf1a35ab61b4382847df911281ff0b8 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:14,387] LMCache INFO:[0m Stored 7431 out of total 7431 tokens. size: 0.9071 gb, cost 22.2042 ms, throughput: 40.8529 GB/s; offload_time: 22.1615 ms, put_time: 0.0427 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207194.3900347
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1462] Request GPU size bytes: 924450816
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1463] Token size of the request: 7037
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1469] Swap waste for job 122: 0.02869873046875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1479] Accumulated tokens for job 122: 1163204
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1481] Discard waste for job 122: 1090.019664850184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1484] Preserve waste for job 122: 1.192608582476775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [estimate_with_func.py:328] Request job id finishing: 121, time is 1761207194.390383
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1462] Request GPU size bytes: 2296774656
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1463] Token size of the request: 17509
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1469] Swap waste for job 121: 0.07130126953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1479] Accumulated tokens for job 121: 1163204
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1481] Discard waste for job 121: 1090.019664850184
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [scheduler.py:1484] Preserve waste for job 121: 1.192608582476775
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '121', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:14,906] LMCache INFO:[0m Storing KV cache for 8192 out of 20736 tokens (skip_leading_tokens=12544) for request chatcmpl-8bc68e76a9cf443ab2b60dd45ba13315 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:14,928] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.9854 ms, throughput: 45.4847 GB/s; offload_time: 21.9402 ms, put_time: 0.0453 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [estimate_with_func.py:307] Request job id arriving: 121, time is 1761207194.9309473
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:14 [estimate_with_func.py:315] Request job id: 121
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '44', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '101', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:15,548] LMCache INFO:[0m Storing KV cache for 8192 out of 28928 tokens (skip_leading_tokens=20736) for request chatcmpl-8bc68e76a9cf443ab2b60dd45ba13315 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:15,571] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1476 ms, throughput: 45.1516 GB/s; offload_time: 22.0895 ms, put_time: 0.0581 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:15 [estimate_with_func.py:307] Request job id arriving: 44, time is 1761207195.5733871
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:15 [estimate_with_func.py:315] Request job id: 44
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:15 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207195.5735798
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:15 [estimate_with_func.py:315] Request job id: 122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:15 [estimate_with_func.py:307] Request job id arriving: 101, time is 1761207195.5736668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:15 [estimate_with_func.py:315] Request job id: 101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,300] LMCache INFO:[0m Storing KV cache for 8192 out of 37120 tokens (skip_leading_tokens=28928) for request chatcmpl-8bc68e76a9cf443ab2b60dd45ba13315 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,324] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.2403 ms, throughput: 43.0287 GB/s; offload_time: 23.1945 ms, put_time: 0.0457 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,328] LMCache INFO:[0m Reqid: chatcmpl-0627eb3f39fe41d2bedc79b173620d6d, Total tokens 2245, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,330] LMCache INFO:[0m Reqid: chatcmpl-ce3f56faf9a7494c9f6d94dd5a36515b, Total tokens 23652, LMCache hit tokens: 13568, need to load: 13552 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,554] LMCache INFO:[0m Storing KV cache for 2245 out of 2245 tokens (skip_leading_tokens=0) for request chatcmpl-0627eb3f39fe41d2bedc79b173620d6d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,561] LMCache INFO:[0m Stored 2245 out of total 2245 tokens. size: 0.2740 gb, cost 6.2253 ms, throughput: 44.0219 GB/s; offload_time: 6.2057 ms, put_time: 0.0196 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:16 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207196.5630674
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:16 [scheduler.py:1462] Request GPU size bytes: 3526754304
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:16 [scheduler.py:1463] Token size of the request: 26885
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:16 [scheduler.py:1469] Swap waste for job 156: 0.10948486328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:16 [scheduler.py:1479] Accumulated tokens for job 156: 1140903
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:16 [scheduler.py:1481] Discard waste for job 156: 1048.9707129976202
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:16 [scheduler.py:1484] Preserve waste for job 156: 1.1892010022684472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,565] LMCache INFO:[0m Reqid: chatcmpl-ce3f56faf9a7494c9f6d94dd5a36515b, Total tokens 23652, LMCache hit tokens: 13568, need to load: 13552 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:16,606] LMCache INFO:[0m Retrieved 13568 out of 13568 required tokens (from 13568 total tokens). size: 1.6562 gb, cost 35.7579 ms, throughput: 46.3184 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,128] LMCache INFO:[0m Storing KV cache for 7936 out of 21504 tokens (skip_leading_tokens=13568) for request chatcmpl-ce3f56faf9a7494c9f6d94dd5a36515b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,151] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.2935 ms, throughput: 43.4544 GB/s; offload_time: 21.4758 ms, put_time: 0.8177 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,156] LMCache INFO:[0m Reqid: chatcmpl-1e8d923ff0204b3e8f158be94011519e, Total tokens 24700, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '156', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:60200 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,434] LMCache INFO:[0m Storing KV cache for 2148 out of 23652 tokens (skip_leading_tokens=21504) for request chatcmpl-ce3f56faf9a7494c9f6d94dd5a36515b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,441] LMCache INFO:[0m Stored 2148 out of total 2148 tokens. size: 0.2622 gb, cost 6.2217 ms, throughput: 42.1442 GB/s; offload_time: 6.2053 ms, put_time: 0.0163 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [estimate_with_func.py:328] Request job id finishing: 134, time is 1761207197.442785
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [estimate_with_func.py:307] Request job id arriving: 156, time is 1761207197.4432764
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [estimate_with_func.py:315] Request job id: 156
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,445] LMCache INFO:[0m Reqid: chatcmpl-1e8d923ff0204b3e8f158be94011519e, Total tokens 24700, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,528] LMCache INFO:[0m Reqid: chatcmpl-1e8d923ff0204b3e8f158be94011519e, Total tokens 24700, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,605] LMCache INFO:[0m Reqid: chatcmpl-1e8d923ff0204b3e8f158be94011519e, Total tokens 24700, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [estimate_with_func.py:328] Request job id finishing: 149, time is 1761207197.6802623
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1462] Request GPU size bytes: 254017536
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1463] Token size of the request: 1538
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1469] Swap waste for job 149: 0.0078857421875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1479] Accumulated tokens for job 149: 1134915
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1481] Discard waste for job 149: 1038.0828932198244
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1484] Preserve waste for job 149: 3.116672746340434
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,682] LMCache INFO:[0m Reqid: chatcmpl-1e8d923ff0204b3e8f158be94011519e, Total tokens 24700, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,774] LMCache INFO:[0m Reqid: chatcmpl-1e8d923ff0204b3e8f158be94011519e, Total tokens 24700, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207197.8639767
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1462] Request GPU size bytes: 2063597568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1463] Token size of the request: 15693
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1469] Swap waste for job 102: 0.0640625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1479] Accumulated tokens for job 102: 1133377
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1481] Discard waste for job 102: 1035.2955562885588
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:17 [scheduler.py:1484] Preserve waste for job 102: 3.116672746340434
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,866] LMCache INFO:[0m Reqid: chatcmpl-1e8d923ff0204b3e8f158be94011519e, Total tokens 24700, LMCache hit tokens: 12032, need to load: 12016 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:17,910] LMCache INFO:[0m Retrieved 12032 out of 12032 required tokens (from 12032 total tokens). size: 1.4688 gb, cost 31.5475 ms, throughput: 46.5568 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:18,406] LMCache INFO:[0m Storing KV cache for 7936 out of 19968 tokens (skip_leading_tokens=12032) for request chatcmpl-1e8d923ff0204b3e8f158be94011519e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:18,428] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.6028 ms, throughput: 44.8437 GB/s; offload_time: 21.5533 ms, put_time: 0.0495 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:18,434] LMCache INFO:[0m Reqid: chatcmpl-e7b254a99bad4f66a3473f7ed5e72a2d, Total tokens 41146, LMCache hit tokens: 24064, need to load: 24048 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:18,839] LMCache INFO:[0m Storing KV cache for 4732 out of 24700 tokens (skip_leading_tokens=19968) for request chatcmpl-1e8d923ff0204b3e8f158be94011519e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:18,852] LMCache INFO:[0m Stored 4732 out of total 4732 tokens. size: 0.5776 gb, cost 13.2290 ms, throughput: 43.6644 GB/s; offload_time: 13.1941 ms, put_time: 0.0350 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207198.8548717
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1462] Request GPU size bytes: 4059299840
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1463] Token size of the request: 30949
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1469] Swap waste for job 174: 0.12601725260416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1479] Accumulated tokens for job 174: 1142384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1481] Discard waste for job 174: 1051.672336180499
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1484] Preserve waste for job 174: 3.116672746340434
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207198.8554027
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1462] Request GPU size bytes: 8604745728
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1463] Token size of the request: 65632
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1469] Swap waste for job 150: 0.26712646484375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1479] Accumulated tokens for job 150: 1142384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1481] Discard waste for job 150: 1051.672336180499
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:18 [scheduler.py:1484] Preserve waste for job 150: 1.187616446079352
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:18,859] LMCache INFO:[0m Reqid: chatcmpl-e7b254a99bad4f66a3473f7ed5e72a2d, Total tokens 41146, LMCache hit tokens: 24064, need to load: 24048 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:18,929] LMCache INFO:[0m Retrieved 24064 out of 24064 required tokens (from 24064 total tokens). size: 2.9375 gb, cost 63.2074 ms, throughput: 46.4740 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '150', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59108 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:19,575] LMCache INFO:[0m Storing KV cache for 7936 out of 32000 tokens (skip_leading_tokens=24064) for request chatcmpl-e7b254a99bad4f66a3473f7ed5e72a2d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:19,597] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.6058 ms, throughput: 44.8374 GB/s; offload_time: 21.5627 ms, put_time: 0.0431 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:19 [estimate_with_func.py:307] Request job id arriving: 150, time is 1761207199.599725
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:19 [estimate_with_func.py:315] Request job id: 150
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '149', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,357] LMCache INFO:[0m Storing KV cache for 8192 out of 40192 tokens (skip_leading_tokens=32000) for request chatcmpl-e7b254a99bad4f66a3473f7ed5e72a2d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,382] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.6552 ms, throughput: 42.2740 GB/s; offload_time: 23.6047 ms, put_time: 0.0504 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [estimate_with_func.py:307] Request job id arriving: 149, time is 1761207200.3851023
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [estimate_with_func.py:315] Request job id: 149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207200.3853536
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [estimate_with_func.py:315] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,387] LMCache INFO:[0m Reqid: chatcmpl-faac416225d34c5190c876887a86236b, Total tokens 12352, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:13:20 [loggers.py:123] Engine 000: Avg prompt throughput: 25806.7 tokens/s, Avg generation throughput: 71.5 tokens/s, Running: 36 reqs, Waiting: 31 reqs, GPU KV cache usage: 94.8%, Prefix cache hit rate: 15.6%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,770] LMCache INFO:[0m Storing KV cache for 7168 out of 7168 tokens (skip_leading_tokens=0) for request chatcmpl-faac416225d34c5190c876887a86236b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,790] LMCache INFO:[0m Stored 7168 out of total 7168 tokens. size: 0.8750 gb, cost 19.1670 ms, throughput: 45.6513 GB/s; offload_time: 19.1292 ms, put_time: 0.0378 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,790] LMCache INFO:[0m Storing KV cache for 954 out of 41146 tokens (skip_leading_tokens=40192) for request chatcmpl-e7b254a99bad4f66a3473f7ed5e72a2d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,794] LMCache INFO:[0m Stored 954 out of total 954 tokens. size: 0.1165 gb, cost 3.6446 ms, throughput: 31.9530 GB/s; offload_time: 3.6281 ms, put_time: 0.0165 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207200.7967262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [scheduler.py:1462] Request GPU size bytes: 9834594304
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [scheduler.py:1463] Token size of the request: 75015
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [scheduler.py:1469] Swap waste for job 164: 0.3053059895833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [scheduler.py:1479] Accumulated tokens for job 164: 1099301
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [scheduler.py:1481] Discard waste for job 164: 974.5003276549965
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:20 [scheduler.py:1484] Preserve waste for job 164: 1.1853551803802957
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:20,800] LMCache INFO:[0m Reqid: chatcmpl-a520e6c65c9842c68ac1c5cacbc6ce2f, Total tokens 30409, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '174', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:21,174] LMCache INFO:[0m Storing KV cache for 3072 out of 3072 tokens (skip_leading_tokens=0) for request chatcmpl-a520e6c65c9842c68ac1c5cacbc6ce2f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:21,182] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 8.3719 ms, throughput: 44.7926 GB/s; offload_time: 8.3497 ms, put_time: 0.0222 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:21,183] LMCache INFO:[0m Storing KV cache for 5184 out of 12352 tokens (skip_leading_tokens=7168) for request chatcmpl-faac416225d34c5190c876887a86236b [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:21,197] LMCache INFO:[0m Stored 5184 out of total 5184 tokens. size: 0.6328 gb, cost 13.9523 ms, throughput: 45.3553 GB/s; offload_time: 13.9235 ms, put_time: 0.0288 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:21 [estimate_with_func.py:307] Request job id arriving: 174, time is 1761207201.1993124
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:21 [estimate_with_func.py:315] Request job id: 174
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:21,583] LMCache INFO:[0m Storing KV cache for 8192 out of 11264 tokens (skip_leading_tokens=3072) for request chatcmpl-a520e6c65c9842c68ac1c5cacbc6ce2f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:21,606] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.9770 ms, throughput: 45.5020 GB/s; offload_time: 21.9315 ms, put_time: 0.0455 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:22,097] LMCache INFO:[0m Storing KV cache for 8192 out of 19456 tokens (skip_leading_tokens=11264) for request chatcmpl-a520e6c65c9842c68ac1c5cacbc6ce2f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:22,119] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.2303 ms, throughput: 44.9837 GB/s; offload_time: 22.1791 ms, put_time: 0.0512 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:22,716] LMCache INFO:[0m Storing KV cache for 8192 out of 27648 tokens (skip_leading_tokens=19456) for request chatcmpl-a520e6c65c9842c68ac1c5cacbc6ce2f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:22,739] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1514 ms, throughput: 45.1439 GB/s; offload_time: 22.1073 ms, put_time: 0.0441 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:22,744] LMCache INFO:[0m Reqid: chatcmpl-58ad6d4d4668441d871ba9b7e751d266, Total tokens 20181, LMCache hit tokens: 12544, need to load: 12528 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:22,785] LMCache INFO:[0m Retrieved 12544 out of 12544 required tokens (from 12544 total tokens). size: 1.5312 gb, cost 32.8442 ms, throughput: 46.6217 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '164', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:23,322] LMCache INFO:[0m Storing KV cache for 5376 out of 17920 tokens (skip_leading_tokens=12544) for request chatcmpl-58ad6d4d4668441d871ba9b7e751d266 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:23,338] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 14.7809 ms, throughput: 44.3986 GB/s; offload_time: 14.7457 ms, put_time: 0.0352 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:23,338] LMCache INFO:[0m Storing KV cache for 2761 out of 30409 tokens (skip_leading_tokens=27648) for request chatcmpl-a520e6c65c9842c68ac1c5cacbc6ce2f [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:23,346] LMCache INFO:[0m Stored 2761 out of total 2761 tokens. size: 0.3370 gb, cost 7.9885 ms, throughput: 42.1903 GB/s; offload_time: 7.9695 ms, put_time: 0.0190 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:23 [estimate_with_func.py:307] Request job id arriving: 164, time is 1761207203.3491013
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:23 [estimate_with_func.py:315] Request job id: 164
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:23,353] LMCache INFO:[0m Reqid: chatcmpl-a4aff856eece4587b7fe714cf286af15, Total tokens 62864, LMCache hit tokens: 45056, need to load: 45040 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:23,485] LMCache INFO:[0m Retrieved 45056 out of 45056 required tokens (from 45056 total tokens). size: 5.5000 gb, cost 119.3131 ms, throughput: 46.0972 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:24,284] LMCache INFO:[0m Storing KV cache for 5888 out of 50944 tokens (skip_leading_tokens=45056) for request chatcmpl-a4aff856eece4587b7fe714cf286af15 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:24,302] LMCache INFO:[0m Stored 5888 out of total 5888 tokens. size: 0.7188 gb, cost 17.6366 ms, throughput: 40.7534 GB/s; offload_time: 17.5936 ms, put_time: 0.0430 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:24,302] LMCache INFO:[0m Storing KV cache for 2261 out of 20181 tokens (skip_leading_tokens=17920) for request chatcmpl-58ad6d4d4668441d871ba9b7e751d266 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:24,309] LMCache INFO:[0m Stored 2261 out of total 2261 tokens. size: 0.2760 gb, cost 6.4961 ms, throughput: 42.4870 GB/s; offload_time: 6.4796 ms, put_time: 0.0165 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:25,296] LMCache INFO:[0m Storing KV cache for 8192 out of 59136 tokens (skip_leading_tokens=50944) for request chatcmpl-a4aff856eece4587b7fe714cf286af15 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:25,321] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.7274 ms, throughput: 42.1454 GB/s; offload_time: 23.6716 ms, put_time: 0.0557 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [estimate_with_func.py:328] Request job id finishing: 81, time is 1761207205.3237724
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [estimate_with_func.py:328] Request job id finishing: 93, time is 1761207205.3241153
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [estimate_with_func.py:328] Request job id finishing: 100, time is 1761207205.3245802
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [scheduler.py:1462] Request GPU size bytes: 296878080
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [scheduler.py:1463] Token size of the request: 2245
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [scheduler.py:1469] Swap waste for job 100: 0.00921630859375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [scheduler.py:1479] Accumulated tokens for job 100: 1137740
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [scheduler.py:1481] Discard waste for job 100: 1043.2124381824938
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:25 [scheduler.py:1484] Preserve waste for job 100: 3.1093502496005088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:25,328] LMCache INFO:[0m Reqid: chatcmpl-521d56bdbe304e1a81ac5830fc461b1d, Total tokens 52486, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:25,975] LMCache INFO:[0m Storing KV cache for 4352 out of 4352 tokens (skip_leading_tokens=0) for request chatcmpl-521d56bdbe304e1a81ac5830fc461b1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:25,988] LMCache INFO:[0m Stored 4352 out of total 4352 tokens. size: 0.5312 gb, cost 11.9610 ms, throughput: 44.4154 GB/s; offload_time: 11.9336 ms, put_time: 0.0273 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:25,988] LMCache INFO:[0m Storing KV cache for 3728 out of 62864 tokens (skip_leading_tokens=59136) for request chatcmpl-a4aff856eece4587b7fe714cf286af15 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:26,000] LMCache INFO:[0m Stored 3728 out of total 3728 tokens. size: 0.4551 gb, cost 11.5740 ms, throughput: 39.3189 GB/s; offload_time: 11.5532 ms, put_time: 0.0208 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:26,414] LMCache INFO:[0m Storing KV cache for 8192 out of 12544 tokens (skip_leading_tokens=4352) for request chatcmpl-521d56bdbe304e1a81ac5830fc461b1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:26,436] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1499 ms, throughput: 45.1469 GB/s; offload_time: 22.1030 ms, put_time: 0.0470 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:26,956] LMCache INFO:[0m Storing KV cache for 8192 out of 20736 tokens (skip_leading_tokens=12544) for request chatcmpl-521d56bdbe304e1a81ac5830fc461b1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:26,979] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1850 ms, throughput: 45.0754 GB/s; offload_time: 22.1398 ms, put_time: 0.0452 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:27,602] LMCache INFO:[0m Storing KV cache for 8192 out of 28928 tokens (skip_leading_tokens=20736) for request chatcmpl-521d56bdbe304e1a81ac5830fc461b1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:27,625] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0341 ms, throughput: 45.3842 GB/s; offload_time: 21.9871 ms, put_time: 0.0470 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '100', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:28,351] LMCache INFO:[0m Storing KV cache for 7936 out of 36864 tokens (skip_leading_tokens=28928) for request chatcmpl-521d56bdbe304e1a81ac5830fc461b1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:28,374] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.1712 ms, throughput: 43.6940 GB/s; offload_time: 22.1303 ms, put_time: 0.0410 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:28 [estimate_with_func.py:328] Request job id finishing: 24, time is 1761207208.3767495
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:28 [estimate_with_func.py:307] Request job id arriving: 100, time is 1761207208.378376
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:28 [estimate_with_func.py:315] Request job id: 100
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:29,187] LMCache INFO:[0m Storing KV cache for 8192 out of 45056 tokens (skip_leading_tokens=36864) for request chatcmpl-521d56bdbe304e1a81ac5830fc461b1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:29,211] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.8511 ms, throughput: 43.7615 GB/s; offload_time: 22.8015 ms, put_time: 0.0496 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:29,216] LMCache INFO:[0m Reqid: chatcmpl-b62c1550a5a144d6b91948d2f7ca9d45, Total tokens 24683, LMCache hit tokens: 18176, need to load: 18160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:29,271] LMCache INFO:[0m Retrieved 18176 out of 18176 required tokens (from 18176 total tokens). size: 2.2188 gb, cost 47.6961 ms, throughput: 46.5185 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,125] LMCache INFO:[0m Storing KV cache for 768 out of 18944 tokens (skip_leading_tokens=18176) for request chatcmpl-b62c1550a5a144d6b91948d2f7ca9d45 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,128] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.6965 ms, throughput: 34.7669 GB/s; offload_time: 2.6809 ms, put_time: 0.0156 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,129] LMCache INFO:[0m Storing KV cache for 7430 out of 52486 tokens (skip_leading_tokens=45056) for request chatcmpl-521d56bdbe304e1a81ac5830fc461b1d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,150] LMCache INFO:[0m Stored 7430 out of total 7430 tokens. size: 0.9070 gb, cost 21.1750 ms, throughput: 42.8326 GB/s; offload_time: 21.1365 ms, put_time: 0.0385 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [estimate_with_func.py:328] Request job id finishing: 91, time is 1761207210.1523247
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,157] LMCache INFO:[0m Reqid: chatcmpl-532f86bcb5484083a2244153adb24aff, Total tokens 24425, LMCache hit tokens: 18944, need to load: 18928 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,225] LMCache INFO:[0m Retrieved 18944 out of 18944 required tokens (from 18944 total tokens). size: 2.3125 gb, cost 62.0103 ms, throughput: 37.2922 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:13:30 [loggers.py:123] Engine 000: Avg prompt throughput: 21944.6 tokens/s, Avg generation throughput: 54.4 tokens/s, Running: 36 reqs, Waiting: 30 reqs, GPU KV cache usage: 88.7%, Prefix cache hit rate: 15.3%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,775] LMCache INFO:[0m Storing KV cache for 2560 out of 21504 tokens (skip_leading_tokens=18944) for request chatcmpl-532f86bcb5484083a2244153adb24aff [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,783] LMCache INFO:[0m Stored 2560 out of total 2560 tokens. size: 0.3125 gb, cost 7.2791 ms, throughput: 42.9310 GB/s; offload_time: 7.2544 ms, put_time: 0.0247 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,783] LMCache INFO:[0m Storing KV cache for 5739 out of 24683 tokens (skip_leading_tokens=18944) for request chatcmpl-b62c1550a5a144d6b91948d2f7ca9d45 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,799] LMCache INFO:[0m Stored 5739 out of total 5739 tokens. size: 0.7006 gb, cost 16.0151 ms, throughput: 43.7439 GB/s; offload_time: 15.9717 ms, put_time: 0.0433 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207210.8019462
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [scheduler.py:1462] Request GPU size bytes: 3239968768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [scheduler.py:1463] Token size of the request: 24700
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [scheduler.py:1469] Swap waste for job 68: 0.10058186848958334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [scheduler.py:1479] Accumulated tokens for job 68: 1046130
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [scheduler.py:1481] Discard waste for job 68: 883.3116018269535
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:30 [scheduler.py:1484] Preserve waste for job 68: 3.109122824473459
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:30,805] LMCache INFO:[0m Reqid: chatcmpl-50f32e86a7084551b2b6e7ff65bccf2e, Total tokens 10801, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,214] LMCache INFO:[0m Storing KV cache for 5120 out of 5120 tokens (skip_leading_tokens=0) for request chatcmpl-50f32e86a7084551b2b6e7ff65bccf2e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,228] LMCache INFO:[0m Stored 5120 out of total 5120 tokens. size: 0.6250 gb, cost 13.7813 ms, throughput: 45.3512 GB/s; offload_time: 13.7534 ms, put_time: 0.0279 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,228] LMCache INFO:[0m Storing KV cache for 2921 out of 24425 tokens (skip_leading_tokens=21504) for request chatcmpl-532f86bcb5484083a2244153adb24aff [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,236] LMCache INFO:[0m Stored 2921 out of total 2921 tokens. size: 0.3566 gb, cost 8.0858 ms, throughput: 44.0981 GB/s; offload_time: 8.0682 ms, put_time: 0.0176 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:31 [estimate_with_func.py:328] Request job id finishing: 90, time is 1761207211.2384925
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:31 [scheduler.py:1462] Request GPU size bytes: 1621098496
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:31 [scheduler.py:1463] Token size of the request: 12352
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:31 [scheduler.py:1469] Swap waste for job 90: 0.05032552083333333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:31 [scheduler.py:1479] Accumulated tokens for job 90: 1032231
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:31 [scheduler.py:1481] Discard waste for job 90: 860.2129891994405
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:31 [scheduler.py:1484] Preserve waste for job 90: 1.1922945770515403
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,241] LMCache INFO:[0m Reqid: chatcmpl-be68c9f8929e4eaeb70c786fd7301abe, Total tokens 13922, LMCache hit tokens: 9216, need to load: 9200 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,269] LMCache INFO:[0m Retrieved 9216 out of 9216 required tokens (from 9216 total tokens). size: 1.1250 gb, cost 24.1629 ms, throughput: 46.5589 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,677] LMCache INFO:[0m Storing KV cache for 2560 out of 11776 tokens (skip_leading_tokens=9216) for request chatcmpl-be68c9f8929e4eaeb70c786fd7301abe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,685] LMCache INFO:[0m Stored 2560 out of total 2560 tokens. size: 0.3125 gb, cost 7.1683 ms, throughput: 43.5946 GB/s; offload_time: 7.1469 ms, put_time: 0.0214 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,685] LMCache INFO:[0m Storing KV cache for 5681 out of 10801 tokens (skip_leading_tokens=5120) for request chatcmpl-50f32e86a7084551b2b6e7ff65bccf2e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,700] LMCache INFO:[0m Stored 5681 out of total 5681 tokens. size: 0.6935 gb, cost 15.2236 ms, throughput: 45.5531 GB/s; offload_time: 15.1945 ms, put_time: 0.0291 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,705] LMCache INFO:[0m Reqid: chatcmpl-045e9aa223c348bb9b8d9fbbedd1dcca, Total tokens 26466, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:31,737] LMCache INFO:[0m Retrieved 10752 out of 10752 required tokens (from 10752 total tokens). size: 1.3125 gb, cost 28.1463 ms, throughput: 46.6314 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,185] LMCache INFO:[0m Storing KV cache for 5888 out of 16640 tokens (skip_leading_tokens=10752) for request chatcmpl-045e9aa223c348bb9b8d9fbbedd1dcca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,201] LMCache INFO:[0m Stored 5888 out of total 5888 tokens. size: 0.7188 gb, cost 16.0767 ms, throughput: 44.7076 GB/s; offload_time: 16.0351 ms, put_time: 0.0416 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,202] LMCache INFO:[0m Storing KV cache for 2146 out of 13922 tokens (skip_leading_tokens=11776) for request chatcmpl-be68c9f8929e4eaeb70c786fd7301abe [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,208] LMCache INFO:[0m Stored 2146 out of total 2146 tokens. size: 0.2620 gb, cost 6.1463 ms, throughput: 42.6212 GB/s; offload_time: 6.1309 ms, put_time: 0.0154 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '90', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,762] LMCache INFO:[0m Storing KV cache for 8192 out of 24832 tokens (skip_leading_tokens=16640) for request chatcmpl-045e9aa223c348bb9b8d9fbbedd1dcca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,784] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0799 ms, throughput: 45.2900 GB/s; offload_time: 22.0348 ms, put_time: 0.0451 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:32 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207212.7866778
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:32 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:32 [estimate_with_func.py:307] Request job id arriving: 90, time is 1761207212.7869205
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:32 [estimate_with_func.py:315] Request job id: 90
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,789] LMCache INFO:[0m Reqid: chatcmpl-b29c088e89504762b931191b34612e48, Total tokens 10762, LMCache hit tokens: 6656, need to load: 6640 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,791] LMCache INFO:[0m Reqid: chatcmpl-75d421546b394963987edffbaee7502e, Total tokens 3267, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:32,812] LMCache INFO:[0m Retrieved 6656 out of 6656 required tokens (from 6656 total tokens). size: 0.8125 gb, cost 17.4985 ms, throughput: 46.4327 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,216] LMCache INFO:[0m Storing KV cache for 4106 out of 10762 tokens (skip_leading_tokens=6656) for request chatcmpl-b29c088e89504762b931191b34612e48 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,227] LMCache INFO:[0m Stored 4106 out of total 4106 tokens. size: 0.5012 gb, cost 11.3573 ms, throughput: 44.1321 GB/s; offload_time: 11.3266 ms, put_time: 0.0307 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,227] LMCache INFO:[0m Storing KV cache for 2560 out of 2560 tokens (skip_leading_tokens=0) for request chatcmpl-75d421546b394963987edffbaee7502e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,234] LMCache INFO:[0m Stored 2560 out of total 2560 tokens. size: 0.3125 gb, cost 6.8089 ms, throughput: 45.8961 GB/s; offload_time: 6.7942 ms, put_time: 0.0147 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,235] LMCache INFO:[0m Storing KV cache for 1634 out of 26466 tokens (skip_leading_tokens=24832) for request chatcmpl-045e9aa223c348bb9b8d9fbbedd1dcca [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,240] LMCache INFO:[0m Stored 1634 out of total 1634 tokens. size: 0.1995 gb, cost 4.9102 ms, throughput: 40.6219 GB/s; offload_time: 4.8977 ms, put_time: 0.0126 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,245] LMCache INFO:[0m Reqid: chatcmpl-c1802de734a54add86a17a9bfc584e5a, Total tokens 18254, LMCache hit tokens: 13312, need to load: 13296 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,249] LMCache INFO:[0m Reqid: chatcmpl-13ad3d765ee3494781fb7a4fc0bc9463, Total tokens 9731, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,287] LMCache INFO:[0m Retrieved 13312 out of 13312 required tokens (from 13312 total tokens). size: 1.6250 gb, cost 34.8412 ms, throughput: 46.6401 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,697] LMCache INFO:[0m Storing KV cache for 4942 out of 18254 tokens (skip_leading_tokens=13312) for request chatcmpl-c1802de734a54add86a17a9bfc584e5a [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,711] LMCache INFO:[0m Stored 4942 out of total 4942 tokens. size: 0.6033 gb, cost 13.5666 ms, throughput: 44.4675 GB/s; offload_time: 13.5294 ms, put_time: 0.0371 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,711] LMCache INFO:[0m Storing KV cache for 2304 out of 2304 tokens (skip_leading_tokens=0) for request chatcmpl-13ad3d765ee3494781fb7a4fc0bc9463 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,718] LMCache INFO:[0m Stored 2304 out of total 2304 tokens. size: 0.2812 gb, cost 6.2246 ms, throughput: 45.1835 GB/s; offload_time: 6.2100 ms, put_time: 0.0146 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,718] LMCache INFO:[0m Storing KV cache for 707 out of 3267 tokens (skip_leading_tokens=2560) for request chatcmpl-75d421546b394963987edffbaee7502e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,720] LMCache INFO:[0m Stored 707 out of total 707 tokens. size: 0.0863 gb, cost 2.0245 ms, throughput: 42.6298 GB/s; offload_time: 2.0142 ms, put_time: 0.0103 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,726] LMCache INFO:[0m Reqid: chatcmpl-95398fa6aaa74a69b49742944a1d9c3c, Total tokens 46281, LMCache hit tokens: 22528, need to load: 22512 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:33,795] LMCache INFO:[0m Retrieved 22528 out of 22528 required tokens (from 22528 total tokens). size: 2.7500 gb, cost 58.8414 ms, throughput: 46.7358 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:34,184] LMCache INFO:[0m Storing KV cache for 768 out of 23296 tokens (skip_leading_tokens=22528) for request chatcmpl-95398fa6aaa74a69b49742944a1d9c3c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:34,187] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.7431 ms, throughput: 34.1762 GB/s; offload_time: 2.7294 ms, put_time: 0.0137 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:34,187] LMCache INFO:[0m Storing KV cache for 7427 out of 9731 tokens (skip_leading_tokens=2304) for request chatcmpl-13ad3d765ee3494781fb7a4fc0bc9463 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:34,207] LMCache INFO:[0m Stored 7427 out of total 7427 tokens. size: 0.9066 gb, cost 19.9140 ms, throughput: 45.5267 GB/s; offload_time: 19.8802 ms, put_time: 0.0338 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:34,854] LMCache INFO:[0m Storing KV cache for 8192 out of 31488 tokens (skip_leading_tokens=23296) for request chatcmpl-95398fa6aaa74a69b49742944a1d9c3c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:34,877] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.4788 ms, throughput: 44.4864 GB/s; offload_time: 22.4145 ms, put_time: 0.0643 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:35,629] LMCache INFO:[0m Storing KV cache for 8192 out of 39680 tokens (skip_leading_tokens=31488) for request chatcmpl-95398fa6aaa74a69b49742944a1d9c3c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:35,653] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.8933 ms, throughput: 43.6809 GB/s; offload_time: 22.8516 ms, put_time: 0.0417 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:35,735] LMCache INFO:[0m Reqid: chatcmpl-95398fa6aaa74a69b49742944a1d9c3c, Total tokens 46281, LMCache hit tokens: 39680, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [estimate_with_func.py:328] Request job id finishing: 131, time is 1761207215.8040898
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1462] Request GPU size bytes: 2719612928
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1463] Token size of the request: 20548
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1469] Swap waste for job 131: 0.08442789713541667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1479] Accumulated tokens for job 131: 1102281
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1481] Discard waste for job 131: 979.7435762663868
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1484] Preserve waste for job 131: 3.104533590589251
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [estimate_with_func.py:328] Request job id finishing: 52, time is 1761207215.8046439
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1462] Request GPU size bytes: 3882221568
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1463] Token size of the request: 29574
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1469] Swap waste for job 52: 0.12052001953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1479] Accumulated tokens for job 52: 1102281
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1481] Discard waste for job 52: 979.7435762663868
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:35 [scheduler.py:1484] Preserve waste for job 52: 1.1940931238309302
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:35,809] LMCache INFO:[0m Reqid: chatcmpl-95398fa6aaa74a69b49742944a1d9c3c, Total tokens 46281, LMCache hit tokens: 39680, need to load: -112 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:35,814] LMCache INFO:[0m Reqid: chatcmpl-471c5c77636342119300e10a29b46aed, Total tokens 78507, LMCache hit tokens: 39168, need to load: 39152 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:35,929] LMCache INFO:[0m Retrieved 39168 out of 39168 required tokens (from 39168 total tokens). size: 4.7812 gb, cost 103.2484 ms, throughput: 46.3082 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:36,757] LMCache INFO:[0m Storing KV cache for 1536 out of 40704 tokens (skip_leading_tokens=39168) for request chatcmpl-471c5c77636342119300e10a29b46aed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:36,764] LMCache INFO:[0m Stored 1536 out of total 1536 tokens. size: 0.1875 gb, cost 5.5721 ms, throughput: 33.6499 GB/s; offload_time: 5.5438 ms, put_time: 0.0283 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:36,764] LMCache INFO:[0m Storing KV cache for 6601 out of 46281 tokens (skip_leading_tokens=39680) for request chatcmpl-95398fa6aaa74a69b49742944a1d9c3c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:36,784] LMCache INFO:[0m Stored 6601 out of total 6601 tokens. size: 0.8058 gb, cost 18.9057 ms, throughput: 42.6213 GB/s; offload_time: 18.8712 ms, put_time: 0.0345 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:36 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207216.7864645
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:36 [scheduler.py:1462] Request GPU size bytes: 3236954112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:36 [scheduler.py:1463] Token size of the request: 24683
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:36 [scheduler.py:1469] Swap waste for job 133: 0.10048828125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:36 [scheduler.py:1479] Accumulated tokens for job 133: 1176947
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:36 [scheduler.py:1481] Discard waste for job 133: 1115.7084092884236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:36 [scheduler.py:1484] Preserve waste for job 133: 1.1940931238309302
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '52', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58590 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '133', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:37,655] LMCache INFO:[0m Storing KV cache for 8192 out of 48896 tokens (skip_leading_tokens=40704) for request chatcmpl-471c5c77636342119300e10a29b46aed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:37,678] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.8316 ms, throughput: 43.7990 GB/s; offload_time: 22.7907 ms, put_time: 0.0409 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:37 [estimate_with_func.py:307] Request job id arriving: 52, time is 1761207217.6809704
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:37 [estimate_with_func.py:315] Request job id: 52
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:37 [estimate_with_func.py:307] Request job id arriving: 133, time is 1761207217.6815794
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:37 [estimate_with_func.py:315] Request job id: 133
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:38,650] LMCache INFO:[0m Storing KV cache for 8192 out of 57088 tokens (skip_leading_tokens=48896) for request chatcmpl-471c5c77636342119300e10a29b46aed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:38,674] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.2651 ms, throughput: 42.9828 GB/s; offload_time: 23.2186 ms, put_time: 0.0466 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '131', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:39,752] LMCache INFO:[0m Storing KV cache for 8192 out of 65280 tokens (skip_leading_tokens=57088) for request chatcmpl-471c5c77636342119300e10a29b46aed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:39,776] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.4747 ms, throughput: 42.5990 GB/s; offload_time: 23.4238 ms, put_time: 0.0509 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:39 [estimate_with_func.py:307] Request job id arriving: 131, time is 1761207219.7795649
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:39 [estimate_with_func.py:315] Request job id: 131
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:39,875] LMCache INFO:[0m Reqid: chatcmpl-471c5c77636342119300e10a29b46aed, Total tokens 78507, LMCache hit tokens: 65280, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:39,956] LMCache INFO:[0m Reqid: chatcmpl-471c5c77636342119300e10a29b46aed, Total tokens 78507, LMCache hit tokens: 65280, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:40,037] LMCache INFO:[0m Reqid: chatcmpl-471c5c77636342119300e10a29b46aed, Total tokens 78507, LMCache hit tokens: 65280, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:40,118] LMCache INFO:[0m Reqid: chatcmpl-471c5c77636342119300e10a29b46aed, Total tokens 78507, LMCache hit tokens: 65280, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:40 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207220.19414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:40 [scheduler.py:1462] Request GPU size bytes: 1412694016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:40 [scheduler.py:1463] Token size of the request: 10762
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:40 [scheduler.py:1469] Swap waste for job 97: 0.04385579427083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:40 [scheduler.py:1479] Accumulated tokens for job 97: 1073757
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:40 [scheduler.py:1481] Discard waste for job 97: 930.1332394271337
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:40 [scheduler.py:1484] Preserve waste for job 97: 1.196011747121811
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:40,199] LMCache INFO:[0m Reqid: chatcmpl-471c5c77636342119300e10a29b46aed, Total tokens 78507, LMCache hit tokens: 65280, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:13:40 [loggers.py:123] Engine 000: Avg prompt throughput: 18858.7 tokens/s, Avg generation throughput: 83.3 tokens/s, Running: 39 reqs, Waiting: 26 reqs, GPU KV cache usage: 92.9%, Prefix cache hit rate: 17.7%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:41,371] LMCache INFO:[0m Storing KV cache for 7936 out of 73216 tokens (skip_leading_tokens=65280) for request chatcmpl-471c5c77636342119300e10a29b46aed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:41,396] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 23.0086 ms, throughput: 42.1039 GB/s; offload_time: 22.9595 ms, put_time: 0.0490 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:41 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207221.398923
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:41 [estimate_with_func.py:315] Request job id: 97
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:41,402] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,308] LMCache INFO:[0m Storing KV cache for 3072 out of 3072 tokens (skip_leading_tokens=0) for request chatcmpl-3e1afe7c877c4449aba95cb5759401b2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,317] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 8.7595 ms, throughput: 42.8107 GB/s; offload_time: 8.7273 ms, put_time: 0.0322 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,318] LMCache INFO:[0m Storing KV cache for 5291 out of 78507 tokens (skip_leading_tokens=73216) for request chatcmpl-471c5c77636342119300e10a29b46aed [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,334] LMCache INFO:[0m Stored 5291 out of total 5291 tokens. size: 0.6459 gb, cost 16.0648 ms, throughput: 40.2043 GB/s; offload_time: 16.0372 ms, put_time: 0.0275 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [estimate_with_func.py:328] Request job id finishing: 140, time is 1761207222.4153829
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1462] Request GPU size bytes: 341442560
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1463] Token size of the request: 2457
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1469] Swap waste for job 140: 0.010599772135416666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1479] Accumulated tokens for job 140: 1141502
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1481] Discard waste for job 140: 1050.0629834951633
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1484] Preserve waste for job 140: 1.1960556459664113
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,418] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 3072, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,492] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 3072, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [estimate_with_func.py:328] Request job id finishing: 60, time is 1761207222.5643852
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1462] Request GPU size bytes: 430833664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1463] Token size of the request: 3267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1469] Swap waste for job 60: 0.013374837239583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1479] Accumulated tokens for job 60: 1139045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1481] Discard waste for job 60: 1045.586284110366
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1484] Preserve waste for job 60: 3.1080741649720727
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,566] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 3072, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [estimate_with_func.py:328] Request job id finishing: 143, time is 1761207222.6419697
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1462] Request GPU size bytes: 1278083072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1463] Token size of the request: 9731
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1469] Swap waste for job 143: 0.03967692057291667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1479] Accumulated tokens for job 143: 1135778
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1481] Discard waste for job 143: 1039.6485601213692
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:42 [scheduler.py:1484] Preserve waste for job 143: 3.1080741649720727
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:42,644] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 3072, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,032] LMCache INFO:[0m Storing KV cache for 7936 out of 11008 tokens (skip_leading_tokens=3072) for request chatcmpl-3e1afe7c877c4449aba95cb5759401b2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,054] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3723 ms, throughput: 45.3274 GB/s; offload_time: 21.3183 ms, put_time: 0.0540 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,143] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,224] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,305] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,386] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '140', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59118 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:43 [estimate_with_func.py:307] Request job id arriving: 140, time is 1761207223.4655993
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:43 [estimate_with_func.py:315] Request job id: 140
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,468] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,549] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,631] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,713] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,794] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:43 [estimate_with_func.py:328] Request job id finishing: 128, time is 1761207223.8730643
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:43,875] LMCache INFO:[0m Reqid: chatcmpl-3e1afe7c877c4449aba95cb5759401b2, Total tokens 25212, LMCache hit tokens: 11008, need to load: -224 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,366] LMCache INFO:[0m Storing KV cache for 8192 out of 19200 tokens (skip_leading_tokens=11008) for request chatcmpl-3e1afe7c877c4449aba95cb5759401b2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,389] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.5000 ms, throughput: 44.4445 GB/s; offload_time: 22.4507 ms, put_time: 0.0493 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:44 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207224.3911757
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:44 [scheduler.py:1462] Request GPU size bytes: 6617825280
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:44 [scheduler.py:1463] Token size of the request: 50415
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:44 [scheduler.py:1469] Swap waste for job 136: 0.2054443359375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:44 [scheduler.py:1479] Accumulated tokens for job 136: 1128252
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:44 [scheduler.py:1481] Discard waste for job 136: 1026.0344983000427
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:44 [scheduler.py:1484] Preserve waste for job 136: 1.1953353527748938
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,394] LMCache INFO:[0m Reqid: chatcmpl-0aa287e4b7df4f0eb1ca7f301491b707, Total tokens 27237, LMCache hit tokens: 11008, need to load: 10992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,430] LMCache INFO:[0m Retrieved 11008 out of 11008 required tokens (from 11008 total tokens). size: 1.3438 gb, cost 29.0043 ms, throughput: 46.3293 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,961] LMCache INFO:[0m Storing KV cache for 2304 out of 13312 tokens (skip_leading_tokens=11008) for request chatcmpl-0aa287e4b7df4f0eb1ca7f301491b707 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,968] LMCache INFO:[0m Stored 2304 out of total 2304 tokens. size: 0.2812 gb, cost 6.6700 ms, throughput: 42.1667 GB/s; offload_time: 6.6455 ms, put_time: 0.0244 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,968] LMCache INFO:[0m Storing KV cache for 6012 out of 25212 tokens (skip_leading_tokens=19200) for request chatcmpl-3e1afe7c877c4449aba95cb5759401b2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:44,984] LMCache INFO:[0m Stored 6012 out of total 6012 tokens. size: 0.7339 gb, cost 16.4176 ms, throughput: 44.7012 GB/s; offload_time: 16.3773 ms, put_time: 0.0403 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '136', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59350 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '60', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:45,501] LMCache INFO:[0m Storing KV cache for 7936 out of 21248 tokens (skip_leading_tokens=13312) for request chatcmpl-0aa287e4b7df4f0eb1ca7f301491b707 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:45,523] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3885 ms, throughput: 45.2930 GB/s; offload_time: 21.3469 ms, put_time: 0.0416 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:45 [estimate_with_func.py:307] Request job id arriving: 136, time is 1761207225.5258083
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:45 [estimate_with_func.py:315] Request job id: 136
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:45 [estimate_with_func.py:307] Request job id arriving: 60, time is 1761207225.5260446
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:45 [estimate_with_func.py:315] Request job id: 60
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:45,530] LMCache INFO:[0m Reqid: chatcmpl-05ae34f0140849bda151609f41c98591, Total tokens 56854, LMCache hit tokens: 41728, need to load: 41712 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:46,006] LMCache INFO:[0m Storing KV cache for 5989 out of 27237 tokens (skip_leading_tokens=21248) for request chatcmpl-0aa287e4b7df4f0eb1ca7f301491b707 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:46,023] LMCache INFO:[0m Stored 5989 out of total 5989 tokens. size: 0.7311 gb, cost 16.7933 ms, throughput: 43.5340 GB/s; offload_time: 16.7498 ms, put_time: 0.0435 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:46,029] LMCache INFO:[0m Reqid: chatcmpl-05ae34f0140849bda151609f41c98591, Total tokens 56854, LMCache hit tokens: 41728, need to load: 41712 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:46,114] LMCache INFO:[0m Reqid: chatcmpl-05ae34f0140849bda151609f41c98591, Total tokens 56854, LMCache hit tokens: 41728, need to load: 41712 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:46,195] LMCache INFO:[0m Reqid: chatcmpl-05ae34f0140849bda151609f41c98591, Total tokens 56854, LMCache hit tokens: 41728, need to load: 41712 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:46 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207226.2742026
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:46 [scheduler.py:1462] Request GPU size bytes: 3207200768
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:46 [scheduler.py:1463] Token size of the request: 24425
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:46 [scheduler.py:1469] Swap waste for job 10: 0.09956461588541667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:46 [scheduler.py:1479] Accumulated tokens for job 10: 1105074
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:46 [scheduler.py:1481] Discard waste for job 10: 984.6705721826062
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:46 [scheduler.py:1484] Preserve waste for job 10: 3.1074812817670074
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:46,277] LMCache INFO:[0m Reqid: chatcmpl-05ae34f0140849bda151609f41c98591, Total tokens 56854, LMCache hit tokens: 41728, need to load: 41712 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:46,396] LMCache INFO:[0m Retrieved 41728 out of 41728 required tokens (from 41728 total tokens). size: 5.0938 gb, cost 109.2938 ms, throughput: 46.6060 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:47,265] LMCache INFO:[0m Storing KV cache for 7936 out of 49664 tokens (skip_leading_tokens=41728) for request chatcmpl-05ae34f0140849bda151609f41c98591 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:47,288] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.8204 ms, throughput: 42.4510 GB/s; offload_time: 22.7753 ms, put_time: 0.0451 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:47 [estimate_with_func.py:328] Request job id finishing: 130, time is 1761207227.2912982
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:47 [scheduler.py:1462] Request GPU size bytes: 1421475840
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:47 [scheduler.py:1463] Token size of the request: 10801
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:47 [scheduler.py:1469] Swap waste for job 130: 0.04412841796875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:47 [scheduler.py:1479] Accumulated tokens for job 130: 1137503
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:47 [scheduler.py:1481] Discard waste for job 130: 1042.7816153675003
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:47 [scheduler.py:1484] Preserve waste for job 130: 3.1074812817670074
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:47,295] LMCache INFO:[0m Reqid: chatcmpl-f51e7e1b0a70445f8f833c59b3695df2, Total tokens 26723, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:48,168] LMCache INFO:[0m Storing KV cache for 1024 out of 1024 tokens (skip_leading_tokens=0) for request chatcmpl-f51e7e1b0a70445f8f833c59b3695df2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:48,171] LMCache INFO:[0m Stored 1024 out of total 1024 tokens. size: 0.1250 gb, cost 3.1295 ms, throughput: 39.9419 GB/s; offload_time: 3.1101 ms, put_time: 0.0194 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:48,172] LMCache INFO:[0m Storing KV cache for 7190 out of 56854 tokens (skip_leading_tokens=49664) for request chatcmpl-05ae34f0140849bda151609f41c98591 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:48,193] LMCache INFO:[0m Stored 7190 out of total 7190 tokens. size: 0.8777 gb, cost 20.7309 ms, throughput: 42.3371 GB/s; offload_time: 20.6920 ms, put_time: 0.0389 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:48,562] LMCache INFO:[0m Storing KV cache for 8192 out of 9216 tokens (skip_leading_tokens=1024) for request chatcmpl-f51e7e1b0a70445f8f833c59b3695df2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:48,584] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1466 ms, throughput: 45.1537 GB/s; offload_time: 22.0984 ms, put_time: 0.0482 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,060] LMCache INFO:[0m Storing KV cache for 8192 out of 17408 tokens (skip_leading_tokens=9216) for request chatcmpl-f51e7e1b0a70445f8f833c59b3695df2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,082] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0431 ms, throughput: 45.3656 GB/s; offload_time: 22.0011 ms, put_time: 0.0420 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,170] LMCache INFO:[0m Reqid: chatcmpl-f51e7e1b0a70445f8f833c59b3695df2, Total tokens 26723, LMCache hit tokens: 17408, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,251] LMCache INFO:[0m Reqid: chatcmpl-f51e7e1b0a70445f8f833c59b3695df2, Total tokens 26723, LMCache hit tokens: 17408, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,332] LMCache INFO:[0m Reqid: chatcmpl-f51e7e1b0a70445f8f833c59b3695df2, Total tokens 26723, LMCache hit tokens: 17408, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:49 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207229.414875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:49 [estimate_with_func.py:315] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,417] LMCache INFO:[0m Reqid: chatcmpl-f51e7e1b0a70445f8f833c59b3695df2, Total tokens 26723, LMCache hit tokens: 17408, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,498] LMCache INFO:[0m Reqid: chatcmpl-f51e7e1b0a70445f8f833c59b3695df2, Total tokens 26723, LMCache hit tokens: 17408, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:49 [estimate_with_func.py:328] Request job id finishing: 104, time is 1761207229.5769472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:49,579] LMCache INFO:[0m Reqid: chatcmpl-f51e7e1b0a70445f8f833c59b3695df2, Total tokens 26723, LMCache hit tokens: 17408, need to load: -96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:50,153] LMCache INFO:[0m Storing KV cache for 8192 out of 25600 tokens (skip_leading_tokens=17408) for request chatcmpl-f51e7e1b0a70445f8f833c59b3695df2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:50,176] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.3014 ms, throughput: 44.8401 GB/s; offload_time: 22.2546 ms, put_time: 0.0469 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:50 [estimate_with_func.py:328] Request job id finishing: 23, time is 1761207230.1780965
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:50,181] LMCache INFO:[0m Reqid: chatcmpl-6d28069869304835940ac2596104f815, Total tokens 38223, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:50,551] LMCache INFO:[0m Storing KV cache for 6912 out of 6912 tokens (skip_leading_tokens=0) for request chatcmpl-6d28069869304835940ac2596104f815 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:50,570] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 18.4401 ms, throughput: 45.7561 GB/s; offload_time: 18.4050 ms, put_time: 0.0352 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:50,570] LMCache INFO:[0m Storing KV cache for 1123 out of 26723 tokens (skip_leading_tokens=25600) for request chatcmpl-f51e7e1b0a70445f8f833c59b3695df2 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:50,574] LMCache INFO:[0m Stored 1123 out of total 1123 tokens. size: 0.1371 gb, cost 3.4176 ms, throughput: 40.1117 GB/s; offload_time: 3.4035 ms, put_time: 0.0141 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:13:50 [loggers.py:123] Engine 000: Avg prompt throughput: 21451.9 tokens/s, Avg generation throughput: 132.8 tokens/s, Running: 36 reqs, Waiting: 25 reqs, GPU KV cache usage: 93.4%, Prefix cache hit rate: 18.7%
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '130', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:41468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '143', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:44922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:51,009] LMCache INFO:[0m Storing KV cache for 8192 out of 15104 tokens (skip_leading_tokens=6912) for request chatcmpl-6d28069869304835940ac2596104f815 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:51,032] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.9029 ms, throughput: 45.6562 GB/s; offload_time: 21.8636 ms, put_time: 0.0392 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:51 [estimate_with_func.py:307] Request job id arriving: 130, time is 1761207231.0341773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:51 [estimate_with_func.py:315] Request job id: 130
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:51 [estimate_with_func.py:307] Request job id arriving: 143, time is 1761207231.0344045
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:51 [estimate_with_func.py:315] Request job id: 143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:51,569] LMCache INFO:[0m Storing KV cache for 8192 out of 23296 tokens (skip_leading_tokens=15104) for request chatcmpl-6d28069869304835940ac2596104f815 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:51,592] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1219 ms, throughput: 45.2040 GB/s; offload_time: 22.0729 ms, put_time: 0.0490 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,234] LMCache INFO:[0m Storing KV cache for 8192 out of 31488 tokens (skip_leading_tokens=23296) for request chatcmpl-6d28069869304835940ac2596104f815 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,257] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0740 ms, throughput: 45.3022 GB/s; offload_time: 22.0329 ms, put_time: 0.0411 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [estimate_with_func.py:328] Request job id finishing: 32, time is 1761207232.2591321
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1462] Request GPU size bytes: 1114374144
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1463] Token size of the request: 8352
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1469] Swap waste for job 32: 0.0345947265625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1479] Accumulated tokens for job 32: 1099651
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1481] Discard waste for job 32: 975.1154164230086
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1484] Preserve waste for job 32: 3.1312955894470216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207232.2595236
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1462] Request GPU size bytes: 6072434688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1463] Token size of the request: 46281
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1469] Swap waste for job 173: 0.18851318359375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1479] Accumulated tokens for job 173: 1099651
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1481] Discard waste for job 173: 975.1154164230086
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:52 [scheduler.py:1484] Preserve waste for job 173: 3.1312955894470216
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,263] LMCache INFO:[0m Reqid: chatcmpl-6256a87d7b124caf95d8e38061ce8e4e, Total tokens 15432, LMCache hit tokens: 6144, need to load: 6128 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,284] LMCache INFO:[0m Retrieved 6144 out of 6144 required tokens (from 6144 total tokens). size: 0.7500 gb, cost 16.3177 ms, throughput: 45.9625 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,934] LMCache INFO:[0m Storing KV cache for 1280 out of 7424 tokens (skip_leading_tokens=6144) for request chatcmpl-6256a87d7b124caf95d8e38061ce8e4e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,938] LMCache INFO:[0m Stored 1280 out of total 1280 tokens. size: 0.1562 gb, cost 3.8868 ms, throughput: 40.1999 GB/s; offload_time: 3.8637 ms, put_time: 0.0231 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,939] LMCache INFO:[0m Storing KV cache for 6735 out of 38223 tokens (skip_leading_tokens=31488) for request chatcmpl-6d28069869304835940ac2596104f815 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,958] LMCache INFO:[0m Stored 6735 out of total 6735 tokens. size: 0.8221 gb, cost 18.9739 ms, throughput: 43.3303 GB/s; offload_time: 18.9394 ms, put_time: 0.0345 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:52,964] LMCache INFO:[0m Reqid: chatcmpl-51351be5ec6e46bd8bdbe8059cc5501d, Total tokens 4185, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,388] LMCache INFO:[0m Storing KV cache for 256 out of 256 tokens (skip_leading_tokens=0) for request chatcmpl-51351be5ec6e46bd8bdbe8059cc5501d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,389] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 0.9481 ms, throughput: 32.9601 GB/s; offload_time: 0.9378 ms, put_time: 0.0103 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,389] LMCache INFO:[0m Storing KV cache for 8008 out of 15432 tokens (skip_leading_tokens=7424) for request chatcmpl-6256a87d7b124caf95d8e38061ce8e4e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,411] LMCache INFO:[0m Stored 8008 out of total 8008 tokens. size: 0.9775 gb, cost 21.3658 ms, throughput: 45.7526 GB/s; offload_time: 21.3232 ms, put_time: 0.0426 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,415] LMCache INFO:[0m Reqid: chatcmpl-5b6f05e4cfc84252929e3d965adb23c3, Total tokens 14375, LMCache hit tokens: 8704, need to load: 8688 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,445] LMCache INFO:[0m Retrieved 8704 out of 8704 required tokens (from 8704 total tokens). size: 1.0625 gb, cost 22.8329 ms, throughput: 46.5338 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,813] LMCache INFO:[0m Storing KV cache for 4352 out of 13056 tokens (skip_leading_tokens=8704) for request chatcmpl-5b6f05e4cfc84252929e3d965adb23c3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,826] LMCache INFO:[0m Stored 4352 out of total 4352 tokens. size: 0.5312 gb, cost 12.0238 ms, throughput: 44.1833 GB/s; offload_time: 11.9970 ms, put_time: 0.0268 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,826] LMCache INFO:[0m Storing KV cache for 3929 out of 4185 tokens (skip_leading_tokens=256) for request chatcmpl-51351be5ec6e46bd8bdbe8059cc5501d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,837] LMCache INFO:[0m Stored 3929 out of total 3929 tokens. size: 0.4796 gb, cost 10.7030 ms, throughput: 44.8112 GB/s; offload_time: 10.6789 ms, put_time: 0.0241 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,841] LMCache INFO:[0m Reqid: chatcmpl-4932f8a8dde74b989f958b245efcabf0, Total tokens 5890, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,844] LMCache INFO:[0m Reqid: chatcmpl-9cc8015d94fc41d1b83ccc864082bf40, Total tokens 24649, LMCache hit tokens: 17408, need to load: 17392 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:53,894] LMCache INFO:[0m Retrieved 17408 out of 17408 required tokens (from 17408 total tokens). size: 2.1250 gb, cost 45.4962 ms, throughput: 46.7072 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,263] LMCache INFO:[0m Storing KV cache for 5890 out of 5890 tokens (skip_leading_tokens=0) for request chatcmpl-4932f8a8dde74b989f958b245efcabf0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,279] LMCache INFO:[0m Stored 5890 out of total 5890 tokens. size: 0.7190 gb, cost 15.8793 ms, throughput: 45.2787 GB/s; offload_time: 15.8475 ms, put_time: 0.0318 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,279] LMCache INFO:[0m Storing KV cache for 768 out of 18176 tokens (skip_leading_tokens=17408) for request chatcmpl-9cc8015d94fc41d1b83ccc864082bf40 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,281] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 2.3427 ms, throughput: 40.0174 GB/s; offload_time: 2.3334 ms, put_time: 0.0094 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,281] LMCache INFO:[0m Storing KV cache for 1319 out of 14375 tokens (skip_leading_tokens=13056) for request chatcmpl-5b6f05e4cfc84252929e3d965adb23c3 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,285] LMCache INFO:[0m Stored 1319 out of total 1319 tokens. size: 0.1610 gb, cost 3.7965 ms, throughput: 42.4106 GB/s; offload_time: 3.7835 ms, put_time: 0.0130 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,292] LMCache INFO:[0m Reqid: chatcmpl-0ba12fdffe354a13a38ac734d611a647, Total tokens 63283, LMCache hit tokens: 49152, need to load: 49136 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,765] LMCache INFO:[0m Storing KV cache for 6473 out of 24649 tokens (skip_leading_tokens=18176) for request chatcmpl-9cc8015d94fc41d1b83ccc864082bf40 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,783] LMCache INFO:[0m Stored 6473 out of total 6473 tokens. size: 0.7902 gb, cost 17.7217 ms, throughput: 44.5873 GB/s; offload_time: 17.6835 ms, put_time: 0.0382 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:54 [estimate_with_func.py:328] Request job id finishing: 169, time is 1761207234.7854044
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,788] LMCache INFO:[0m Reqid: chatcmpl-0ba12fdffe354a13a38ac734d611a647, Total tokens 63283, LMCache hit tokens: 49152, need to load: 49136 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '173', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:54,939] LMCache INFO:[0m Retrieved 49152 out of 49152 required tokens (from 49152 total tokens). size: 6.0000 gb, cost 128.5491 ms, throughput: 46.6748 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:55,895] LMCache INFO:[0m Storing KV cache for 7936 out of 57088 tokens (skip_leading_tokens=49152) for request chatcmpl-0ba12fdffe354a13a38ac734d611a647 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:55,919] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 22.7754 ms, throughput: 42.5349 GB/s; offload_time: 22.7262 ms, put_time: 0.0492 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:55 [estimate_with_func.py:307] Request job id arriving: 173, time is 1761207235.9226139
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:55 [estimate_with_func.py:315] Request job id: 173
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:55,925] LMCache INFO:[0m Reqid: chatcmpl-6a1a95f16c324c96a10aa020955f07eb, Total tokens 15268, LMCache hit tokens: 6912, need to load: 6896 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:56,751] LMCache INFO:[0m Storing KV cache for 6195 out of 63283 tokens (skip_leading_tokens=57088) for request chatcmpl-0ba12fdffe354a13a38ac734d611a647 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:56,771] LMCache INFO:[0m Stored 6195 out of total 6195 tokens. size: 0.7562 gb, cost 18.9653 ms, throughput: 39.8741 GB/s; offload_time: 18.9256 ms, put_time: 0.0398 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:56,776] LMCache INFO:[0m Reqid: chatcmpl-6a1a95f16c324c96a10aa020955f07eb, Total tokens 15268, LMCache hit tokens: 6912, need to load: 6896 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:56,851] LMCache INFO:[0m Reqid: chatcmpl-6a1a95f16c324c96a10aa020955f07eb, Total tokens 15268, LMCache hit tokens: 6912, need to load: 6896 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:56 [estimate_with_func.py:328] Request job id finishing: 98, time is 1761207236.9211414
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:56,924] LMCache INFO:[0m Reqid: chatcmpl-6a1a95f16c324c96a10aa020955f07eb, Total tokens 15268, LMCache hit tokens: 6912, need to load: 6896 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '32', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:56,948] LMCache INFO:[0m Retrieved 6912 out of 6912 required tokens (from 6912 total tokens). size: 0.8438 gb, cost 18.1956 ms, throughput: 46.3711 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:57,370] LMCache INFO:[0m Storing KV cache for 7936 out of 14848 tokens (skip_leading_tokens=6912) for request chatcmpl-6a1a95f16c324c96a10aa020955f07eb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:57,392] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.3440 ms, throughput: 45.3874 GB/s; offload_time: 21.3019 ms, put_time: 0.0422 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:57 [estimate_with_func.py:307] Request job id arriving: 32, time is 1761207237.394128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:57 [estimate_with_func.py:315] Request job id: 32
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:57,397] LMCache INFO:[0m Reqid: chatcmpl-ed9f16618518462ba1ca1a8530254f57, Total tokens 21024, LMCache hit tokens: 15616, need to load: 15600 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:57,401] LMCache INFO:[0m Reqid: chatcmpl-6d75e2bac5b3485fab0d28402c15159c, Total tokens 38382, LMCache hit tokens: 26880, need to load: 26864 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:57,448] LMCache INFO:[0m Retrieved 15616 out of 15616 required tokens (from 15616 total tokens). size: 1.9062 gb, cost 40.8225 ms, throughput: 46.6961 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:57,519] LMCache INFO:[0m Retrieved 26880 out of 26880 required tokens (from 26880 total tokens). size: 3.2812 gb, cost 70.1064 ms, throughput: 46.8038 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,081] LMCache INFO:[0m Storing KV cache for 5408 out of 21024 tokens (skip_leading_tokens=15616) for request chatcmpl-ed9f16618518462ba1ca1a8530254f57 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,096] LMCache INFO:[0m Stored 5408 out of total 5408 tokens. size: 0.6602 gb, cost 15.0841 ms, throughput: 43.7652 GB/s; offload_time: 15.0469 ms, put_time: 0.0372 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,096] LMCache INFO:[0m Storing KV cache for 2304 out of 29184 tokens (skip_leading_tokens=26880) for request chatcmpl-6d75e2bac5b3485fab0d28402c15159c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,103] LMCache INFO:[0m Stored 2304 out of total 2304 tokens. size: 0.2812 gb, cost 6.5748 ms, throughput: 42.7772 GB/s; offload_time: 6.5595 ms, put_time: 0.0153 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,104] LMCache INFO:[0m Storing KV cache for 420 out of 15268 tokens (skip_leading_tokens=14848) for request chatcmpl-6a1a95f16c324c96a10aa020955f07eb [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,105] LMCache INFO:[0m Stored 420 out of total 420 tokens. size: 0.0513 gb, cost 1.4908 ms, throughput: 34.3900 GB/s; offload_time: 1.4820 ms, put_time: 0.0089 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,181] LMCache INFO:[0m Reqid: chatcmpl-6d75e2bac5b3485fab0d28402c15159c, Total tokens 38382, LMCache hit tokens: 29184, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,250] LMCache INFO:[0m Reqid: chatcmpl-6d75e2bac5b3485fab0d28402c15159c, Total tokens 38382, LMCache hit tokens: 29184, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:58 [estimate_with_func.py:328] Request job id finishing: 7, time is 1761207238.3159006
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:58,320] LMCache INFO:[0m Reqid: chatcmpl-6d75e2bac5b3485fab0d28402c15159c, Total tokens 38382, LMCache hit tokens: 29184, need to load: -240 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:59,036] LMCache INFO:[0m Storing KV cache for 8192 out of 37376 tokens (skip_leading_tokens=29184) for request chatcmpl-6d75e2bac5b3485fab0d28402c15159c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:59,060] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.6014 ms, throughput: 42.3704 GB/s; offload_time: 23.5399 ms, put_time: 0.0614 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [estimate_with_func.py:328] Request job id finishing: 25, time is 1761207239.0628798
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1462] Request GPU size bytes: 1184235520
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1463] Token size of the request: 8764
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1469] Swap waste for job 25: 0.036763509114583336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1479] Accumulated tokens for job 25: 1084861
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1481] Discard waste for job 25: 949.2926647549154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1484] Preserve waste for job 25: 1.195036501720034
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [estimate_with_func.py:328] Request job id finishing: 127, time is 1761207239.0633502
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1462] Request GPU size bytes: 2783576064
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1463] Token size of the request: 21040
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1469] Swap waste for job 127: 0.08641357421875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1479] Accumulated tokens for job 127: 1084861
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1481] Discard waste for job 127: 949.2926647549154
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:13:59 [scheduler.py:1484] Preserve waste for job 127: 1.195036501720034
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:59,068] LMCache INFO:[0m Reqid: chatcmpl-26c551af319146f0a1ea43567c80ff58, Total tokens 86149, LMCache hit tokens: 65536, need to load: 65520 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '25', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:13:59,392] LMCache INFO:[0m Retrieved 65536 out of 65536 required tokens (from 65536 total tokens). size: 8.0000 gb, cost 303.8062 ms, throughput: 26.3326 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '127', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:43098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:00,517] LMCache INFO:[0m Storing KV cache for 7168 out of 72704 tokens (skip_leading_tokens=65536) for request chatcmpl-26c551af319146f0a1ea43567c80ff58 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:00,539] LMCache INFO:[0m Stored 7168 out of total 7168 tokens. size: 0.8750 gb, cost 21.0392 ms, throughput: 41.5889 GB/s; offload_time: 20.9948 ms, put_time: 0.0445 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:00,540] LMCache INFO:[0m Storing KV cache for 1006 out of 38382 tokens (skip_leading_tokens=37376) for request chatcmpl-6d75e2bac5b3485fab0d28402c15159c [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:00,544] LMCache INFO:[0m Stored 1006 out of total 1006 tokens. size: 0.1228 gb, cost 3.7507 ms, throughput: 32.7412 GB/s; offload_time: 3.7344 ms, put_time: 0.0164 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [estimate_with_func.py:328] Request job id finishing: 129, time is 1761207240.5464077
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [scheduler.py:1462] Request GPU size bytes: 1834352640
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [scheduler.py:1463] Token size of the request: 13922
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [scheduler.py:1469] Swap waste for job 129: 0.05694580078125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [scheduler.py:1479] Accumulated tokens for job 129: 1141206
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [scheduler.py:1481] Discard waste for job 129: 1049.523159429795
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [scheduler.py:1484] Preserve waste for job 129: 3.1413590302543035
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [estimate_with_func.py:307] Request job id arriving: 25, time is 1761207240.5472405
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [estimate_with_func.py:315] Request job id: 25
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [estimate_with_func.py:307] Request job id arriving: 127, time is 1761207240.5473974
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:00 [estimate_with_func.py:315] Request job id: 127
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:14:00 [loggers.py:123] Engine 000: Avg prompt throughput: 24070.7 tokens/s, Avg generation throughput: 71.7 tokens/s, Running: 38 reqs, Waiting: 19 reqs, GPU KV cache usage: 97.3%, Prefix cache hit rate: 18.7%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:01,814] LMCache INFO:[0m Storing KV cache for 8192 out of 80896 tokens (skip_leading_tokens=72704) for request chatcmpl-26c551af319146f0a1ea43567c80ff58 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:01,839] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.1622 ms, throughput: 41.3870 GB/s; offload_time: 24.1199 ms, put_time: 0.0423 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:01,845] LMCache INFO:[0m Reqid: chatcmpl-5ca858b594e6463ca69da7825e6463b5, Total tokens 3373, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:02,809] LMCache INFO:[0m Storing KV cache for 2816 out of 2816 tokens (skip_leading_tokens=0) for request chatcmpl-5ca858b594e6463ca69da7825e6463b5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:02,818] LMCache INFO:[0m Stored 2816 out of total 2816 tokens. size: 0.3438 gb, cost 8.0500 ms, throughput: 42.7020 GB/s; offload_time: 8.0212 ms, put_time: 0.0288 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:02,819] LMCache INFO:[0m Storing KV cache for 5253 out of 86149 tokens (skip_leading_tokens=80896) for request chatcmpl-26c551af319146f0a1ea43567c80ff58 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:02,835] LMCache INFO:[0m Stored 5253 out of total 5253 tokens. size: 0.6412 gb, cost 16.5932 ms, throughput: 38.6444 GB/s; offload_time: 16.5651 ms, put_time: 0.0281 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:02,842] LMCache INFO:[0m Reqid: chatcmpl-35c373436a0d40ada4cb4e829c29698e, Total tokens 26047, LMCache hit tokens: 15616, need to load: 15600 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,021] LMCache INFO:[0m Storing KV cache for 557 out of 3373 tokens (skip_leading_tokens=2816) for request chatcmpl-5ca858b594e6463ca69da7825e6463b5 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,023] LMCache INFO:[0m Stored 557 out of total 557 tokens. size: 0.0680 gb, cost 1.7236 ms, throughput: 39.4478 GB/s; offload_time: 1.7135 ms, put_time: 0.0101 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:03 [estimate_with_func.py:328] Request job id finishing: 15, time is 1761207243.0252638
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,028] LMCache INFO:[0m Reqid: chatcmpl-35c373436a0d40ada4cb4e829c29698e, Total tokens 26047, LMCache hit tokens: 15616, need to load: 15600 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,074] LMCache INFO:[0m Retrieved 15616 out of 15616 required tokens (from 15616 total tokens). size: 1.9062 gb, cost 40.8561 ms, throughput: 46.6577 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,612] LMCache INFO:[0m Storing KV cache for 7936 out of 23552 tokens (skip_leading_tokens=15616) for request chatcmpl-35c373436a0d40ada4cb4e829c29698e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,634] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.5360 ms, throughput: 44.9828 GB/s; offload_time: 21.4965 ms, put_time: 0.0395 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:03 [estimate_with_func.py:328] Request job id finishing: 117, time is 1761207243.636071
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,639] LMCache INFO:[0m Reqid: chatcmpl-c3673bd15db64807a085c9d1f42a3530, Total tokens 38242, LMCache hit tokens: 30720, need to load: 30704 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:03,728] LMCache INFO:[0m Retrieved 30720 out of 30720 required tokens (from 30720 total tokens). size: 3.7500 gb, cost 80.4302 ms, throughput: 46.6243 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '129', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,412] LMCache INFO:[0m Storing KV cache for 5632 out of 36352 tokens (skip_leading_tokens=30720) for request chatcmpl-c3673bd15db64807a085c9d1f42a3530 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,428] LMCache INFO:[0m Stored 5632 out of total 5632 tokens. size: 0.6875 gb, cost 15.9456 ms, throughput: 43.1153 GB/s; offload_time: 15.9147 ms, put_time: 0.0309 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,429] LMCache INFO:[0m Storing KV cache for 2495 out of 26047 tokens (skip_leading_tokens=23552) for request chatcmpl-35c373436a0d40ada4cb4e829c29698e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,436] LMCache INFO:[0m Stored 2495 out of total 2495 tokens. size: 0.3046 gb, cost 7.0148 ms, throughput: 43.4176 GB/s; offload_time: 6.9987 ms, put_time: 0.0161 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [estimate_with_func.py:307] Request job id arriving: 129, time is 1761207244.4385636
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [estimate_with_func.py:315] Request job id: 129
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,443] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,738] LMCache INFO:[0m Storing KV cache for 1890 out of 38242 tokens (skip_leading_tokens=36352) for request chatcmpl-c3673bd15db64807a085c9d1f42a3530 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,744] LMCache INFO:[0m Stored 1890 out of total 1890 tokens. size: 0.2307 gb, cost 6.3970 ms, throughput: 36.0659 GB/s; offload_time: 6.3802 ms, put_time: 0.0168 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,751] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,831] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [estimate_with_func.py:328] Request job id finishing: 110, time is 1761207244.903869
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1462] Request GPU size bytes: 2025717760
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1463] Token size of the request: 15432
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1469] Swap waste for job 110: 0.06288655598958333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1479] Accumulated tokens for job 110: 1130128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1481] Discard waste for job 110: 1029.4196700378134
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1484] Preserve waste for job 110: 1.197857638103206
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [estimate_with_func.py:328] Request job id finishing: 101, time is 1761207244.9043024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1462] Request GPU size bytes: 2757492736
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1463] Token size of the request: 21024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1469] Swap waste for job 101: 0.08560384114583333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1479] Accumulated tokens for job 101: 1130128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1481] Discard waste for job 101: 1029.4196700378134
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:04 [scheduler.py:1484] Preserve waste for job 101: 1.197857638103206
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,907] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:04,994] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,080] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,166] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '101', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59006 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [estimate_with_func.py:307] Request job id arriving: 101, time is 1761207245.2491035
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [estimate_with_func.py:315] Request job id: 101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,252] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207245.3354588
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1462] Request GPU size bytes: 2003697664
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1463] Token size of the request: 15268
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1469] Swap waste for job 122: 0.06220296223958333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1479] Accumulated tokens for job 122: 1093672
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1481] Discard waste for job 122: 964.6345977404212
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1484] Preserve waste for job 122: 3.1443267151301084
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,338] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,415] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,492] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,569] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,646] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,723] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,799] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [estimate_with_func.py:328] Request job id finishing: 123, time is 1761207245.8733428
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [estimate_with_func.py:328] Request job id finishing: 149, time is 1761207245.873886
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1462] Request GPU size bytes: 444465152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1463] Token size of the request: 3373
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1469] Swap waste for job 149: 0.013798014322916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1479] Accumulated tokens for job 149: 1078404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1481] Discard waste for job 149: 938.1276534772677
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:05 [scheduler.py:1484] Preserve waste for job 149: 3.1443267151301084
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:05,877] LMCache INFO:[0m Reqid: chatcmpl-099c7ef15abc4383bd4b2f4939ebc363, Total tokens 90936, LMCache hit tokens: 75008, need to load: 74992 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:06,092] LMCache INFO:[0m Retrieved 75008 out of 75008 required tokens (from 75008 total tokens). size: 9.1562 gb, cost 197.0340 ms, throughput: 46.4704 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '110', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:07,385] LMCache INFO:[0m Storing KV cache for 7936 out of 82944 tokens (skip_leading_tokens=75008) for request chatcmpl-099c7ef15abc4383bd4b2f4939ebc363 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:07,409] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 23.3430 ms, throughput: 41.5007 GB/s; offload_time: 23.2946 ms, put_time: 0.0484 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:07 [estimate_with_func.py:307] Request job id arriving: 110, time is 1761207247.4127147
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:07 [estimate_with_func.py:315] Request job id: 110
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:07,416] LMCache INFO:[0m Reqid: chatcmpl-c432123d5c0e42b7be4889926756e89e, Total tokens 3780, LMCache hit tokens: 2048, need to load: 2032 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:07,426] LMCache INFO:[0m Retrieved 2048 out of 2048 required tokens (from 2048 total tokens). size: 0.2500 gb, cost 5.6347 ms, throughput: 44.3682 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '122', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '149', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58592 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:08,780] LMCache INFO:[0m Storing KV cache for 256 out of 2304 tokens (skip_leading_tokens=2048) for request chatcmpl-c432123d5c0e42b7be4889926756e89e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:08,782] LMCache INFO:[0m Stored 256 out of total 256 tokens. size: 0.0312 gb, cost 1.3042 ms, throughput: 23.9602 GB/s; offload_time: 1.2876 ms, put_time: 0.0166 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:08,783] LMCache INFO:[0m Storing KV cache for 7992 out of 90936 tokens (skip_leading_tokens=82944) for request chatcmpl-099c7ef15abc4383bd4b2f4939ebc363 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:08,807] LMCache INFO:[0m Stored 7992 out of total 7992 tokens. size: 0.9756 gb, cost 23.4722 ms, throughput: 41.5635 GB/s; offload_time: 23.4283 ms, put_time: 0.0438 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:08 [estimate_with_func.py:307] Request job id arriving: 122, time is 1761207248.8101094
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:08 [estimate_with_func.py:315] Request job id: 122
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:08 [estimate_with_func.py:307] Request job id arriving: 149, time is 1761207248.8103645
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:08 [estimate_with_func.py:315] Request job id: 149
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:08,814] LMCache INFO:[0m Reqid: chatcmpl-d7a11049d33b4ca8afd1f2473dd129df, Total tokens 37322, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,021] LMCache INFO:[0m Storing KV cache for 1476 out of 3780 tokens (skip_leading_tokens=2304) for request chatcmpl-c432123d5c0e42b7be4889926756e89e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,025] LMCache INFO:[0m Stored 1476 out of total 1476 tokens. size: 0.1802 gb, cost 4.1900 ms, throughput: 43.0015 GB/s; offload_time: 4.1737 ms, put_time: 0.0163 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,030] LMCache INFO:[0m Reqid: chatcmpl-d7a11049d33b4ca8afd1f2473dd129df, Total tokens 37322, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207249.1240625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [scheduler.py:1462] Request GPU size bytes: 3416653824
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [scheduler.py:1463] Token size of the request: 26047
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [scheduler.py:1469] Swap waste for job 102: 0.10606689453125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [scheduler.py:1479] Accumulated tokens for job 102: 1142706
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [scheduler.py:1481] Discard waste for job 102: 1052.2601846800146
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [scheduler.py:1484] Preserve waste for job 102: 1.2000723887180937
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,126] LMCache INFO:[0m Reqid: chatcmpl-d7a11049d33b4ca8afd1f2473dd129df, Total tokens 37322, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,212] LMCache INFO:[0m Reqid: chatcmpl-d7a11049d33b4ca8afd1f2473dd129df, Total tokens 37322, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,296] LMCache INFO:[0m Reqid: chatcmpl-d7a11049d33b4ca8afd1f2473dd129df, Total tokens 37322, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:09 [estimate_with_func.py:328] Request job id finishing: 3, time is 1761207249.379001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,382] LMCache INFO:[0m Reqid: chatcmpl-d7a11049d33b4ca8afd1f2473dd129df, Total tokens 37322, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:09,453] LMCache INFO:[0m Retrieved 24576 out of 24576 required tokens (from 24576 total tokens). size: 3.0000 gb, cost 64.6097 ms, throughput: 46.4327 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,095] LMCache INFO:[0m Storing KV cache for 7936 out of 32512 tokens (skip_leading_tokens=24576) for request chatcmpl-d7a11049d33b4ca8afd1f2473dd129df [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,117] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.6423 ms, throughput: 44.7618 GB/s; offload_time: 21.5970 ms, put_time: 0.0454 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,121] LMCache INFO:[0m Reqid: chatcmpl-ffcb7fb25ee74364917f16119faeb570, Total tokens 18530, LMCache hit tokens: 12288, need to load: 12272 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '102', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:51388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,158] LMCache INFO:[0m Retrieved 12288 out of 12288 required tokens (from 12288 total tokens). size: 1.5000 gb, cost 32.3224 ms, throughput: 46.4075 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:14:10 [loggers.py:123] Engine 000: Avg prompt throughput: 24853.1 tokens/s, Avg generation throughput: 102.4 tokens/s, Running: 35 reqs, Waiting: 20 reqs, GPU KV cache usage: 94.3%, Prefix cache hit rate: 16.2%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,770] LMCache INFO:[0m Storing KV cache for 3328 out of 15616 tokens (skip_leading_tokens=12288) for request chatcmpl-ffcb7fb25ee74364917f16119faeb570 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,780] LMCache INFO:[0m Stored 3328 out of total 3328 tokens. size: 0.4062 gb, cost 9.3777 ms, throughput: 43.3210 GB/s; offload_time: 9.3505 ms, put_time: 0.0272 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,781] LMCache INFO:[0m Storing KV cache for 4810 out of 37322 tokens (skip_leading_tokens=32512) for request chatcmpl-d7a11049d33b4ca8afd1f2473dd129df [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,795] LMCache INFO:[0m Stored 4810 out of total 4810 tokens. size: 0.5872 gb, cost 13.7596 ms, throughput: 42.6727 GB/s; offload_time: 13.7358 ms, put_time: 0.0237 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:10 [estimate_with_func.py:307] Request job id arriving: 102, time is 1761207250.7974865
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:10 [estimate_with_func.py:315] Request job id: 102
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,801] LMCache INFO:[0m Reqid: chatcmpl-ba392f2b08a7429e8c75d47a5104cd75, Total tokens 38430, LMCache hit tokens: 29440, need to load: 29424 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:10,890] LMCache INFO:[0m Retrieved 29440 out of 29440 required tokens (from 29440 total tokens). size: 3.5938 gb, cost 77.0979 ms, throughput: 46.6128 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:11,524] LMCache INFO:[0m Storing KV cache for 5376 out of 34816 tokens (skip_leading_tokens=29440) for request chatcmpl-ba392f2b08a7429e8c75d47a5104cd75 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:11,540] LMCache INFO:[0m Stored 5376 out of total 5376 tokens. size: 0.6562 gb, cost 15.2501 ms, throughput: 43.0326 GB/s; offload_time: 15.2228 ms, put_time: 0.0273 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:11,540] LMCache INFO:[0m Storing KV cache for 2914 out of 18530 tokens (skip_leading_tokens=15616) for request chatcmpl-ffcb7fb25ee74364917f16119faeb570 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:11,548] LMCache INFO:[0m Stored 2914 out of total 2914 tokens. size: 0.3557 gb, cost 7.9983 ms, throughput: 44.4737 GB/s; offload_time: 7.9790 ms, put_time: 0.0192 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:11,554] LMCache INFO:[0m Reqid: chatcmpl-59ec5fb548624d52acf84eed2c7cb498, Total tokens 36159, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:11,987] LMCache INFO:[0m Storing KV cache for 3614 out of 38430 tokens (skip_leading_tokens=34816) for request chatcmpl-ba392f2b08a7429e8c75d47a5104cd75 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:11,998] LMCache INFO:[0m Stored 3614 out of total 3614 tokens. size: 0.4412 gb, cost 11.0250 ms, throughput: 40.0147 GB/s; offload_time: 10.9984 ms, put_time: 0.0266 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [estimate_with_func.py:328] Request job id finishing: 171, time is 1761207252.0006592
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [estimate_with_func.py:328] Request job id finishing: 152, time is 1761207252.0010712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [scheduler.py:1462] Request GPU size bytes: 5016125440
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [scheduler.py:1463] Token size of the request: 38223
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [scheduler.py:1469] Swap waste for job 152: 0.15572102864583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [scheduler.py:1479] Accumulated tokens for job 152: 1140920
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [scheduler.py:1481] Discard waste for job 152: 1049.00170449137
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:12 [scheduler.py:1484] Preserve waste for job 152: 3.144807264851589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:12,004] LMCache INFO:[0m Reqid: chatcmpl-59ec5fb548624d52acf84eed2c7cb498, Total tokens 36159, LMCache hit tokens: 24576, need to load: 24560 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:12,076] LMCache INFO:[0m Retrieved 24576 out of 24576 required tokens (from 24576 total tokens). size: 3.0000 gb, cost 64.5268 ms, throughput: 46.4923 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:12,722] LMCache INFO:[0m Storing KV cache for 7936 out of 32512 tokens (skip_leading_tokens=24576) for request chatcmpl-59ec5fb548624d52acf84eed2c7cb498 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:12,744] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.4310 ms, throughput: 45.2033 GB/s; offload_time: 21.3875 ms, put_time: 0.0434 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:12,749] LMCache INFO:[0m Reqid: chatcmpl-bea2998135134304b6f47cc34e397b7e, Total tokens 28620, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:13,247] LMCache INFO:[0m Storing KV cache for 4608 out of 4608 tokens (skip_leading_tokens=0) for request chatcmpl-bea2998135134304b6f47cc34e397b7e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:13,260] LMCache INFO:[0m Stored 4608 out of total 4608 tokens. size: 0.5625 gb, cost 12.5095 ms, throughput: 44.9660 GB/s; offload_time: 12.4793 ms, put_time: 0.0301 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:13,260] LMCache INFO:[0m Storing KV cache for 3647 out of 36159 tokens (skip_leading_tokens=32512) for request chatcmpl-59ec5fb548624d52acf84eed2c7cb498 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:13,271] LMCache INFO:[0m Stored 3647 out of total 3647 tokens. size: 0.4452 gb, cost 10.8371 ms, throughput: 41.0803 GB/s; offload_time: 10.8136 ms, put_time: 0.0235 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [estimate_with_func.py:328] Request job id finishing: 126, time is 1761207253.273775
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [estimate_with_func.py:328] Request job id finishing: 141, time is 1761207253.2740493
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [scheduler.py:1462] Request GPU size bytes: 659292160
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [scheduler.py:1463] Token size of the request: 4883
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [scheduler.py:1469] Swap waste for job 141: 0.020467122395833332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [scheduler.py:1479] Accumulated tokens for job 141: 1161334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [scheduler.py:1481] Discard waste for job 141: 1086.5473391362207
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:13 [scheduler.py:1484] Preserve waste for job 141: 3.144807264851589
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:13,691] LMCache INFO:[0m Storing KV cache for 8192 out of 12800 tokens (skip_leading_tokens=4608) for request chatcmpl-bea2998135134304b6f47cc34e397b7e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:13,713] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.8854 ms, throughput: 45.6926 GB/s; offload_time: 21.8447 ms, put_time: 0.0407 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '152', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59142 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:14,239] LMCache INFO:[0m Storing KV cache for 8192 out of 20992 tokens (skip_leading_tokens=12800) for request chatcmpl-bea2998135134304b6f47cc34e397b7e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:14,261] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 21.9366 ms, throughput: 45.5860 GB/s; offload_time: 21.8940 ms, put_time: 0.0425 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:14 [estimate_with_func.py:307] Request job id arriving: 152, time is 1761207254.263395
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:14 [estimate_with_func.py:315] Request job id: 152
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:14 [estimate_with_func.py:328] Request job id finishing: 83, time is 1761207254.350398
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:14,353] LMCache INFO:[0m Reqid: chatcmpl-bea2998135134304b6f47cc34e397b7e, Total tokens 28620, LMCache hit tokens: 20992, need to load: -64 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:14,356] LMCache INFO:[0m Reqid: chatcmpl-1fe74b4f36af4bdd90e51b464e22c832, Total tokens 27705, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:14,942] LMCache INFO:[0m Storing KV cache for 7628 out of 28620 tokens (skip_leading_tokens=20992) for request chatcmpl-bea2998135134304b6f47cc34e397b7e [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:14,964] LMCache INFO:[0m Stored 7628 out of total 7628 tokens. size: 0.9312 gb, cost 20.9556 ms, throughput: 44.4345 GB/s; offload_time: 20.9089 ms, put_time: 0.0467 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:14,968] LMCache INFO:[0m Reqid: chatcmpl-1fe74b4f36af4bdd90e51b464e22c832, Total tokens 27705, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [estimate_with_func.py:328] Request job id finishing: 168, time is 1761207255.0533934
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:15,055] LMCache INFO:[0m Reqid: chatcmpl-1fe74b4f36af4bdd90e51b464e22c832, Total tokens 27705, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:15,088] LMCache INFO:[0m Retrieved 10752 out of 10752 required tokens (from 10752 total tokens). size: 1.3125 gb, cost 28.1769 ms, throughput: 46.5807 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:15,573] LMCache INFO:[0m Storing KV cache for 7936 out of 18688 tokens (skip_leading_tokens=10752) for request chatcmpl-1fe74b4f36af4bdd90e51b464e22c832 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:15,596] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.7277 ms, throughput: 44.5858 GB/s; offload_time: 21.6779 ms, put_time: 0.0498 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [estimate_with_func.py:328] Request job id finishing: 157, time is 1761207255.6900618
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [scheduler.py:1462] Request GPU size bytes: 2336620544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [scheduler.py:1463] Token size of the request: 17473
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [scheduler.py:1469] Swap waste for job 157: 0.07253824869791667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [scheduler.py:1479] Accumulated tokens for job 157: 1124623
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [scheduler.py:1481] Discard waste for job 157: 1019.5019257069384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:15 [scheduler.py:1484] Preserve waste for job 157: 3.1413615718483925
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:15,693] LMCache INFO:[0m Reqid: chatcmpl-1fe74b4f36af4bdd90e51b464e22c832, Total tokens 27705, LMCache hit tokens: 18688, need to load: -208 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,286] LMCache INFO:[0m Storing KV cache for 8192 out of 26880 tokens (skip_leading_tokens=18688) for request chatcmpl-1fe74b4f36af4bdd90e51b464e22c832 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,309] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.4156 ms, throughput: 44.6118 GB/s; offload_time: 22.3648 ms, put_time: 0.0508 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:16 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207256.3112445
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:16 [scheduler.py:1462] Request GPU size bytes: 7461273600
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:16 [scheduler.py:1463] Token size of the request: 56854
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:16 [scheduler.py:1469] Swap waste for job 138: 0.23162841796875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:16 [scheduler.py:1479] Accumulated tokens for job 138: 1134855
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:16 [scheduler.py:1481] Discard waste for job 138: 1037.9740842246733
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:16 [scheduler.py:1484] Preserve waste for job 138: 1.202348224245585
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,314] LMCache INFO:[0m Reqid: chatcmpl-7dbcb1f8f96440a682c78447ed0548d6, Total tokens 6580, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,318] LMCache INFO:[0m Reqid: chatcmpl-e16f3b444ce9438d8761098bdcba2eee, Total tokens 65413, LMCache hit tokens: 50176, need to load: 50160 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,463] LMCache INFO:[0m Retrieved 50176 out of 50176 required tokens (from 50176 total tokens). size: 6.1250 gb, cost 132.3704 ms, throughput: 46.2717 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,889] LMCache INFO:[0m Storing KV cache for 6580 out of 6580 tokens (skip_leading_tokens=0) for request chatcmpl-7dbcb1f8f96440a682c78447ed0548d6 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,907] LMCache INFO:[0m Stored 6580 out of total 6580 tokens. size: 0.8032 gb, cost 17.8292 ms, throughput: 45.0509 GB/s; offload_time: 17.7883 ms, put_time: 0.0409 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,908] LMCache INFO:[0m Storing KV cache for 768 out of 50944 tokens (skip_leading_tokens=50176) for request chatcmpl-e16f3b444ce9438d8761098bdcba2eee [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,911] LMCache INFO:[0m Stored 768 out of total 768 tokens. size: 0.0938 gb, cost 3.0043 ms, throughput: 31.2051 GB/s; offload_time: 2.9909 ms, put_time: 0.0134 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,912] LMCache INFO:[0m Storing KV cache for 825 out of 27705 tokens (skip_leading_tokens=26880) for request chatcmpl-1fe74b4f36af4bdd90e51b464e22c832 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:16,915] LMCache INFO:[0m Stored 825 out of total 825 tokens. size: 0.1007 gb, cost 2.8422 ms, throughput: 35.4327 GB/s; offload_time: 2.8315 ms, put_time: 0.0107 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '138', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59290 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:17,911] LMCache INFO:[0m Storing KV cache for 8192 out of 59136 tokens (skip_leading_tokens=50944) for request chatcmpl-e16f3b444ce9438d8761098bdcba2eee [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:17,936] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 23.7406 ms, throughput: 42.1220 GB/s; offload_time: 23.6968 ms, put_time: 0.0438 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:17 [estimate_with_func.py:307] Request job id arriving: 138, time is 1761207257.9393663
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:17 [estimate_with_func.py:315] Request job id: 138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [estimate_with_func.py:328] Request job id finishing: 100, time is 1761207258.0292025
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1462] Request GPU size bytes: 498335744
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1463] Token size of the request: 3780
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1469] Swap waste for job 100: 0.015470377604166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1479] Accumulated tokens for job 100: 1084581
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1481] Discard waste for job 100: 948.807137751685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1484] Preserve waste for job 100: 3.1413615718483925
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207258.0294852
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1462] Request GPU size bytes: 4893966336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1463] Token size of the request: 37322
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1469] Swap waste for job 68: 0.1519287109375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1479] Accumulated tokens for job 68: 1084581
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1481] Discard waste for job 68: 948.807137751685
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:18 [scheduler.py:1484] Preserve waste for job 68: 1.2043856319628263
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:18,043] LMCache INFO:[0m Reqid: chatcmpl-e16f3b444ce9438d8761098bdcba2eee, Total tokens 65413, LMCache hit tokens: 59136, need to load: -144 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:18,046] LMCache INFO:[0m Reqid: chatcmpl-5f49d8332de049b1aaec51de83537a20, Total tokens 4968, LMCache hit tokens: 3072, need to load: 3056 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:18,049] LMCache INFO:[0m Reqid: chatcmpl-fa3153d41c194b1fa84f8f40759e3344, Total tokens 29933, LMCache hit tokens: 24320, need to load: 24304 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:18,066] LMCache INFO:[0m Retrieved 3072 out of 3072 required tokens (from 3072 total tokens). size: 0.3750 gb, cost 8.2844 ms, throughput: 45.2660 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:18,130] LMCache INFO:[0m Retrieved 24320 out of 24320 required tokens (from 24320 total tokens). size: 2.9688 gb, cost 63.3711 ms, throughput: 46.8471 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '157', 'last_func_call': 'search_engine_query', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '68', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:34622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,022] LMCache INFO:[0m Storing KV cache for 1896 out of 4968 tokens (skip_leading_tokens=3072) for request chatcmpl-5f49d8332de049b1aaec51de83537a20 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,028] LMCache INFO:[0m Stored 1896 out of total 1896 tokens. size: 0.2314 gb, cost 5.6927 ms, throughput: 40.6565 GB/s; offload_time: 5.6652 ms, put_time: 0.0275 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,029] LMCache INFO:[0m Storing KV cache for 6277 out of 65413 tokens (skip_leading_tokens=59136) for request chatcmpl-e16f3b444ce9438d8761098bdcba2eee [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,049] LMCache INFO:[0m Stored 6277 out of total 6277 tokens. size: 0.7662 gb, cost 19.1937 ms, throughput: 39.9211 GB/s; offload_time: 19.1610 ms, put_time: 0.0328 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:19 [estimate_with_func.py:307] Request job id arriving: 157, time is 1761207259.0519
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:19 [estimate_with_func.py:315] Request job id: 157
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:19 [estimate_with_func.py:307] Request job id arriving: 68, time is 1761207259.0521457
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:19 [estimate_with_func.py:315] Request job id: 68
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,055] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,545] LMCache INFO:[0m Storing KV cache for 5613 out of 29933 tokens (skip_leading_tokens=24320) for request chatcmpl-fa3153d41c194b1fa84f8f40759e3344 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,560] LMCache INFO:[0m Stored 5613 out of total 5613 tokens. size: 0.6852 gb, cost 15.2931 ms, throughput: 44.8033 GB/s; offload_time: 15.2653 ms, put_time: 0.0278 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,564] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,652] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,737] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '141', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:47918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:19 [estimate_with_func.py:307] Request job id arriving: 141, time is 1761207259.8198907
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:19 [estimate_with_func.py:315] Request job id: 141
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,821] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,905] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:19,990] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,074] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,159] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,243] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,328] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,412] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,496] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [estimate_with_func.py:328] Request job id finishing: 1, time is 1761207260.579215
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207260.5799646
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [scheduler.py:1462] Request GPU size bytes: 3925082112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [scheduler.py:1463] Token size of the request: 29933
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [scheduler.py:1469] Swap waste for job 10: 0.1218505859375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [scheduler.py:1479] Accumulated tokens for job 10: 1143793
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [scheduler.py:1481] Discard waste for job 10: 1054.2458427602971
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:20 [scheduler.py:1484] Preserve waste for job 10: 1.2035203718003773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,582] LMCache INFO:[0m Reqid: chatcmpl-76d363151b5a4725873f31371b7e3488, Total tokens 15433, LMCache hit tokens: 10752, need to load: 10736 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,588] LMCache INFO:[0m Reqid: chatcmpl-94fa0e7fa45349e7b519a944f8c8f880, Total tokens 14459, LMCache hit tokens: 9728, need to load: 9712 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:14:20 [loggers.py:123] Engine 000: Avg prompt throughput: 29366.0 tokens/s, Avg generation throughput: 102.1 tokens/s, Running: 32 reqs, Waiting: 17 reqs, GPU KV cache usage: 93.6%, Prefix cache hit rate: 16.2%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,621] LMCache INFO:[0m Retrieved 10752 out of 10752 required tokens (from 10752 total tokens). size: 1.3125 gb, cost 28.2475 ms, throughput: 46.4643 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:20,647] LMCache INFO:[0m Retrieved 9728 out of 9728 required tokens (from 9728 total tokens). size: 1.1875 gb, cost 25.4750 ms, throughput: 46.6144 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '100', 'last_func_call': 'search_engine_query', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58926 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '10', 'last_func_call': 'fetch_url_content', 'is_last_step': True}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:21,089] LMCache INFO:[0m Storing KV cache for 4681 out of 15433 tokens (skip_leading_tokens=10752) for request chatcmpl-76d363151b5a4725873f31371b7e3488 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:21,102] LMCache INFO:[0m Stored 4681 out of total 4681 tokens. size: 0.5714 gb, cost 13.0216 ms, throughput: 43.8817 GB/s; offload_time: 12.9875 ms, put_time: 0.0341 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:21,103] LMCache INFO:[0m Storing KV cache for 3328 out of 13056 tokens (skip_leading_tokens=9728) for request chatcmpl-94fa0e7fa45349e7b519a944f8c8f880 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:21,112] LMCache INFO:[0m Stored 3328 out of total 3328 tokens. size: 0.4062 gb, cost 9.0951 ms, throughput: 44.6669 GB/s; offload_time: 9.0723 ms, put_time: 0.0228 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207261.11416
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [scheduler.py:1462] Request GPU size bytes: 3633709056
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [scheduler.py:1463] Token size of the request: 27705
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [scheduler.py:1469] Swap waste for job 97: 0.11280517578125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [scheduler.py:1479] Accumulated tokens for job 97: 1102606
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [scheduler.py:1481] Discard waste for job 97: 980.3162577618862
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [scheduler.py:1484] Preserve waste for job 97: 1.2035203718003773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [estimate_with_func.py:307] Request job id arriving: 100, time is 1761207261.114798
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [estimate_with_func.py:315] Request job id: 100
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: search_engine_query
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [estimate_with_func.py:307] Request job id arriving: 10, time is 1761207261.1149852
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:21 [estimate_with_func.py:315] Request job id: 10
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:21,118] LMCache INFO:[0m Reqid: chatcmpl-29f4579d977742999b5261979794dcf1, Total tokens 70485, LMCache hit tokens: 46080, need to load: 46064 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:21,253] LMCache INFO:[0m Retrieved 46080 out of 46080 required tokens (from 46080 total tokens). size: 5.6250 gb, cost 122.0479 ms, throughput: 46.0885 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:22,095] LMCache INFO:[0m Storing KV cache for 6656 out of 52736 tokens (skip_leading_tokens=46080) for request chatcmpl-29f4579d977742999b5261979794dcf1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:22,116] LMCache INFO:[0m Stored 6656 out of total 6656 tokens. size: 0.8125 gb, cost 19.4450 ms, throughput: 41.7845 GB/s; offload_time: 19.4059 ms, put_time: 0.0391 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:22,116] LMCache INFO:[0m Storing KV cache for 1403 out of 14459 tokens (skip_leading_tokens=13056) for request chatcmpl-94fa0e7fa45349e7b519a944f8c8f880 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:22,120] LMCache INFO:[0m Stored 1403 out of total 1403 tokens. size: 0.1713 gb, cost 4.1303 ms, throughput: 41.4658 GB/s; offload_time: 4.1178 ms, put_time: 0.0125 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:22 [estimate_with_func.py:328] Request job id finishing: 140, time is 1761207262.1227202
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:22 [scheduler.py:1462] Request GPU size bytes: 864944128
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:22 [scheduler.py:1463] Token size of the request: 6580
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:22 [scheduler.py:1469] Swap waste for job 140: 0.026851399739583334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:22 [scheduler.py:1479] Accumulated tokens for job 140: 1145386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:22 [scheduler.py:1481] Discard waste for job 140: 1057.1592085898105
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:22 [scheduler.py:1484] Preserve waste for job 140: 1.2003521591566184
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '97', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:58466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '140', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'fetch_url_content'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:59118 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:23,144] LMCache INFO:[0m Storing KV cache for 8192 out of 60928 tokens (skip_leading_tokens=52736) for request chatcmpl-29f4579d977742999b5261979794dcf1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:23,170] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.0095 ms, throughput: 41.6502 GB/s; offload_time: 23.9626 ms, put_time: 0.0468 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:23 [estimate_with_func.py:307] Request job id arriving: 97, time is 1761207263.1724963
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:23 [estimate_with_func.py:315] Request job id: 97
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:23 [estimate_with_func.py:307] Request job id arriving: 140, time is 1761207263.17274
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:23 [estimate_with_func.py:315] Request job id: 140
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,298] LMCache INFO:[0m Storing KV cache for 8192 out of 69120 tokens (skip_leading_tokens=60928) for request chatcmpl-29f4579d977742999b5261979794dcf1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,324] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 24.4191 ms, throughput: 40.9516 GB/s; offload_time: 24.3687 ms, put_time: 0.0504 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,329] LMCache INFO:[0m Reqid: chatcmpl-a8aa86a53f0c4a568886e9f90f019d0d, Total tokens 11939, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,799] LMCache INFO:[0m Storing KV cache for 6912 out of 6912 tokens (skip_leading_tokens=0) for request chatcmpl-a8aa86a53f0c4a568886e9f90f019d0d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,818] LMCache INFO:[0m Stored 6912 out of total 6912 tokens. size: 0.8438 gb, cost 18.4216 ms, throughput: 45.8022 GB/s; offload_time: 18.3867 ms, put_time: 0.0349 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,819] LMCache INFO:[0m Storing KV cache for 1365 out of 70485 tokens (skip_leading_tokens=69120) for request chatcmpl-29f4579d977742999b5261979794dcf1 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,824] LMCache INFO:[0m Stored 1365 out of total 1365 tokens. size: 0.1666 gb, cost 5.1163 ms, throughput: 32.5678 GB/s; offload_time: 5.0962 ms, put_time: 0.0201 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:24,919] LMCache INFO:[0m Reqid: chatcmpl-a8aa86a53f0c4a568886e9f90f019d0d, Total tokens 11939, LMCache hit tokens: 6912, need to load: -32 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,007] LMCache INFO:[0m Reqid: chatcmpl-a8aa86a53f0c4a568886e9f90f019d0d, Total tokens 11939, LMCache hit tokens: 6912, need to load: 0 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,095] LMCache INFO:[0m Reqid: chatcmpl-a8aa86a53f0c4a568886e9f90f019d0d, Total tokens 11939, LMCache hit tokens: 6912, need to load: 96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:25 [estimate_with_func.py:328] Request job id finishing: 50, time is 1761207265.1813715
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,184] LMCache INFO:[0m Reqid: chatcmpl-a8aa86a53f0c4a568886e9f90f019d0d, Total tokens 11939, LMCache hit tokens: 6912, need to load: 96 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,186] LMCache INFO:[0m Reqid: chatcmpl-81882967fc7844fcb137d0bd3df2f1d9, Total tokens 13481, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,561] LMCache INFO:[0m Storing KV cache for 3072 out of 3072 tokens (skip_leading_tokens=0) for request chatcmpl-81882967fc7844fcb137d0bd3df2f1d9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,569] LMCache INFO:[0m Stored 3072 out of total 3072 tokens. size: 0.3750 gb, cost 8.3791 ms, throughput: 44.7541 GB/s; offload_time: 8.3522 ms, put_time: 0.0269 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,570] LMCache INFO:[0m Storing KV cache for 5027 out of 11939 tokens (skip_leading_tokens=6912) for request chatcmpl-a8aa86a53f0c4a568886e9f90f019d0d [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,583] LMCache INFO:[0m Stored 5027 out of total 5027 tokens. size: 0.6136 gb, cost 13.5584 ms, throughput: 45.2596 GB/s; offload_time: 13.5284 ms, put_time: 0.0300 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:25,984] LMCache INFO:[0m Storing KV cache for 8192 out of 11264 tokens (skip_leading_tokens=3072) for request chatcmpl-81882967fc7844fcb137d0bd3df2f1d9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,006] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.0784 ms, throughput: 45.2931 GB/s; offload_time: 22.0343 ms, put_time: 0.0441 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,011] LMCache INFO:[0m Reqid: chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0, Total tokens 31892, LMCache hit tokens: 0, need to load: -16 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,382] LMCache INFO:[0m Storing KV cache for 5888 out of 5888 tokens (skip_leading_tokens=0) for request chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,398] LMCache INFO:[0m Stored 5888 out of total 5888 tokens. size: 0.7188 gb, cost 15.8490 ms, throughput: 45.3498 GB/s; offload_time: 15.8142 ms, put_time: 0.0349 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,398] LMCache INFO:[0m Storing KV cache for 2217 out of 13481 tokens (skip_leading_tokens=11264) for request chatcmpl-81882967fc7844fcb137d0bd3df2f1d9 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,405] LMCache INFO:[0m Stored 2217 out of total 2217 tokens. size: 0.2706 gb, cost 6.1710 ms, throughput: 43.8555 GB/s; offload_time: 6.1564 ms, put_time: 0.0146 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,835] LMCache INFO:[0m Storing KV cache for 8192 out of 14080 tokens (skip_leading_tokens=5888) for request chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,858] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.2241 ms, throughput: 44.9962 GB/s; offload_time: 22.1757 ms, put_time: 0.0484 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:26,954] LMCache INFO:[0m Reqid: chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0, Total tokens 31892, LMCache hit tokens: 14080, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:27,039] LMCache INFO:[0m Reqid: chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0, Total tokens 31892, LMCache hit tokens: 14080, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:27,124] LMCache INFO:[0m Reqid: chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0, Total tokens 31892, LMCache hit tokens: 14080, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:27,209] LMCache INFO:[0m Reqid: chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0, Total tokens 31892, LMCache hit tokens: 14080, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [estimate_with_func.py:328] Request job id finishing: 11, time is 1761207267.2924185
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1462] Request GPU size bytes: 3123314688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1463] Token size of the request: 23652
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1469] Swap waste for job 11: 0.09696044921875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1479] Accumulated tokens for job 11: 1130047
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1481] Discard waste for job 11: 1029.2733934209082
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1484] Preserve waste for job 11: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [estimate_with_func.py:328] Request job id finishing: 130, time is 1761207267.2930298
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1462] Request GPU size bytes: 2025193472
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1463] Token size of the request: 15433
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1469] Swap waste for job 130: 0.06287027994791666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1479] Accumulated tokens for job 130: 1130047
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1481] Discard waste for job 130: 1029.2733934209082
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1484] Preserve waste for job 130: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:27,295] LMCache INFO:[0m Reqid: chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0, Total tokens 31892, LMCache hit tokens: 14080, need to load: -80 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:27,825] LMCache INFO:[0m Storing KV cache for 8192 out of 22272 tokens (skip_leading_tokens=14080) for request chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:27,848] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.3216 ms, throughput: 44.7997 GB/s; offload_time: 22.2743 ms, put_time: 0.0473 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [estimate_with_func.py:328] Request job id finishing: 5, time is 1761207267.8502595
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [estimate_with_func.py:328] Request job id finishing: 143, time is 1761207267.8511436
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1462] Request GPU size bytes: 1897529344
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1463] Token size of the request: 14459
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1469] Swap waste for job 143: 0.05890706380208333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1479] Accumulated tokens for job 143: 1122854
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1481] Discard waste for job 143: 1016.3251067929208
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:27 [scheduler.py:1484] Preserve waste for job 143: 1.203674465277945
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:28,481] LMCache INFO:[0m Storing KV cache for 8192 out of 30464 tokens (skip_leading_tokens=22272) for request chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:28,503] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.2345 ms, throughput: 44.9752 GB/s; offload_time: 22.1874 ms, put_time: 0.0471 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:28,508] LMCache INFO:[0m Reqid: chatcmpl-018651bf406c49fba8d212ffc07142cc, Total tokens 18859, LMCache hit tokens: 13824, need to load: 13808 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:28,513] LMCache INFO:[0m Reqid: chatcmpl-cc8d057320a240fe900cb01373b95a04, Total tokens 31500, LMCache hit tokens: 20992, need to load: 20976 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m DEBUGGING eos: True
[1;36m(APIServer pid=3659290)[0;0m extra_args: {'job_id': '143', 'last_func_call': 'fetch_url_content', 'is_last_step': False, 'this_func_call': 'search_engine_query'}
[1;36m(APIServer pid=3659290)[0;0m INFO:     127.0.0.1:44922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:28,566] LMCache INFO:[0m Retrieved 13824 out of 13824 required tokens (from 13824 total tokens). size: 1.6875 gb, cost 37.6223 ms, throughput: 44.8537 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:28,621] LMCache INFO:[0m Retrieved 20992 out of 20992 required tokens (from 20992 total tokens). size: 2.5625 gb, cost 54.7998 ms, throughput: 46.7612 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,160] LMCache INFO:[0m Storing KV cache for 5035 out of 18859 tokens (skip_leading_tokens=13824) for request chatcmpl-018651bf406c49fba8d212ffc07142cc [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,175] LMCache INFO:[0m Stored 5035 out of total 5035 tokens. size: 0.6146 gb, cost 14.1100 ms, throughput: 43.5596 GB/s; offload_time: 14.0749 ms, put_time: 0.0351 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,175] LMCache INFO:[0m Storing KV cache for 1536 out of 22528 tokens (skip_leading_tokens=20992) for request chatcmpl-cc8d057320a240fe900cb01373b95a04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,180] LMCache INFO:[0m Stored 1536 out of total 1536 tokens. size: 0.1875 gb, cost 4.5053 ms, throughput: 41.6178 GB/s; offload_time: 4.4909 ms, put_time: 0.0144 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,180] LMCache INFO:[0m Storing KV cache for 1428 out of 31892 tokens (skip_leading_tokens=30464) for request chatcmpl-e0bccfbf5f6044148ef1ed18338a9ca0 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,184] LMCache INFO:[0m Stored 1428 out of total 1428 tokens. size: 0.1743 gb, cost 4.3416 ms, throughput: 40.1505 GB/s; offload_time: 4.3289 ms, put_time: 0.0126 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:29 [estimate_with_func.py:307] Request job id arriving: 143, time is 1761207269.187483
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:29 [estimate_with_func.py:315] Request job id: 143
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,824] LMCache INFO:[0m Storing KV cache for 8192 out of 30720 tokens (skip_leading_tokens=22528) for request chatcmpl-cc8d057320a240fe900cb01373b95a04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,846] LMCache INFO:[0m Stored 8192 out of total 8192 tokens. size: 1.0000 gb, cost 22.1618 ms, throughput: 45.1228 GB/s; offload_time: 22.1184 ms, put_time: 0.0434 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,851] LMCache INFO:[0m Reqid: chatcmpl-46c534bc73954dc880d7e6151d067d59, Total tokens 26214, LMCache hit tokens: 15360, need to load: 15344 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:29,897] LMCache INFO:[0m Retrieved 15360 out of 15360 required tokens (from 15360 total tokens). size: 1.8750 gb, cost 40.1833 ms, throughput: 46.6612 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,441] LMCache INFO:[0m Storing KV cache for 7424 out of 22784 tokens (skip_leading_tokens=15360) for request chatcmpl-46c534bc73954dc880d7e6151d067d59 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,462] LMCache INFO:[0m Stored 7424 out of total 7424 tokens. size: 0.9062 gb, cost 20.1119 ms, throughput: 45.0604 GB/s; offload_time: 20.0725 ms, put_time: 0.0395 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,462] LMCache INFO:[0m Storing KV cache for 780 out of 31500 tokens (skip_leading_tokens=30720) for request chatcmpl-cc8d057320a240fe900cb01373b95a04 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,465] LMCache INFO:[0m Stored 780 out of total 780 tokens. size: 0.0952 gb, cost 2.6863 ms, throughput: 35.4450 GB/s; offload_time: 2.6753 ms, put_time: 0.0110 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Request last_func_call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m Job to history last func call: fetch_url_content
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [estimate_with_func.py:328] Request job id finishing: 148, time is 1761207270.4674754
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [scheduler.py:1462] Request GPU size bytes: 883294208
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [scheduler.py:1463] Token size of the request: 6334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [scheduler.py:1469] Swap waste for job 148: 0.027421061197916666
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [scheduler.py:1479] Accumulated tokens for job 148: 1147698
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [scheduler.py:1481] Discard waste for job 148: 1061.39467140359
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [scheduler.py:1484] Preserve waste for job 148: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,471] LMCache INFO:[0m Reqid: chatcmpl-3ed6b7f5d3e7465da147c1f874dabea4, Total tokens 23661, LMCache hit tokens: 15104, need to load: 15088 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:14:30 [loggers.py:123] Engine 000: Avg prompt throughput: 20804.9 tokens/s, Avg generation throughput: 75.8 tokens/s, Running: 33 reqs, Waiting: 13 reqs, GPU KV cache usage: 99.3%, Prefix cache hit rate: 16.3%
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,830] LMCache INFO:[0m Storing KV cache for 3430 out of 26214 tokens (skip_leading_tokens=22784) for request chatcmpl-46c534bc73954dc880d7e6151d067d59 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,839] LMCache INFO:[0m Stored 3430 out of total 3430 tokens. size: 0.4187 gb, cost 9.6970 ms, throughput: 43.1784 GB/s; offload_time: 9.6736 ms, put_time: 0.0234 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,844] LMCache INFO:[0m Reqid: chatcmpl-3ed6b7f5d3e7465da147c1f874dabea4, Total tokens 23661, LMCache hit tokens: 15104, need to load: 15088 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:30 [estimate_with_func.py:328] Request job id finishing: 79, time is 1761207270.9336364
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,936] LMCache INFO:[0m Reqid: chatcmpl-3ed6b7f5d3e7465da147c1f874dabea4, Total tokens 23661, LMCache hit tokens: 15104, need to load: 15088 [3m(vllm_v1_adapter.py:1191:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:30,983] LMCache INFO:[0m Retrieved 15104 out of 15104 required tokens (from 15104 total tokens). size: 1.8438 gb, cost 39.6304 ms, throughput: 46.5236 GB/s; [3m(cache_engine.py:509:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:31,516] LMCache INFO:[0m Storing KV cache for 7936 out of 23040 tokens (skip_leading_tokens=15104) for request chatcmpl-3ed6b7f5d3e7465da147c1f874dabea4 [3m(vllm_v1_adapter.py:1075:lmcache.integration.vllm.vllm_v1_adapter)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m [32;20m[2025-10-23 01:14:31,538] LMCache INFO:[0m Stored 7936 out of total 7936 tokens. size: 0.9688 gb, cost 21.6625 ms, throughput: 44.7201 GB/s; offload_time: 21.6169 ms, put_time: 0.0456 ms [3m(cache_engine.py:288:lmcache.v1.cache_engine)[0m
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 44, time is 1761207271.5410068
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 136, time is 1761207271.5419862
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 8579055616
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 65413
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 136: 0.26632893880208336
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 136: 983843
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 136: 782.1844406581838
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 136: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 138, time is 1761207271.5427644
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 110, time is 1761207271.5428386
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 3436314624
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 26214
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 110: 0.10667724609375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 110: 957629
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 110: 741.4616139922169
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 110: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 165, time is 1761207271.5432072
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 133, time is 1761207271.5433142
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 164, time is 1761207271.5436947
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 144, time is 1761207271.5445464
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 103, time is 1761207271.54529
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 66, time is 1761207271.5454915
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 3585605632
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 27237
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 66: 0.11131184895833333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 66: 700646
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 66: 399.88274812100707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 66: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 152, time is 1761207271.5458243
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 6697910272
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 51101
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 152: 0.20793050130208332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 152: 700646
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 152: 399.88274812100707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 152: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 140, time is 1761207271.5459313
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 2805465088
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 21404
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 140: 0.08709309895833334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 140: 700646
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 140: 399.88274812100707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 140: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 102, time is 1761207271.5460353
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 150, time is 1761207271.5460773
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 174, time is 1761207271.54681
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 5022810112
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 38242
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 174: 0.15592854817708332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 174: 576255
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 174: 272.1150057271771
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 174: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 94, time is 1761207271.5472689
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 68, time is 1761207271.5475476
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 101, time is 1761207271.547602
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 4129292288
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 31500
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 101: 0.12819010416666668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 101: 519240
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 101: 221.74365471708273
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 101: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 141, time is 1761207271.5479817
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 902168576
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 6883
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 141: 0.028006998697916667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 141: 519240
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 141: 221.74365471708273
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 141: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 122, time is 1761207271.548078
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 100, time is 1761207271.548294
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 757334016
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 5778
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 100: 0.0235107421875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 100: 495579
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 100: 202.35154249418983
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 100: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 25, time is 1761207271.5487869
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 1768947712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 13481
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 25: 0.054915364583333334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 25: 482098
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 25: 191.69932320131946
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 25: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 146, time is 1761207271.5490904
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 3516268544
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 26723
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 146: 0.10915934244791667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 146: 455375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 146: 171.43461992172345
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 146: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 77, time is 1761207271.549437
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 129, time is 1761207271.5496633
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 2472673280
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 18859
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 129: 0.07676188151041667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 129: 416335
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 129: 143.86296648616695
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 129: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 156, time is 1761207271.5499332
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 131, time is 1761207271.550275
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 3757572096
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 28620
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 131: 0.116650390625
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 131: 349333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 131: 102.1704707254712
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 131: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 121, time is 1761207271.5506246
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 109, time is 1761207271.5508966
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 32, time is 1761207271.5510485
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 1567096832
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 11939
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 32: 0.04864908854166667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 32: 301350
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 32: 76.68232718811575
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 32: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 142, time is 1761207271.55125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 4008050688
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 30409
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 142: 0.12442626953125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 142: 270941
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 142: 62.41728721460214
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 142: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 173, time is 1761207271.5516312
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 119, time is 1761207271.55229
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 1896873984
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 14375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 119: 0.05888671875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 119: 186081
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 119: 30.355942671732024
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 119: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 90, time is 1761207271.5525417
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 2435973120
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 18530
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 90: 0.07562255859375
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 90: 167551
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 90: 24.872336175066707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 90: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 149, time is 1761207271.5528138
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 689700864
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 5262
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 149: 0.0214111328125
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 149: 167551
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 149: 24.872336175066707
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 149: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 52, time is 1761207271.552926
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 5044174848
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 38430
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 52: 0.156591796875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 52: 129121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 52: 15.233330303452593
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 52: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 143, time is 1761207271.5533245
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 2625896448
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 20034
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 143: 0.0815185546875
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 143: 129121
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 143: 15.233330303452593
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 143: 3.1551425208456267
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 160, time is 1761207271.553419
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 10, time is 1761207271.5536532
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 157, time is 1761207271.553703
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 60, time is 1761207271.5537384
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 656408576
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 4968
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 60: 0.020377604166666667
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 60: 98941
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 60: 9.30351094807334
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 60: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 99, time is 1761207271.5539052
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 16, time is 1761207271.5539827
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 127, time is 1761207271.5545468
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 4180934656
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 31892
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 127: 0.12979329427083333
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 127: 0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 127: 0.001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 127: 1.2042946681798061
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [estimate_with_func.py:328] Request job id finishing: 97, time is 1761207271.5549345
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1462] Request GPU size bytes: 5873205248
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1463] Token size of the request: 44809
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1469] Swap waste for job 97: 0.18232828776041668
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1479] Accumulated tokens for job 97: 0
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1481] Discard waste for job 97: 0.001
[1;36m(EngineCore_DP0 pid=3659995)[0;0m INFO 10-23 01:14:31 [scheduler.py:1484] Preserve waste for job 97: 1.2042946681798061
[1;36m(APIServer pid=3659290)[0;0m WARNING 10-23 01:14:37 [launcher.py:98] port 8000 is used by process psutil.Process(pid=3659290, name='vllm', status='running') launched with command:
[1;36m(APIServer pid=3659290)[0;0m WARNING 10-23 01:14:37 [launcher.py:98] /data/lhc/func_call/vllm/.venv/bin/python3 /data/lhc/func_call/vllm/.venv/bin/vllm serve meta-llama/Llama-3.1-8B-Instruct --scheduling_policy=infercept --kv-transfer-config {"kv_connector":"LMCacheConnectorV1", "kv_role":"kv_both"}
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:14:37 [launcher.py:101] Shutting down FastAPI HTTP server.
[1;36m(APIServer pid=3659290)[0;0m INFO:     Shutting down
[1;36m(APIServer pid=3659290)[0;0m INFO 10-23 01:14:42 [loggers.py:123] Engine 000: Avg prompt throughput: 2191.8 tokens/s, Avg generation throughput: 5.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 16.3%
[1;36m(APIServer pid=3659290)[0;0m INFO:     Waiting for application shutdown.
[1;36m(APIServer pid=3659290)[0;0m INFO:     Application shutdown complete.
